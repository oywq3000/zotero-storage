2023.5
电脑编程技巧与维护
1 概述
近年来, 人工智能[1]与深度学习[2]在机器学习领域得
到快速发展, 各种新型的神经网络不断出现, 如受限玻
尔兹曼机 (RBM)[3]、 卷 积 神 经 网 络[4]和自动 编码器[5]等。
现有的深度学习模型大致分为两类: 判别器与生成器。
2014 年, Ian Goodfellow 将 RBM 与自动编码器结合并引
入极大值、 极小值双边博弈思想, 提出了由判别器与生成
器两部分组成的 GAN[6]这一全新的生成模型。 但是 GAN
的调参难度较大, 处理比较复杂的数据集、 训练过程有
时会出现模式崩溃、 生成图片效果较差、 梯度消失等问
题。 随着研究人员对 GAN 的研究逐渐深入, GAN 在许
多领域与其他模型进行了结合, 均取得了良好的应用效
果。 对几种经典的 GAN 进行综述, 大致介绍了 GAN 目
前的发展趋势。
2 GAN 模型的基本原理
作 为 一 种 强 大 的 生 成 器 , GAN 是 一 种 包 含 两 个 由
多层感知机 (MLP) 组 成 的 网 络 的 深 度 神 经 网 络 结 构 ,
即生成器和判别器。 生成器负责生成尽可能逼真的数据
以便成功 “欺骗” 判别器, 而判别器则需要尽可能准确
地区分出真实数据与生成数据。
真实数据与生成数据之间的关系如图 1 所示。
在图 1 中, 真实数据的分布由点间距较大的虚线表
示, 判别器判断出的结果分布由点间距较小的虚线表
示, 生成器生成数据的分布由实线表示。 其中, z 表示
噪声, 而 z 到 x 之间的线段表示由生成器生成的数据分
布 与 真 实 分 布 之 间 的 对 应 情 况 。 GAN 的 目 的 是 使 用 生
成样本分布 (实线) 去拟合真实的样本分布 (点间距较
大的虚线), 进而生成尽可能真实的样本。 在训练过程
的初期, 由生成器生成的数据分布与真实的样本分布区
别较大, 判断数据的真实性需要对判别器进行训练。 在
经过一定的训练次数后 , GAN 达 到 图 1 (b) 状 态 , 此
时判别器可以较好地指示样本的来源。 随后通过对生成
器的训练, 提升生成数据的真实性, 以 “欺骗” 判别
器, 进而达到图 1 (c) 状态。 最后通过多次的迭代训
练 后, GAN 达到图 1 (d) 状态 , 生 成 的 数 据 几 乎 完 全
拟合于真实的数据分布情况, 此时判别器判断数据来源
的结果约为 1/2。
设 z 为随机噪声, x 为真实数据, 生成器和判别器
分别为 G 和 D。 其中, D 是一个二分类器, 用于判断数
据 的 来 源 是 生 成 器 还 是 真 实 数 据 。 GAN 的 损 失 函 数 计
算公式如公式 (1) 所示:
(1)
其中, 第 1 项中的 logD(x) 表示判别器对样本数据
的判断结果; 第 2 项则表示对数据的合成与判断。 基于
极大值、 极小值双边博弈, 分别对生成器和判别器进行
优 化 并 进 行 交 替 训 练 , 直 至 达 到 纳 什 均 衡 。 对 于 GAN
的目标函数, 在生成器 G 的参数固定时, 可以得到最
优的判别器 D。 对于一个来自真实分布或生成分布的数
据, 它对判别器损失函数的贡献如公式 (2) 所示:
(2)
其 中 , pr(x) 为 真 实 分 布 ; pg(x) 为 生 成 分 布 。 令
其关于 D(x) 的导数为零, 可以得到全局最优解, 如公
生成对抗网络研究综述
于文家,樊国政,左昱昊,陈怡丹
(西安航空工业计算技术研究所, 西安 710064)
摘 要: 生成对抗网络 (GAN) 是一种基于深度学习的强大生成模型,目前广泛应用于计算机视觉、
自然语言处理、半监督学习等领域,并取得了显著的成果。随后研究人员通过对 GAN 的生成器、判
别器做结构上的改进或对目标函数等进行优化,提出了更多种的 GAN。首先介绍 GAN 的研究进展和
基 本 思 想 ,其 次 对 一 些 经 典 的 GAN,如 深 度 卷 积 生 成 对 抗 网 络 (DCGAN)、 条 件 生 成 对 抗 网 络
(CGAN)、WGAN 和超分辨率生成对抗网络 (SRGAN) 等进行综述,最后对 GAN 的相关工作进行总
结与展望。
关键词: 深度学习;生成对抗网络;生成器;判别器
图 1 真实数据与生成数据之间的关系
(a) (b) (c) (d)
z
x
174
DOI:10.16184/j.cnki.comprg.2023.05.030


2023.5
电脑编程技巧与维护
式 (3) 所示:
(3)
若将生成器固定, 则将目标函数中的数学期望按照
定义展开, 如公式 (4) 所示:
(4)
当生成器固定时, 公式 (4) 中的 pr(x)与 pg(x) 均
表示常数, 此时 V(G,D) 表示 D(x) 的函数。 令 y=D(x),
a=pr(x), b=pg(x), 构造函数计算公式如公式 (5) 所示:
F(y) =alogy+blog (1-y) (5)
对 F (y) 求 导 , 并 令 其 导 数 为 零 , 所 得 公 式 如
公 式 (6) 所示:
(6)
将该最优判别器的值代入目标函 数 中 并 消 去D(x),
得到关于 G 的目标函数, 如公式 (7) 所示:
(7)
KL 散度与 JS 散度均为非负, 并且当且仅当两个分
布相等时取值为 0。
由公式 (7) 可得, 当且仅当 pr(x) =pg(x) 时, C(G)
取得最小值-log 4。
当生成对抗网络训练过程的迭代次数足够多时,
pr (x) 与 pg (x) 无 限 接 近 , 可 看 作 近 似 相 等 。 此 时 D
(x) 的 最 优 解 近 似 为 0.5, 即 判 别 器 无 法 判 断 样 本 数
据的来源, 而生成器生成的数据与真实的样本数据完
全一致。
3 GAN 的改进
3.1 DCGAN
与 GAN 中生成器和判别器所使用的 多 层 感 知 机 相
比, 卷积神经网络具有更强大的数据拟合与表达能力,
并且其在判别式模型中取得了一定的成功。 因此, Alec
等人使用卷积神经网络对原 始 GAN 的生成器和 判 别 器
所采用的多层感知机 进行了 替 换 , 提 出 了 DCGAN。 从
本质上来说, DCGAN 是对 GAN 的 训 练 过 程 进 行 指 导 。
DCGAN 在强调隐藏层分析和可 视 化 计 数 的 同 时 , 通 过
使用卷积层取代了全连接层、 去除池化层并采用批标
准化等技术, 将判别器的训练结果作为输入回传到生
成器中。
DCGAN 的 出 现 极 大 地 增 强 了 GAN 的 数 据 生 成 质
量。 在理 论上, DCGAN 虽然没有带来解释 性 , 但 是 其
生成图像的强大能力使得众多研究人员逐渐开始对生成
对抗网络进行研究。 同时, DCGAN 证明了将 神 经 网 络
引入生成对抗网络的可行性。 另外, DCGAN 的 网 络 结
构也被用以评价不同目标函数的 GAN 生成能力。
3.2 CGAN
随着研究的深入, 越来越多带有附加信息的数据成
为了深度学习的研究对象。 Mehdi Mirza 提出了 CGAN 将
额外信息引入到 GAN 之中, 通过使用条件概率对目标函
数进行替换并生成带有标签的数据。 CGAN 将附加信息
作为输入的一部分引入到 GAN 中, 使其能够指导数据的
生成过程, 从而使 GAN 可以处理带有类别标签的数据。
CGAN 与 GAN 的区别在于其目标函数中的概率是条
件概率。 CGAN 的目标函数计算公式如公式 (8) 所示:
(8)
其中, y 表示额外信息。 CGAN 将 额 外 信 息 y 作 为
生成器和判别器输入的一部分。 在生成器中, 先验输入
噪声 pz(z) 和额外信息 y 共同构成生成器的隐藏层输入。
CGAN 以 GAN 为 基 础 , 通 过 将 类 别 标 签 之 类 的 额
外 信 息 作 为 生 成 器 与 判 别 器 输 入 的 一 部 分 , 实 现 GAN
处 理带有额外信息数据的功能。 原始 GAN 的生成 器 输
入是随机噪声, 而 CGAN 的生成器可以将类别标签与随
机噪声组合后的数据作为隐藏层输 入。 原始 GAN 判 别
器的输入是图片数据, CGAN 的判别器的输入是类别标
签和图片数据拼接以后的数据, 并将其作为判断是生成
器生成的数据还是实际数据的依据。
3.3 WGAN
2017 年, 马丁·阿约夫斯基 (Martin Ayovsky) 等用
Wasserstein 距离代替 GAN 中的 JS 散度, 以解决生成对抗
网络中两种分布不重叠的梯度消失问题, 提出了 WGAN。
Wasserstein 距离的数学表达式如公式 (9) 所示:
(9)
当 fw 为判别器时, WGAN 的目标函数如公式 (10)
所示:
(10)
与之前的判别器不同, WGAN 不再需要使用判别器
作为0~1 分类来将其值限制在 [0,1]。 fw 的值越大, WGAN
175


2023.5
电脑编程技巧与维护
的生成分布就越接近真实的分布; 反之, 则 WGAN 的生成
分布越接近生成的分布。 此外, 由于利普希茨 (Lipschitz)
常数是 1, 显然 Lipschitz 连续在鉴别器中是难以实现的。
为了将 Lipschitz 连续表示为权重剪枝, 需要参数 w∈[-c,c],
其中, c 表示一个常数。 判别器的损失函数如公式
(11) 所示:
(11)
与此同时, 生成器的损失函数如公式 (12) 所示:
(12)
WGAN 在理论上解释了因生成器的梯度消失而导致
的 不 稳 定 训 练 的 原 因 , 并 用 Wasserstein 距 离 代 替 了 JS
散度, 从理论上解决了梯度消失的问题。
3.4 SRGAN
2017 年, Christian Ledig 等首次将生成对抗网络用
于图像超分辨率领域, 提出了 SRGAN[10]并取得了良好的
效果。 SRGAN 是 由 对 抗 损 失 和 内 容 损 失 共 同 组 成 的 感
知损失, 用来取代传统 GAN 的损失函数。
SRGAN 的生成器使用的是 SRResNet, 因 为 当 损 失
函数从判别器反向传播返回到生成器时, 需要经过多层
网络, 而在经过多层网络的过程中势必会出现梯度弥
散。 通过使用残差连接, 可以有效地保证生成对抗网络
训练的鲁棒性。
SRGAN 的 生 成 器 损 失 函 数 如 公 式 ( 13) ~ ( 16)
所示:
(13)
(14)
(15)
(16)
其中, 表示重构损失, 即生成图像与真实图像
的逐像素点 MSE 损失; 表示感知损失, 由对抗损失
和 内 容 损 失 组 成 ; 表 示 内 容 损 失 ; VGG 网 络 中 第 i
层 第 j 个 卷 积 核 输 出 的 特 征 映 射 的 MSE 损 失 为 ;
表示对抗损失。
SRGAN 的判别器损失函数如公式 (17) 所示:
(17)
SRGAN 提 出 了 新 的 生 成 器 — — —SRResNet, 以 及 全
新的损失函数, 在通过对抗损失提升生成图像的真实感
的同时, 通过内容损失获取高分辨率图像和生成图像的
感知相似性, 而不只是像素级相似性, 这些改进使得
SRGAN 可以更好地捕捉图像的感知细节。
4 结语
GAN 的 强 大 生 成 能 力 使 其 在 深 度 学 习 领 域 得 到 了
快速发展。 目前国内外众多学者已经将新的研究方向放
在了训练指标、 模式坍塌及生成能力的可解释性上。 在
实际应用场景中, 如何去除噪声、 提升生成图像的质量
及如何将这一强大的深度学习模型应用于自然语言处理
领域, 也是亟待解决的问题。
参考文献
[1] NILSSON N J. Principle of artificial intelligence [J] .
IEEE Intelligent Systems, 1982, 29 (2) : 2-4.
[2] LECUN Y, BENGIO Y, HINTON G. Deep learning [J] .
Nature, 2015, 521 (7553) : 436.
[3] 张健, 丁世飞, 张楠, 等. 受限玻尔兹曼机研究综
述 [J] . 软件学报, 2019, 30 (7) : 2073-2090.
[4] LAWRENCE S, GILES C L, TSOI A C, et al. Face
recognition: a convolutional neural -network approach
[J] . IEEE Transactions on Neural Networks, 1997, 8
(1) : 98-113.
[5] 邓俊锋, 张晓龙. 基于自动编码器组合的深度学习优
化方法 [J] . 计算机应用, 2016, 36 (3) : 697-702.
[6] LEDIG C, WANG Z, SHI W, et al. Photo-realistic single
image super -resolution using a generative adversarial
network [C] //IEEE. IEEE Conference on Compute r
Vision and Pattern Recognition, Puerto Rico. NewYork:
IEEE, 2017: 1-10.
176