1.1
1.2
1.3
1.3.1
1.3.2
1.3.3
1.3.4
1.4
1.4.1
1.4.2
1.4.3
1.4.4
1.4.5
1.5
1.5.1
1.5.2
1.5.3
1.6
1.7
目錄
简介
序言
第一部分:数据系统的基石
第一章:可靠性、可扩展性、可维护性
第二章:数据模型与查询语言
第三章:存储与检索
第四章:编码与演化
第二部分:分布式数据
第五章:复制
第六章:分区
第七章:事务
第八章:分布式系统的麻烦
第九章:一致性与共识
第三部分:派生数据
第十章:批处理
第十一章:流处理
第十二章:数据系统的未来
术语表
后记
1


设计数据密集型应用 - 中文翻译
作者: Martin Kleppmann
原书名称:《Designing Data-Intensive Application》
译者:冯若航 (fengruohang@outlook.com )
Gitbook地址:ddia-cn(需要科学上网)
建议使用Typora或Gitbook以获取最佳阅读体验。
译序
不懂数据库的全栈工程师不是好架构师
—— Vonng
现今,尤其是在互联网领域,大多数应用都属于数据密集型应用。本书从底层数据结构到顶
层架构设计,将数据系统设计中的精髓娓娓道来。其中的宝贵经验无论是对架构师,DBA、
还是后端工程师、甚至产品经理都会有帮助。
这是一本理论结合实践的书,书中很多问题,译者在实际场景中都曾遇到过,读来让人击节
扼腕。如果能早点读到这本书,该少走多少弯路啊!
这也是一本深入浅出的书,讲述概念的来龙去脉而不是卖弄定义,介绍事物发展演化历程而
不是事实堆砌,将复杂的概念讲述的浅显易懂,但又直击本质不失深度。每章最后的引用质
量非常好,是深入学习各个主题的绝佳索引。
本书为数据系统的设计、实现、与评价提供了很好的概念框架。读完并理解本书内容后,读
者可以轻松看破大多数的技术忽悠,与技术砖家撕起来虎虎生风 。
这是2017年译者读过最好的一本技术类书籍,这么好的书没有中文翻译,实在是遗憾。某不
才,愿为先进技术文化的传播贡献一分力量。既可以深入学习有趣的技术主题,又可以锻炼
中英文语言文字功底,何乐而不为?
前言
在我们的社会中,技术是一种强大的力量。数据、软件、通信可以用于坏的方面:不公
平的阶级固化,损害公民权利,保护既得利益集团。但也可以用于好的方面:让底层人
民发出自己的声音,让每个人都拥有机会,避免灾难。本书献给所有将技术用于善途的
人们。
简介
2


计算是一种流行文化,流行文化鄙视历史。 流行文化关乎个体身份和参与感,但与合作
无关。流行文化活在当下,也与过去和未来无关。 我认为大部分(为了钱)编写代码的
人就是这样的, 他们不知道自己的文化来自哪里。
——阿兰·凯接受Dobb博士的杂志采访时(2012年)
目录
序言
第一部分:数据系统的基石
第一章:可靠性、可扩展性、可维护性
第二章:数据模型与查询语言
第三章:存储与检索
第四章:编码与演化
第二部分:分布式数据
第五章:复制
第六章:分区
第七章:事务
第八章:分布式系统的麻烦
第九章:一致性与共识
第三部分:衍生数据
第十章:批处理
第十一章:流处理
第十二章:数据系统的未来
术语表
后记
法律声明
从原作者处得知,已经有简体中文的翻译计划,将于2018年末完成。
简介
3


译者纯粹出于学习目的与个人兴趣翻译本书,不追求任何经济利益。
译者保留对此版本译文的署名权,其他权利以原作者和出版社的主张为准。
本译文只供学习研究参考之用,不得公开传播发行或用于商业用途。有能力阅读英文书籍者
请购买正版支持。
CONTRIBUTION
1. 序言初翻修正 by @seagullbird
2. 第一章语法标点校正 by @nevertiree
3. 第六章部分校正 与第10章的初翻 by @MuAlex
4. 第一部分前言,ch2校正 by @jiajiadebug
5. 词汇表、后记关于野猪的部分 by @Chowss
LICENSE
CC-BY 4.0
简介
4


序言
如果近几年从业于软件工程,特别是服务器端和后端系统开发,那么您很有可能已经被大量
关于数据存储和处理的时髦词汇轰炸过了: NoSQL!大数据!Web-Scale!分片!最终一致
性!ACID! CAP定理!云服务!MapReduce!实时!
在最近十年中,我们看到了很多有趣的进展,关于数据库,分布式系统,以及在此基础上构
建应用程序的方式。这些进展有着各种各样的驱动力:
谷歌,雅虎,亚马逊,脸书,领英,微软和推特等互联网公司正在和巨大的流量/数据打
交道,这迫使他们去创造能有效应对如此规模的新工具。
企业需要变得敏捷,需要低成本地检验假设,需要通过缩短开发周期和保持数据模型的
灵活性,快速地响应新的市场洞察。
免费和开源软件变得非常成功,在许多环境中比商业软件和定制软件更受欢迎。
处理器主频几乎没有增长,但是多核处理器已经成为标配,网络也越来越快。这意味着
并行化程度只增不减。
即使您在一个小团队中工作,现在也可以构建分布在多台计算机甚至多个地理区域的系
统,这要归功于譬如亚马逊网络服务(AWS)等基础设施即服务(IaaS)概念的践行
者。
许多服务都要求高可用,因停电或维护导致的服务不可用,变得越来越难以接受。
数据密集型应用(data-intensive applications)正在通过使用这些技术进步来推动可能性的
边界。一个应用被称为数据密集型的,如果数据是其主要挑战(数据量,数据复杂度或数据
变化速度)—— 与之相对的是计算密集型,即处理器速度是其瓶颈。
帮助数据密集型应用存储和处理数据的工具与技术,正迅速地适应这些变化。新型数据库系
统(“NoSQL”)已经备受关注,而消息队列,缓存,搜索索引,批处理和流处理框架以及相
关技术也非常重要。很多应用组合使用这些工具与技术。
这些生意盎然的时髦词汇体现出人们对新的可能性的热情,这是一件好事。但是作为软件工
程师和架构师,如果要开发优秀的应用,我们还需要对各种层出不穷的技术及其利弊权衡有
精准的技术理解。为了获得这种洞察,我们需要深挖时髦词汇背后的内容。
幸运的是,在技术迅速变化的背后总是存在一些持续成立的原则,无论您使用了特定工具的
哪个版本。如果您理解了这些原则,就可以领会这些工具的适用场景,如何充分利用它们,
以及如何避免其中的陷阱。这正是本书的初衷。
本书的目标是帮助您在飞速变化的数据处理和数据存储技术大观园中找到方向。本书并不是
某个特定工具的教程,也不是一本充满枯燥理论的教科书。相反,我们将看到一些成功数据
系统的样例:许多流行应用每天都要在生产中会满足可扩展性、性能、以及可靠性的要求,
而这些技术构成了这些应用的基础。
序言
5


我们将深入这些系统的内部,理清它们的关键算法,讨论背后的原则和它们必须做出的权
衡。在这个过程中,我们将尝试寻找思考数据系统的有效方式 —— 不仅关于它们如何工作,
还包括它们为什么以这种方式工作,以及哪些问题是我们需要问的。
阅读本书后,你能很好地决定哪种技术适合哪种用途,并了解如何将工具组合起来,为一个
良好应用架构奠定基础。本书并不足以使你从头开始构建自己的数据库存储引擎,不过幸运
的是这基本上很少有必要。你将获得对系统底层发生事情的敏锐直觉,这样你就有能力推理
它们的行为,做出优秀的设计决策,并追踪任何可能出现的问题。
本书的目标读者
如果你开发的应用具有用于存储或处理数据的某种服务器/后端系统,而且使用网络(例如,
Web应用,移动应用或连接到互联网的传感器),那么本书就是为你准备的。
本书是为软件工程师,软件架构师,以及喜欢写代码的技术经理准备的。如果您需要对所从
事系统的架构做出决策 —— 例如您需要选择解决某个特定问题的工具,并找出如何最好地使
用这些工具,那么这本书对您尤有价值。但即使你无法选择你的工具,本书仍将帮助你更好
地了解所使用工具的长处和短处。
您应当具有一些开发Web应用或网络服务的经验,且应当熟悉关系型数据库和SQL。任何您
了解的非关系型数据库和其他与数据相关工具都会有所帮助,但不是必需的。对常见网络协
议如TCP和HTTP的大概理解是有帮助的。编程语言或框架的选择对阅读本书没有任何不同影
响。
如果以下任意一条对您为真,你会发现这本书很有价值:
您想了解如何使数据系统可扩展,例如,支持拥有数百万用户的Web或移动应用。
您需要提高应用程序的可用性(最大限度地减少停机时间),保持稳定运行。
您正在寻找使系统在长期运行过程易于维护的方法,即使系统规模增长,需求与技术也
发生变化。
您对事物的运作方式有着天然的好奇心,并且希望知道一些主流网站和在线服务背后发
生的事情。这本书打破了各种数据库和数据处理系统的内幕,探索这些系统设计中的智
慧是非常有趣的。
有时在讨论可扩展的数据系统时,人们会说:“你又不在谷歌或亚马逊,别操心可扩展性了,
直接上关系型数据库”。这个陈述有一定的道理:为了不必要的扩展性而设计程序,不仅会浪
费不必要的精力,并且可能会把你锁死在一个不灵活的设计中。实际上这是一种“过早优化”的
形式。不过,选择合适的工具确实很重要,而不同的技术各有优缺点。我们将看到,关系数
据库虽然很重要,但绝不是数据处理的终章。
本书涉及的领域
序言
6


本书并不会尝试告诉读者如何安装或使用特定的软件包或API,因为已经有大量文档给出了详
细的使用说明。相反,我们会讨论数据系统的基石——各种原则与利弊权衡,并探讨了不同
产品所做出的不同设计决策。
在电子书中包含了在线资源全文的链接。所有链接在出版时都进行了验证,但不幸的是,由
于网络的自然规律,链接往往会频繁地破损。如果您遇到链接断开的情况,或者正在阅读本
书的打印副本,可以使用搜索引擎查找参考文献。对于学术论文,您可以在Google学术中搜
索标题,查找可以公开获取的PDF文件。或者,您也可以在 https://github.com/ept/ddia
references 中找到所有的参考资料,我们在那儿维护最新的链接。
我们主要关注的是数据系统的架构(architecture),以及它们被集成到数据密集型应用中的
方式。本书没有足够的空间覆盖部署,运维,安全,管理等领域 —— 这些都是复杂而重要的
主题,仅仅在本书中用粗略的注解讨论这些对它们很不公平。每个领域都值得用单独的书去
讲。
本书中描述的许多技术都被涵盖在大数据(Big Data)这个时髦词的范畴中。然而“大数据”这
个术语被滥用,缺乏明确定义,以至于在严肃的工程讨论中没有用处。这本书使用歧义更小
的术语,如“单节点”之于”分布式系统“,或”在线/交互式系统“之于”离线/批处理系统“。
本书对自由和开源软件(FOSS)有一定偏好,因为阅读,修改和执行源码是了解一样东西详
细工作原理的好方法。开放的平台也可以降低供应商垄断的风险。然而在适当的情况下,我
们也会讨论专利软件(闭源软件,软件即服务 SaaS,或一些在文献中描述过但未公开发行的
公司内部软件)。
本书纲要
本书分为三部分:
1. 在第一部分中,我们会讨论设计数据密集型应用所赖的基本思想。我们从第1章开始,讨
论我们实际要达到的目标:可靠性,可扩展性和可维护性;我们该如何思考这些概念;
以及如何实现它们。在第2章中,我们比较了几种不同的数据模型和查询语言,看看它们
如何适用于不同的场景。在第3章中将讨论存储引擎:数据库如何在磁盘上摆放数据,以
便能高效地再次找到它。第4章转向数据编码(序列化),以及随时间演化的模式。
2. 在第二部分中,我们从讨论存储在一台机器上的数据转向讨论分布在多台机器上的数
据。这对于可扩展性通常是必需的,但带来了各种独特的挑战。我们首先讨论复制(第5
章),分区/分片(第6章)和事务(第7章)。然后我们将探索关于分布式系统问题的更
多细节(第8章),以及在分布式系统中实现一致性与共识意味着什么(第9章)。
3. 在第三部分中,我们讨论那些从其他数据集衍生出一些数据集的系统。衍生数据经常出
现在异构系统中:当没有单个数据库可以把所有事情都做的很好时,应用需要集成几种
不同的数据库,缓存,索引等。在第10章中我们将从一种衍生数据的批处理方法开始,
序言
7


然后在此基础上建立在第11章中讨论的流处理。最后,在第12章中,我们将所有内容汇
总,讨论在将来构建可靠,可伸缩和可维护的应用程序的方法。
参考文献与延伸阅读
本书中讨论的大部分内容已经在其它地方以某种形式出现过了 —— 会议演示文稿,研究论
文,博客文章,代码,BUG跟踪器,邮件列表,以及工程习惯中。本书总结了不同来源资料
中最重要的想法,并在文本中包含了指向原始文献的链接。 如果你想更深入地探索一个领
域,那么每章末尾的参考文献都是很好的资源,其中大部分可以免费在线获取。
O‘Reilly Safari
Safari (formerly Safari Books Online) is a membership-based training and reference platform
for enterprise, government, educators, and individuals.
Members have access to thousands of books, training videos, Learning Paths, interac‐ tive
tutorials, and curated playlists from over 250 publishers, including O’Reilly Media, Harvard
Business Review, Prentice Hall Professional, Addison-Wesley Pro‐ fessional, Microsoft
Press, Sams, Que, Peachpit Press, Adobe, Focal Press, Cisco Press, John Wiley & Sons,
Syngress, Morgan Kaufmann, IBM Redbooks, Packt, Adobe Press, FT Press, Apress,
Manning, New Riders, McGraw-Hill, Jones & Bartlett, and Course Technology, among
others.
For more information, please visit http://oreilly.com/safari.
致谢
本书融合了学术研究和工业实践的经验,融合并系统化了大量其他人的想法与知识。在计算
领域,我们往往会被各种新鲜花样所吸引,但我认为前人完成的工作中,有太多值得我们学
习的地方了。本书有800多处引用:文章,博客,讲座,文档等,对我来说这些都是宝贵的学
习资源。我非常感谢这些材料的作者分享他们的知识。
我也从与人交流中学到了很多东西,很多人花费了宝贵的时间与我讨论想法并耐心解释。特
别感谢 Joe Adler, Ross Anderson, Peter Bailis, Márton Balassi, Alastair Beresford, Mark
Callaghan, Mat Clayton, Patrick Collison, Sean Cribbs, Shirshanka Das, Niklas Ekström,
Stephan Ewen, Alan Fekete, Gyula Fóra, Camille Fournier, Andres Freund, John Garbutt,
Seth Gilbert, Tom Haggett, Pat Hel‐ land, Joe Hellerstein, Jakob Homan, Heidi Howard,
John Hugg, Julian Hyde, Conrad Irwin, Evan Jones, Flavio Junqueira, Jessica Kerr, Kyle
Kingsbury, Jay Kreps, Carl Lerche, Nicolas Liochon, Steve Loughran, Lee Mallabone,
序言
8


Nathan Marz, Caitie McCaffrey, Josie McLellan, Christopher Meiklejohn, Ian Meyers, Neha
Narkhede, Neha Narula, Cathy O’Neil, Onora O’Neill, Ludovic Orban, Zoran Perkov, Julia
Powles, Chris Riccomini, Henry Robinson, David Rosenthal, Jennifer Rullmann, Matthew
Sackman, Martin Scholl, Amit Sela, Gwen Shapira, Greg Spurrier, Sam Stokes, Ben
Stopford, Tom Stuart, Diana Vasile, Rahul Vohra, Pete Warden, 以及 Brett Wooldridge.
更多人通过审阅草稿并提供反馈意见在本书的创作过程中做出了无价的贡献。我要特别感谢
Raul Agepati, Tyler Akidau, Mattias Andersson, Sasha Baranov, Veena Basavaraj, David
Beyer, Jim Brikman, Paul Carey, Raul Castro Fernandez, Joseph Chow, Derek Elkins, Sam
Elliott, Alexander Gallego, Mark Grover, Stu Halloway, Heidi Howard, Nicola Kleppmann,
Stefan Kruppa, Bjorn Madsen, Sander Mak, Stefan Podkowinski, Phil Potter, Hamid
Ramazani, Sam Stokes, 以及Ben Summers。当然对于本书中的任何遗留错误或难以接受的
见解,我都承担全部责任。
为了帮助这本书落地,并且耐心地处理我缓慢的写作和不寻常的要求,我要对编辑Marie
Beaugureau,Mike Loukides,Ann Spencer和O'Reilly的所有团队表示感谢。我要感谢
Rachel Head帮我找到了合适的术语。我要感谢Alastair Beresford,Susan Goodhue,Neha
Narkhede和Kevin Scott,在其他工作事务之外给了我充分地创作时间和自由。
特别感谢Shabbir Diwan和Edie Freedman,他们非常用心地为各章配了地图。他们提出了不
落俗套的灵感,创作了这些地图,美丽而引人入胜,真是太棒了。
最后我要表达对家人和朋友们的爱,没有他们,我将无法走完这个将近四年的写作历程。你
们是最棒的。
序言
9


第一部分 数据系统基础
本书前四章介绍了数据系统底层的基础概念,无论是在单台机器上运行的单点数据系统,还
是分布在多台机器上的分布式数据系统都适用。
1. 第一章将介绍本书使用的术语和方法。可靠性,可扩展性和可维护性 ,这些词汇到底意
味着什么?如何实现这些目标?
2. 第二章将对几种不同的数据模型和查询语言进行比较。从程序员的角度看,这是数据库
之间最明显的区别。不同的数据模型适用于不同的应用场景。
3. 第三章将深入存储引擎内部,研究数据库如何在磁盘上摆放数据。不同的存储引擎针对
不同的负载进行优化,选择合适的存储引擎对系统性能有巨大影响。
4. 第四章将对几种不同的 数据编码进行比较。特别研究了这些格式在应用需求经常变化、
模式需要随时间演变的环境中表现如何。
第二部分将专门讨论在分布式数据系统中特有的问题。
目录
1. 可靠性、可扩展性、可维护性
2. 数据模型与查询语言
3. 存储与检索
4. 编码与演化
上一章 目录 下一章
序言 设计数据密集型应用 第一章:可靠性、可扩展性、可维护性
第一部分:数据系统的基石
10


第一章:可靠性,可扩展性,可维护性
第一章:可靠性、可扩展性、可维护性
11


第一章:可靠性、可扩展性、可维护性
12


互联网做得太棒了,以至于大多数人将它看作像太平洋这样的自然资源,而不是什么人
工产物。上一次出现这种大规模且无差错的技术, 你还记得是什么时候吗?
——阿兰·凯在接受Dobb博士杂志采访时说(2012年)
[TOC]
现今很多应用程序都是数据密集型(data-intensive)的,而非计算密集型(compute
intensive)的。因此CPU很少成为这类应用的瓶颈,更大的问题通常来自数据量、数据复杂
性、以及数据的变更速度。
数据密集型应用通常由标准组件构建而成,标准组件提供了很多通用的功能;例如,许多应
用程序都需要:
数据库(database)
存储数据,以便自己或其他应用程序之后能再次找到
缓存(cache)
记住开销昂贵操作的结果,加快读取速度
搜索索引(search indexes)
允许用户按关键字搜索数据,或以各种方式对数据进行过滤
流处理(stream processing)
向其他进程发送消息,进行异步处理
批处理(batch processing)
定期处理累积的大批量数据
如果这些功能听上去平淡无奇,那是因为这些数据系统(data system)是非常成功的抽
象:我们一直不假思索地使用它们并习以为常。绝大多数工程师不会幻想从零开始编写存储
引擎,因为在开发应用时,数据库已经是足够完美的工具了。
但现实没有这么简单。不同的应用有着不同的需求,因而数据库系统也是百花齐放,有着各
式各样的特性。实现缓存有很多种手段,创建搜索索引也有好几种方法,诸如此类。因此在
开发应用前,我们依然有必要先弄清楚最适合手头工作的工具和方法。而且当单个工具解决
不了你的问题时,组合使用这些工具可能还是有些难度的。
本书将是一趟关于数据系统原理、实践与应用的旅程,并讲述了设计数据密集型应用的方
法。我们将探索不同工具之间的共性与特性,以及各自的实现原理。
第一章:可靠性、可扩展性、可维护性
13


本章将从我们所要实现的基础目标开始:可靠、可扩展、可维护的数据系统。我们将澄清这
些词语的含义,概述考量这些目标的方法。并回顾一些后续章节所需的基础知识。在接下来
的章节中我们将抽丝剥茧,研究设计数据密集型应用时可能遇到的设计决策。
关于数据系统的思考
我们通常认为,数据库、消息队列、缓存等工具分属于几个差异显著的类别。虽然数据库和
消息队列表面上有一些相似性——它们都会存储一段时间的数据——但它们有迥然不同的访
问模式,这意味着迥异的性能特征和实现手段。
那我们为什么要把这些东西放在数据系统(data system)的总称之下混为一谈呢?
近些年来,出现了许多新的数据存储工具与数据处理工具。它们针对不同应用场景进行优
化,因此不再适合生硬地归入传统类别【1】。类别之间的界限变得越来越模糊,例如:数据
存储可以被当成消息队列用(Redis),消息队列则带有类似数据库的持久保证(Apache
Kafka)。
其次,越来越多的应用程序有着各种严格而广泛的要求,单个工具不足以满足所有的数据处
理和存储需求。取而代之的是,总体工作被拆分成一系列能被单个工具高效完成的任务,并
通过应用代码将它们缝合起来。
例如,如果将缓存(应用管理的缓存层,Memcached或同类产品)和全文搜索(全文搜索服
务器,例如Elasticsearch或Solr)功能从主数据库剥离出来,那么使缓存/索引与主数据库保
持同步通常是应用代码的责任。图1-1 给出了这种架构可能的样子(细节将在后面的章节中详
细介绍)。
第一章:可靠性、可扩展性、可维护性
14


图1-1 一个可能的组合使用多个组件的数据系统架构
当你将多个工具组合在一起提供服务时,服务的接口或应用程序编程接口(API, Application
Programming Interface)通常向客户端隐藏这些实现细节。现在,你基本上已经使用较小
的通用组件创建了一个全新的、专用的数据系统。这个新的复合数据系统可能会提供特定的
保证,例如:缓存在写入时会作废或更新,以便外部客户端获取一致的结果。现在你不仅是
应用程序开发人员,还是数据系统设计人员了。
设计数据系统或服务时可能会遇到很多棘手的问题,例如:当系统出问题时,如何确保数据
的正确性和完整性?当部分系统退化降级时,如何为客户提供始终如一的良好性能?当负载
增加时,如何扩容应对?什么样的API才是好的API?
影响数据系统设计的因素很多,包括参与人员的技能和经验、历史遗留问题、系统路径依
赖、交付时限、公司的风险容忍度、监管约束等,这些因素都需要具体问题具体分析。
本书着重讨论三个在大多数软件系统中都很重要的问题:
可靠性(Reliability)
系统在困境(adversity)(硬件故障、软件故障、人为错误)中仍可正常工作(正确完成功
能,并能达到期望的性能水准)。
可扩展性(Scalability)
有合理的办法应对系统的增长(数据量、流量、复杂性)(参阅“可扩展性”)
第一章:可靠性、可扩展性、可维护性
15


可维护性(Maintainability)
许多不同的人(工程师、运维)在不同的生命周期,都能在高效地在系统上工作(使系统保
持现有行为,并适应新的应用场景)。(参阅”可维护性“)
人们经常追求这些词汇,却没有清楚理解它们到底意味着什么。为了工程的严谨性,本章的
剩余部分将探讨可靠性、可扩展性、可维护性的含义。为实现这些目标而使用的各种技术,
架构和算法将在后续的章节中研究。
可靠性
人们对于一个东西是否可靠,都有一个直观的想法。人们对可靠软件的典型期望包括:
应用程序表现出用户所期望的功能。
允许用户犯错,允许用户以出乎意料的方式使用软件。
在预期的负载和数据量下,性能满足要求。
系统能防止未经授权的访问和滥用。
如果所有这些在一起意味着“正确工作”,那么可以把可靠性粗略理解为“即使出现问题,也能
继续正确工作”。
造成错误的原因叫做故障(fault),能预料并应对故障的系统特性可称为容错(fault
tolerant)或韧性(resilient)。“容错”一词可能会产生误导,因为它暗示着系统可以容忍所
有可能的错误,但在实际中这是不可能的。比方说,如果整个地球(及其上的所有服务器)
都被黑洞吞噬了,想要容忍这种错误,需要把网络托管到太空中——这种预算能不能批准就
祝你好运了。所以在讨论容错时,只有谈论特定类型的错误才有意义。
注意故障(fault)不同于失效(failure)【2】。故障通常定义为系统的一部分状态偏离其
标准,而失效则是系统作为一个整体停止向用户提供服务。故障的概率不可能降到零,因此
最好设计容错机制以防因故障而导致失效。本书中我们将介绍几种用不可靠的部件构建可靠
系统的技术。
反直觉的是,在这类容错系统中,通过故意触发来提高故障率是有意义的,例如:在没有警
告的情况下随机地杀死单个进程。许多高危漏洞实际上是由糟糕的错误处理导致的【3】,因
此我们可以通过故意引发故障来确保容错机制不断运行并接受考验,从而提高故障自然发生
时系统能正确处理的信心。Netflix公司的Chaos Monkey【4】就是这种方法的一个例子。
尽管比起阻止错误(prevent error),我们通常更倾向于容忍错误。但也有预防胜于治疗的
情况(比如不存在治疗方法时)。安全问题就属于这种情况。例如,如果攻击者破坏了系
统,并获取了敏感数据,这种事是撤销不了的。但本书主要讨论的是可以恢复的故障种类,
正如下面几节所述。
硬件故障
第一章:可靠性、可扩展性、可维护性
16


当想到系统失效的原因时,硬件故障(hardware faults)总会第一个进入脑海。硬盘崩溃、
内存出错、机房断电、有人拔错网线......任何与大型数据中心打过交道的人都会告诉你:一
旦你拥有很多机器,这些事情总会发生!
据报道称,硬盘的平均无故障时间(MTTF, mean time to failure)约为10到50年【5】
【6】。因此从数学期望上讲,在拥有10000个磁盘的存储集群上,平均每天会有1个磁盘出故
障。
为了减少系统的故障率,第一反应通常都是增加单个硬件的冗余度,例如:磁盘可以组建
RAID,服务器可能有双路电源和热插拔CPU,数据中心可能有电池和柴油发电机作为后备电
源,某个组件挂掉时冗余组件可以立刻接管。这种方法虽然不能完全防止由硬件问题导致的
系统失效,但它简单易懂,通常也足以让机器不间断运行很多年。
直到最近,硬件冗余对于大多数应用来说已经足够了,它使单台机器完全失效变得相当罕
见。只要你能快速地把备份恢复到新机器上,故障停机时间对大多数应用而言都算不上灾难
性的。只有少量高可用性至关重要的应用才会要求有多套硬件冗余。
但是随着数据量和应用计算需求的增加,越来越多的应用开始大量使用机器,这会相应地增
加硬件故障率。此外在一些云平台(如亚马逊网络服务(AWS, Amazon Web Services))
中,虚拟机实例不可用却没有任何警告也是很常见的【7】,因为云平台的设计就是优先考虑
灵活性(flexibility)和弹性(elasticity) ,而不是单机可靠性。
如果在硬件冗余的基础上进一步引入软件容错机制,那么系统在容忍整个(单台)机器故障
的道路上就更进一步了。这样的系统也有运维上的便利,例如:如果需要重启机器(例如应
用操作系统安全补丁),单服务器系统就需要计划停机。而允许机器失效的系统则可以一次
修复一个节点,无需整个系统停机。
. 在应对负载的方法一节定义 ↩
软件错误
我们通常认为硬件故障是随机的、相互独立的:一台机器的磁盘失效并不意味着另一台机器
的磁盘也会失效。大量硬件组件不可能同时发生故障,除非它们存在比较弱的相关性(同样
的原因导致关联性错误,例如服务器机架的温度)。
另一类错误是内部的系统性错误(systematic error)【7】。这类错误难以预料,而且因为
是跨节点相关的,所以比起不相关的硬件故障往往可能造成更多的系统失效【5】。例子包
括:
接受特定的错误输入,便导致所有应用服务器实例崩溃的BUG。例如2012年6月30日的
闰秒,由于Linux内核中的一个错误,许多应用同时挂掉了。
失控进程会占用一些共享资源,包括CPU时间、内存、磁盘空间或网络带宽。
系统依赖的服务变慢,没有响应,或者开始返回错误的响应。
级联故障,一个组件中的小故障触发另一个组件中的故障,进而触发更多的故障
i
i
第一章:可靠性、可扩展性、可维护性
17


【10】。
导致这类软件故障的BUG通常会潜伏很长时间,直到被异常情况触发为止。这种情况意味着
软件对其环境做出了某种假设——虽然这种假设通常来说是正确的,但由于某种原因最后不
再成立了【11】。
虽然软件中的系统性故障没有速效药,但我们还是有很多小办法,例如:仔细考虑系统中的
假设和交互;彻底的测试;进程隔离;允许进程崩溃并重启;测量、监控并分析生产环境中
的系统行为。如果系统能够提供一些保证(例如在一个消息队列中,进入与发出的消息数量
相等),那么系统就可以在运行时不断自检,并在出现差异(discrepancy)时报警
【12】。
人为错误
设计并构建了软件系统的工程师是人类,维持系统运行的运维也是人类。即使他们怀有最大
的善意,人类也是不可靠的。举个例子,一项关于大型互联网服务的研究发现,运维配置错
误是导致服务中断的首要原因,而硬件故障(服务器或网络)仅导致了10-25%的服务中断
【13】。
尽管人类不可靠,但怎么做才能让系统变得可靠?最好的系统会组合使用以下几种办法:
以最小化犯错机会的方式设计系统。例如,精心设计的抽象、API和管理后台使做对事情
更容易,搞砸事情更困难。但如果接口限制太多,人们就会忽略它们的好处而想办法绕
开。很难正确把握这种微妙的平衡。
将人们最容易犯错的地方与可能导致失效的地方解耦(decouple)。特别是提供一个功
能齐全的非生产环境沙箱(sandbox),使人们可以在不影响真实用户的情况下,使用
真实数据安全地探索和实验。
在各个层次进行彻底的测试【3】,从单元测试、全系统集成测试到手动测试。自动化测
试易于理解,已经被广泛使用,特别适合用来覆盖正常情况中少见的边缘场景(corner
case)。
允许从人为错误中简单快速地恢复,以最大限度地减少失效情况带来的影响。 例如,快
速回滚配置变更,分批发布新代码(以便任何意外错误只影响一小部分用户),并提供
数据重算工具(以备旧的计算出错)。
配置详细和明确的监控,比如性能指标和错误率。 在其他工程学科中这指的是遥测
(telemetry)。 (一旦火箭离开了地面,遥测技术对于跟踪发生的事情和理解失败是至
关重要的。)监控可以向我们发出预警信号,并允许我们检查是否有任何地方违反了假
设和约束。当出现问题时,指标数据对于问题诊断是非常宝贵的。
良好的管理实践与充分的培训——一个复杂而重要的方面,但超出了本书的范围。
可靠性有多重要?
第一章:可靠性、可扩展性、可维护性
18


可靠性不仅仅是针对核电站和空中交通管制软件而言,我们也期望更多平凡的应用能可靠地
运行。商务应用中的错误会导致生产力损失(也许数据报告不完整还会有法律风险),而电
商网站的中断则可能会导致收入和声誉的巨大损失。
即使在“非关键”应用中,我们也对用户负有责任。试想一位家长把所有的照片和孩子的视频
储存在你的照片应用里【15】。如果数据库突然损坏,他们会感觉如何?他们可能会知道如
何从备份恢复吗?
在某些情况下,我们可能会选择牺牲可靠性来降低开发成本(例如为未经证实的市场开发产
品原型)或运营成本(例如利润率极低的服务),但我们偷工减料时,应该清楚意识到自己
在做什么。
可扩展性
系统今天能可靠运行,并不意味未来也能可靠运行。服务降级(degradation)的一个常见
原因是负载增加,例如:系统负载已经从一万个并发用户增长到十万个并发用户,或者从一
百万增长到一千万。也许现在处理的数据量级要比过去大得多。
可扩展性(Scalability)是用来描述系统应对负载增长能力的术语。但是请注意,这不是贴
在系统上的一维标签:说“X可扩展”或“Y不可扩展”是没有任何意义的。相反,讨论可扩展性意
味着考虑诸如“如果系统以特定方式增长,有什么选项可以应对增长?”和“如何增加计算资源
来处理额外的负载?”等问题。
描述负载
在讨论增长问题(如果负载加倍会发生什么?)前,首先要能简要描述系统的当前负载。负
载可以用一些称为负载参数(load parameters)的数字来描述。参数的最佳选择取决于系统
架构,它可能是每秒向Web服务器发出的请求、数据库中的读写比率、聊天室中同时活跃的
用户数量、缓存命中率或其他东西。除此之外,也许平均情况对你很重要,也许你的瓶颈是
少数极端场景。
为了使这个概念更加具体,我们以推特在2012年11月发布的数据【16】为例。推特的两个主
要业务是:
发布推文
用户可以向其粉丝发布新消息(平均 4.6k请求/秒,峰值超过 12k请求/秒)。
主页时间线
用户可以查阅他们关注的人发布的推文(300k请求/秒)。
处理每秒12,000次写入(发推文的速率峰值)还是很简单的。然而推特的扩展性挑战并不是
主要来自推特量,而是来自扇出(fan-out)——每个用户关注了很多人,也被很多人关注。
ii
第一章:可靠性、可扩展性、可维护性
19


. 扇出:从电子工程学中借用的术语,它描述了输入连接到另一个门输出的逻辑门数
量。 输出需要提供足够的电流来驱动所有连接的输入。 在事务处理系统中,我们使用它
来描述为了服务一个传入请求而需要执行其他服务的请求数量。 ↩
大体上讲,这一对操作有两种实现方式。
1. 发布推文时,只需将新推文插入全局推文集合即可。当一个用户请求自己的主页时间线
时,首先查找他关注的所有人,查询这些被关注用户发布的推文并按时间顺序合并。在
如图1-2所示的关系型数据库中,可以编写这样的查询:
SELECT tweets.*, users.*
FROM tweets
JOIN users ON tweets.sender_id = users.id
JOIN follows ON follows.followee_id = users.id
WHERE follows.follower_id = current_user
图1-2 推特主页时间线的关系型模式简单实现
2. 为每个用户的主页时间线维护一个缓存,就像每个用户的推文收件箱(图1-3)。 当一个
用户发布推文时,查找所有关注该用户的人,并将新的推文插入到每个主页时间线缓存
中。 因此读取主页时间线的请求开销很小,因为结果已经提前计算好了。
图1-3 用于分发推特至关注者的数据流水线,2012年11月的负载参数【16】
ii
第一章:可靠性、可扩展性、可维护性
20


推特的第一个版本使用了方法1,但系统很难跟上主页时间线查询的负载。所以公司转向了方
法2,方法2的效果更好,因为发推频率比查询主页时间线的频率几乎低了两个数量级,所以
在这种情况下,最好在写入时做更多的工作,而在读取时做更少的工作。
然而方法2的缺点是,发推现在需要大量的额外工作。平均来说,一条推文会发往约75个关
注者,所以每秒4.6k的发推写入,变成了对主页时间线缓存每秒345k的写入。但这个平均值
隐藏了用户粉丝数差异巨大这一现实,一些用户有超过3000万的粉丝,这意味着一条推文就
可能会导致主页时间线缓存的3000万次写入!及时完成这种操作是一个巨大的挑战 —— 推特
尝试在5秒内向粉丝发送推文。
在推特的例子中,每个用户粉丝数的分布(可能按这些用户的发推频率来加权)是探讨可扩
展性的一个关键负载参数,因为它决定了扇出负载。你的应用程序可能具有非常不同的特
征,但可以采用相似的原则来考虑它的负载。
推特轶事的最终转折:现在已经稳健地实现了方法2,推特逐步转向了两种方法的混合。大多
数用户发的推文会被扇出写入其粉丝主页时间线缓存中。但是少数拥有海量粉丝的用户(即
名流)会被排除在外。当用户读取主页时间线时,分别地获取出该用户所关注的每位名流的
推文,再与用户的主页时间线缓存合并,如方法1所示。这种混合方法能始终如一地提供良好
性能。在第12章中我们将重新讨论这个例子,这在覆盖更多技术层面之后。
描述性能
一旦系统的负载被描述好,就可以研究当负载增加会发生什么。我们可以从两种角度来看:
增加负载参数并保持系统资源(CPU、内存、网络带宽等)不变时,系统性能将受到什
么影响?
增加负载参数并希望保持性能不变时,需要增加多少系统资源?
这两个问题都需要性能数据,所以让我们简单地看一下如何描述系统性能。
对于Hadoop这样的批处理系统,通常关心的是吞吐量(throughput),即每秒可以处理的
记录数量,或者在特定规模数据集上运行作业的总时间 。对于在线系统,通常更重要的是服
务的响应时间(response time),即客户端发送请求到接收响应之间的时间。
. 理想情况下,批量作业的运行时间是数据集的大小除以吞吐量。 在实践中由于数据倾
斜(数据不是均匀分布在每个工作进程中),需要等待最慢的任务完成,所以运行时间
往往更长。 ↩
延迟和响应时间
延迟(latency)和响应时间(response time)经常用作同义词,但实际上它们并不一
样。响应时间是客户所看到的,除了实际处理请求的时间(服务时间(service time))
之外,还包括网络延迟和排队延迟。延迟是某个请求等待处理的持续时长,在此期间它
处于休眠(latent)状态,并等待服务【17】。
iii
iii
第一章:可靠性、可扩展性、可维护性
21


即使不断重复发送同样的请求,每次得到的响应时间也都会略有不同。现实世界的系统会处
理各式各样的请求,响应时间可能会有很大差异。因此我们需要将响应时间视为一个可以测
量的数值分布(distribution),而不是单个数值。
在图1-4中,每个灰条表代表一次对服务的请求,其高度表示请求花费了多长时间。大多数请
求是相当快的,但偶尔会出现需要更长的时间的异常值。这也许是因为缓慢的请求实质上开
销更大,例如它们可能会处理更多的数据。但即使(你认为)所有请求都花费相同时间的情
况下,随机的附加延迟也会导致结果变化,例如:上下文切换到后台进程,网络数据包丢失
与TCP重传,垃圾收集暂停,强制从磁盘读取的页面错误,服务器机架中的震动【18】,还
有很多其他原因。
图1-4 展示了一个服务100次请求响应时间的均值与百分位数
通常报表都会展示服务的平均响应时间。 (严格来讲“平均”一词并不指代任何特定公式,但
实际上它通常被理解为算术平均值(arithmetic mean):给定 n 个值,加起来除以 n )。然
而如果你想知道“典型(typical)”响应时间,那么平均值并不是一个非常好的指标,因为它不
能告诉你有多少用户实际上经历了这个延迟。
通常使用百分位点(percentiles)会更好。如果将响应时间列表按最快到最慢排序,那么中
位数(median)就在正中间:举个例子,如果你的响应时间中位数是200毫秒,这意味着一
半请求的返回时间少于200毫秒,另一半比这个要长。
如果想知道典型场景下用户需要等待多长时间,那么中位数是一个好的度量标准:一半用户
请求的响应时间少于响应时间的中位数,另一半服务时间比中位数长。中位数也被称为第50
百分位点,有时缩写为p50。注意中位数是关于单个请求的;如果用户同时发出几个请求(在
一个会话过程中,或者由于一个页面中包含了多个资源),则至少一个请求比中位数慢的概
率远大于50%。
为了弄清异常值有多糟糕,可以看看更高的百分位点,例如第95、99和99.9百分位点(缩写
为p95,p99和p999)。它们意味着95%,99%或99.9%的请求响应时间要比该阈值快,例
如:如果第95百分位点响应时间是1.5秒,则意味着100个请求中的95个响应时间快于1.5秒,
而100个请求中的5个响应时间超过1.5秒。如图1-4所示。
第一章:可靠性、可扩展性、可维护性
22


响应时间的高百分位点(也称为尾部延迟(tail latencies))非常重要,因为它们直接影响
用户的服务体验。例如亚马逊在描述内部服务的响应时间要求时以99.9百分位点为准,即使
它只影响一千个请求中的一个。这是因为请求响应最慢的客户往往也是数据最多的客户,也
可以说是最有价值的客户 —— 因为他们掏钱了【19】。保证网站响应迅速对于保持客户的满
意度非常重要,亚马逊观察到:响应时间增加100毫秒,销售量就减少1%【20】;而另一些
报告说:慢 1 秒钟会让客户满意度指标减少16%【21,22】。
另一方面,优化第99.99百分位点(一万个请求中最慢的一个)被认为太昂贵了,不能为亚马
逊的目标带来足够好处。减小高百分位点处的响应时间相当困难,因为它很容易受到随机事
件的影响,这超出了控制范围,而且效益也很小。
百分位点通常用于服务级别目标(SLO, service level objectives)和服务级别协议(SLA,
service level agreements),即定义服务预期性能和可用性的合同。 SLA可能会声明,如
果服务响应时间的中位数小于200毫秒,且99.9百分位点低于1秒,则认为服务工作正常(如
果响应时间更长,就认为服务不达标)。这些指标为客户设定了期望值,并允许客户在SLA未
达标的情况下要求退款。
排队延迟(queueing delay)通常占了高百分位点处响应时间的很大一部分。由于服务器只
能并行处理少量的事务(如受其CPU核数的限制),所以只要有少量缓慢的请求就能阻碍后
续请求的处理,这种效应有时被称为头部阻塞(head-of-line blocking)。即使后续请求在
服务器上处理的非常迅速,由于需要等待先前请求完成,客户端最终看到的是缓慢的总体响
应时间。因为存在这种效应,测量客户端的响应时间非常重要。
为测试系统的可扩展性而人为产生负载时,产生负载的客户端要独立于响应时间不断发送请
求。如果客户端在发送下一个请求之前等待先前的请求完成,这种行为会产生人为排队的效
果,使得测试时的队列比现实情况更短,使测量结果产生偏差【23】。
第一章:可靠性、可扩展性、可维护性
23


实践中的百分位点
在多重调用的后端服务里,高百分位数变得特别重要。即使并行调用,最终用户请求仍
然需要等待最慢的并行呼叫完成。如图1-5所示,只需要一个缓慢的呼叫就可以使整个最
终用户请求变慢。即使只有一小部分后端呼叫速度较慢,如果最终用户请求需要多个后
端调用,则获得较慢调用的机会也会增加,因此较高比例的最终用户请求速度会变慢
(效果称为尾部延迟放大【24】)。
如果您想将响应时间百分点添加到您的服务的监视仪表板,则需要持续有效地计算它
们。例如,您可能希望在最近10分钟内保持请求响应时间的滚动窗口。每一分钟,您都
会计算出该窗口中的中值和各种百分数,并将这些度量值绘制在图上。
简单的实现是在时间窗口内保存所有请求的响应时间列表,并且每分钟对列表进行排
序。如果对你来说效率太低,那么有一些算法能够以最小的CPU和内存成本(如前向衰
减【25】,t-digest【26】或HdrHistogram 【27】)来计算百分位数的近似值。请注
意,平均百分比(例如,减少时间分辨率或合并来自多台机器的数据)在数学上没有意
义 - 聚合响应时间数据的正确方法是添加直方图【28】。
图1-5 当一个请求需要多个后端请求时,单个后端慢请求就会拖慢整个终端用户的请求
应对负载的方法
现在我们已经讨论了用于描述负载的参数和用于衡量性能的指标。可以开始认真讨论可扩展
性了:当负载参数增加时,如何保持良好的性能?
适应某个级别负载的架构不太可能应付10倍于此的负载。如果你正在开发一个快速增长的服
务,那么每次负载发生数量级的增长时,你可能都需要重新考虑架构——或者更频繁。
第一章:可靠性、可扩展性、可维护性
24


人们经常讨论纵向扩展(scaling up)(垂直扩展(vertical scaling),转向更强大的机
器)和横向扩展(scaling out)(水平扩展(horizontal scaling),将负载分布到多台小机
器上)之间的对立。跨多台机器分配负载也称为“无共享(shared-nothing)”架构。可以在单
台机器上运行的系统通常更简单,但高端机器可能非常贵,所以非常密集的负载通常无法避
免地需要横向扩展。现实世界中的优秀架构需要将这两种方法务实地结合,因为使用几台足
够强大的机器可能比使用大量的小型虚拟机更简单也更便宜。
有些系统是弹性(elastic)的,这意味着可以在检测到负载增加时自动增加计算资源,而其
他系统则是手动扩展(人工分析容量并决定向系统添加更多的机器)。如果负载极难预测
(highly unpredictable),则弹性系统可能很有用,但手动扩展系统更简单,并且意外操作
可能会更少(参阅“重新平衡分区”)。
跨多台机器部署无状态服务(stateless services)非常简单,但将带状态的数据系统从单节
点变为分布式配置则可能引入许多额外复杂度。出于这个原因,常识告诉我们应该将数据库
放在单个节点上(纵向扩展),直到扩展成本或可用性需求迫使其改为分布式。
随着分布式系统的工具和抽象越来越好,至少对于某些类型的应用而言,这种常识可能会改
变。可以预见分布式数据系统将成为未来的默认设置,即使对不处理大量数据或流量的场景
也如此。本书的其余部分将介绍多种分布式数据系统,不仅讨论它们在可扩展性方面的表
现,还包括易用性和可维护性。
大规模的系统架构通常是应用特定的—— 没有一招鲜吃遍天的通用可扩展架构(不正式的叫
法:万金油(magic scaling sauce) )。应用的问题可能是读取量、写入量、要存储的数
据量、数据的复杂度、响应时间要求、访问模式或者所有问题的大杂烩。
举个例子,用于处理每秒十万个请求(每个大小为1 kB)的系统与用于处理每分钟3个请求
(每个大小为2GB)的系统看上去会非常不一样,尽管两个系统有同样的数据吞吐量。
一个良好适配应用的可扩展架构,是围绕着假设(assumption)建立的:哪些操作是常见
的?哪些操作是罕见的?这就是所谓负载参数。如果假设最终是错误的,那么为扩展所做的
工程投入就白费了,最糟糕的是适得其反。在早期创业公司或非正式产品中,通常支持产品
快速迭代的能力,要比可扩展至未来的假想负载要重要的多。
尽管这些架构是应用程序特定的,但可扩展的架构通常也是从通用的积木块搭建而成的,并
以常见的模式排列。在本书中,我们将讨论这些构件和模式。
可维护性
众所周知,软件的大部分开销并不在最初的开发阶段,而是在持续的维护阶段,包括修复漏
洞、保持系统正常运行、调查失效、适配新的平台、为新的场景进行修改、偿还技术债、添
加新的功能等等。
第一章:可靠性、可扩展性、可维护性
25


不幸的是,许多从事软件系统行业的人不喜欢维护所谓的遗留(legacy)系统,——也许因
为涉及修复其他人的错误、和过时的平台打交道,或者系统被迫使用于一些份外工作。每一
个遗留系统都以自己的方式让人不爽,所以很难给出一个通用的建议来和它们打交道。
但是我们可以,也应该以这样一种方式来设计软件:在设计之初就尽量考虑尽可能减少维护
期间的痛苦,从而避免自己的软件系统变成遗留系统。为此,我们将特别关注软件系统的三
个设计原则:
可操作性(Operability)
便于运维团队保持系统平稳运行。
简单性(Simplicity)
从系统中消除尽可能多的复杂度(complexity),使新工程师也能轻松理解系统。(注意这
和用户接口的简单性不一样。)
可演化性(evolability)
使工程师在未来能轻松地对系统进行更改,当需求变化时为新应用场景做适配。也称为可扩
展性(extensibility),可修改性(modifiability)或可塑性(plasticity)。
和之前提到的可靠性、可扩展性一样,实现这些目标也没有简单的解决方案。不过我们会试
着想象具有可操作性,简单性和可演化性的系统会是什么样子。
可操作性:人生苦短,关爱运维
有人认为,“良好的运维经常可以绕开垃圾(或不完整)软件的局限性,而再好的软件摊上垃
圾运维也没法可靠运行”。尽管运维的某些方面可以,而且应该是自动化的,但在最初建立正
确运作的自动化机制仍然取决于人。
运维团队对于保持软件系统顺利运行至关重要。一个优秀运维团队的典型职责如下(或者更
多)【29】:
监控系统的运行状况,并在服务状态不佳时快速恢复服务
跟踪问题的原因,例如系统故障或性能下降
及时更新软件和平台,比如安全补丁
了解系统间的相互作用,以便在异常变更造成损失前进行规避。
预测未来的问题,并在问题出现之前加以解决(例如,容量规划)
建立部署,配置、管理方面的良好实践,编写相应工具
执行复杂的维护任务,例如将应用程序从一个平台迁移到另一个平台
当配置变更时,维持系统的安全性
定义工作流程,使运维操作可预测,并保持生产环境稳定。
铁打的营盘流水的兵,维持组织对系统的了解。
第一章:可靠性、可扩展性、可维护性
26


良好的可操作性意味着更轻松的日常工作,进而运维团队能专注于高价值的事情。数据系统
可以通过各种方式使日常任务更轻松:
通过良好的监控,提供对系统内部状态和运行时行为的可见性(visibility)
为自动化提供良好支持,将系统与标准化工具相集成
避免依赖单台机器(在整个系统继续不间断运行的情况下允许机器停机维护)
提供良好的文档和易于理解的操作模型(“如果做X,会发生Y”)
提供良好的默认行为,但需要时也允许管理员自由覆盖默认值
有条件时进行自我修复,但需要时也允许管理员手动控制系统状态
行为可预测,最大限度减少意外
简单性:管理复杂度
小型软件项目可以使用简单讨喜的、富表现力的代码,但随着项目越来越大,代码往往变得
非常复杂,难以理解。这种复杂度拖慢了所有系统相关人员,进一步增加了维护成本。一个
陷入复杂泥潭的软件项目有时被描述为烂泥潭(a big ball of mud)【30】。
复杂度(complexity)有各种可能的症状,例如:状态空间激增、模块间紧密耦合、纠结的
依赖关系、不一致的命名和术语、解决性能问题的Hack、需要绕开的特例等等,现在已经有
很多关于这个话题的讨论【31,32,33】。
因为复杂度导致维护困难时,预算和时间安排通常会超支。在复杂的软件中进行变更,引入
错误的风险也更大:当开发人员难以理解系统时,隐藏的假设、无意的后果和意外的交互就
更容易被忽略。相反,降低复杂度能极大地提高软件的可维护性,因此简单性应该是构建系
统的一个关键目标。
简化系统并不一定意味着减少功能;它也可以意味着消除额外的(accidental)的复杂度。
Moseley和Marks【32】把额外复杂度定义为:由具体实现中涌现,而非(从用户视角看,系
统所解决的)问题本身固有的复杂度。
用于消除额外复杂度的最好工具之一是抽象(abstraction)。一个好的抽象可以将大量实现
细节隐藏在一个干净,简单易懂的外观下面。一个好的抽象也可以广泛用于各类不同应用。
比起重复造很多轮子,重用抽象不仅更有效率,而且有助于开发高质量的软件。抽象组件的
质量改进将使所有使用它的应用受益。
例如,高级编程语言是一种抽象,隐藏了机器码、CPU寄存器和系统调用。 SQL也是一种抽
象,隐藏了复杂的磁盘/内存数据结构、来自其他客户端的并发请求、崩溃后的不一致性。当
然在用高级语言编程时,我们仍然用到了机器码;只不过没有直接(directly)使用罢了,正
是因为编程语言的抽象,我们才不必去考虑这些实现细节。
抽象可以帮助我们将系统的复杂度控制在可管理的水平,不过,找到好的抽象是非常困难
的。在分布式系统领域虽然有许多好的算法,但我们并不清楚它们应该打包成什么样抽象。
本书将紧盯那些允许我们将大型系统的部分提取为定义明确的、可重用的组件的优秀抽象。
第一章:可靠性、可扩展性、可维护性
27


可演化性:拥抱变化
系统的需求永远不变,基本是不可能的。更可能的情况是,它们处于常态的变化中,例如:
你了解了新的事实、出现意想不到的应用场景、业务优先级发生变化、用户要求新功能、新
平台取代旧平台、法律或监管要求发生变化、系统增长迫使架构变化等。
在组织流程方面,敏捷(agile)工作模式为适应变化提供了一个框架。敏捷社区还开发了对
在频繁变化的环境中开发软件很有帮助的技术工具和模式,如测试驱动开发(TDD, test
driven development)和重构(refactoring)。
这些敏捷技术的大部分讨论都集中在相当小的规模(同一个应用中的几个代码文件)。本书
将探索在更大数据系统层面上提高敏捷性的方法,可能由几个不同的应用或服务组成。例
如,为了将装配主页时间线的方法从方法1变为方法2,你会如何“重构”推特的架构 ?
修改数据系统并使其适应不断变化需求的容易程度,是与简单性和抽象性密切相关的:简单
易懂的系统通常比复杂系统更容易修改。但由于这是一个非常重要的概念,我们将用一个不
同的词来指代数据系统层面的敏捷性:可演化性(evolvability)【34】。
本章小结
本章探讨了一些关于数据密集型应用的基本思考方式。这些原则将指导我们阅读本书的其余
部分,那里将会深入技术细节。
一个应用必须满足各种需求才称得上有用。有一些功能需求(functional requirements)
(它应该做什么,比如允许以各种方式存储,检索,搜索和处理数据)以及一些非功能性需
求(nonfunctional )(通用属性,例如安全性,可靠性,合规性,可扩展性,兼容性和可维
护性)。在本章详细讨论了可靠性,可扩展性和可维护性。
可靠性(Reliability)意味着即使发生故障,系统也能正常工作。故障可能发生在硬件(通
常是随机的和不相关的),软件(通常是系统性的Bug,很难处理),和人类(不可避免地时
不时出错)。容错技术可以对终端用户隐藏某些类型的故障。
可扩展性(Scalability)意味着即使在负载增加的情况下也有保持性能的策略。为了讨论可
扩展性,我们首先需要定量描述负载和性能的方法。我们简要了解了推特主页时间线的例
子,介绍描述负载的方法,并将响应时间百分位点作为衡量性能的一种方式。在可扩展的系
统中可以添加处理容量(processing capacity)以在高负载下保持可靠。
可维护性(Maintainability)有许多方面,但实质上是关于工程师和运维团队的生活质量
的。良好的抽象可以帮助降低复杂度,并使系统易于修改和适应新的应用场景。良好的可操
作性意味着对系统的健康状态具有良好的可见性,并拥有有效的管理手段。
第一章:可靠性、可扩展性、可维护性
28


不幸的是,使应用可靠、可扩展或可维护并不容易。但是某些模式和技术会不断重新出现在
不同的应用中。在接下来的几章中,我们将看到一些数据系统的例子,并分析它们如何实现
这些目标。
在本书后面的第三部分中,我们将看到一种模式:几个组件协同工作以构成一个完整的系统
(如图1-1中的例子)
参考文献
1. Michael Stonebraker and Uğur Çetintemel: “'One Size Fits All': An Idea Whose Time
Has Come and Gone,” at 21st International Conference on Data Engineering (ICDE),
April 2005.
2. Walter L. Heimerdinger and Charles B. Weinstock: “A Conceptual Framework for
System Fault Tolerance,” Technical Report CMU/SEI-92-TR-033, Software Engineering
Institute, Carnegie Mellon University, October 1992.
3. Ding Yuan, Yu Luo, Xin Zhuang, et al.: “Simple Testing Can Prevent Most Critical
Failures: An Analysis of Production Failures in Distributed Data-Intensive Systems,” at
11th USENIX Symposium on Operating Systems Design and Implementation (OSDI),
October 2014.
4. Yury Izrailevsky and Ariel Tseitlin: “The Netflix Simian Army,” techblog.netflix.com, July
19, 2011.
5. Daniel Ford, François Labelle, Florentina I. Popovici, et al.: “Availability in Globally
Distributed Storage Systems,” at 9th USENIX Symposium on Operating Systems
Design and Implementation (OSDI), October 2010.
6. Brian Beach: “Hard Drive Reliability Update – Sep 2014,” backblaze.com, September
23, 2014.
7. Laurie Voss: “AWS: The Good, the Bad and the Ugly,” blog.awe.sm, December 18,
2012.
8. Haryadi S. Gunawi, Mingzhe Hao, Tanakorn Leesatapornwongsa, et al.: “What Bugs
Live in the Cloud?,” at 5th ACM Symposium on Cloud Computing (SoCC), November
2014. doi:10.1145/2670979.2670986
9. Nelson Minar: “Leap Second Crashes Half the Internet,” somebits.com, July 3, 2012.
10. Amazon Web Services: “Summary of the Amazon EC2 and Amazon RDS Service
Disruption in the US East Region,” aws.amazon.com, April 29, 2011.
第一章:可靠性、可扩展性、可维护性
29


11. Richard I. Cook: “How Complex Systems Fail,” Cognitive Technologies Laboratory, April
2000.
12. Jay Kreps: “Getting Real About Distributed System Reliability,” blog.empathybox.com,
March 19, 2012.
13. David Oppenheimer, Archana Ganapathi, and David A. Patterson: “Why Do Internet
Services Fail, and What Can Be Done About It?,” at 4th USENIX Symposium on
Internet Technologies and Systems (USITS), March 2003.
14. Nathan Marz: “Principles of Software Engineering, Part 1,” nathanmarz.com, April 2,
2013.
15. Michael Jurewitz:“The Human Impact of Bugs,” jury.me, March 15, 2013.
16. Raffi Krikorian: “Timelines at Scale,” at QCon San Francisco, November 2012.
17. Martin Fowler: Patterns of Enterprise Application Architecture. Addison Wesley, 2002.
ISBN: 978-0-321-12742-6
18. Kelly Sommers: “After all that run around, what caused 500ms disk latency even when
we replaced physical server?” twitter.com, November 13, 2014.
19. Giuseppe DeCandia, Deniz Hastorun, Madan Jampani, et al.: “Dynamo: Amazon's
Highly Available Key-Value Store,” at 21st ACM Symposium on Operating Systems
Principles (SOSP), October 2007.
20. Greg Linden: “Make Data Useful,” slides from presentation at Stanford University Data
Mining class (CS345), December 2006.
21. Tammy Everts: “The Real Cost of Slow Time vs Downtime,” webperformancetoday.com,
November 12, 2014.
22. Jake Brutlag:“Speed Matters for Google Web Search,” googleresearch.blogspot.co.uk,
June 22, 2009.
23. Tyler Treat: “Everything You Know About Latency Is Wrong,” bravenewgeek.com,
December 12, 2015.
24. Jeffrey Dean and Luiz André Barroso: “The Tail at Scale,” Communications of the ACM,
volume 56, number 2, pages 74–80, February 2013. doi:10.1145/2408776.2408794
25. Graham Cormode, Vladislav Shkapenyuk, Divesh Srivastava, and Bojian Xu: “Forward
Decay: A Practical Time Decay Model for Streaming Systems,” at 25th IEEE
International Conference on Data Engineering (ICDE), March 2009.
第一章:可靠性、可扩展性、可维护性
30


26. Ted Dunning and Otmar Ertl: “Computing Extremely Accurate Quantiles Using t
Digests,” github.com, March 2014.
27. Gil Tene: “HdrHistogram,” hdrhistogram.org.
28. Baron Schwartz: “Why Percentiles Don’t Work the Way You Think,” vividcortex.com,
December 7, 2015.
29. James Hamilton: “On Designing and Deploying Internet-Scale Services,” at 21st Large
Installation System Administration Conference (LISA), November 2007.
30. Brian Foote and Joseph Yoder: “Big Ball of Mud,” at 4th Conference on Pattern
Languages of Programs (PLoP), September 1997.
31. Frederick P Brooks: “No Silver Bullet – Essence and Accident in Software Engineering,”
in The Mythical Man-Month, Anniversary edition, Addison-Wesley, 1995. ISBN: 978-0
201-83595-3
32. Ben Moseley and Peter Marks: “Out of the Tar Pit,” at BCS Software Practice
Advancement (SPA), 2006.
33. Rich Hickey: “Simple Made Easy,” at Strange Loop, September 2011.
34. Hongyu Pei Breivold, Ivica Crnkovic, and Peter J. Eriksson: “Analyzing Software
Evolvability,” at 32nd Annual IEEE International Computer Software and Applications
Conference (COMPSAC), July 2008. doi:10.1109/COMPSAC.2008.50
上一章 目录 下一章
第一部分:数据系统基础 设计数据密集型应用 第二章:数据模型与查询语言
第一章:可靠性、可扩展性、可维护性
31


2. 数据模型与查询语言
语言的边界就是思想的边界。
—— 路德维奇·维特根斯坦,《逻辑哲学》(1922)
[TOC]
数据模型可能是软件开发中最重要的部分了,因为它们的影响如此深远:不仅仅影响着软件
的编写方式,而且影响着我们的解题思路。
多数应用使用层层叠加的数据模型构建。对于每层数据模型的关键问题是:它是如何用低一
层数据模型来表示的?例如:
1. 作为一名应用开发人员,你观察现实世界(里面有人员,组织,货物,行为,资金流
向,传感器等),并采用对象或数据结构,以及操控那些数据结构的API来进行建模。那
些结构通常是特定于应用程序的。
2. 当要存储那些数据结构时,你可以利用通用数据模型来表示它们,如JSON或XML文档,
关系数据库中的表、或图模型。
3. 数据库软件的工程师选定如何以内存、磁盘或网络上的字节来表示JSON/XML/关系/图数
第二章:数据模型与查询语言
32


据。这类表示形式使数据有可能以各种方式来查询,搜索,操纵和处理。
4. 在更低的层次上,硬件工程师已经想出了使用电流,光脉冲,磁场或者其他东西来表示
字节的方法。
一个复杂的应用程序可能会有更多的中间层次,比如基于API的API,不过基本思想仍然是一
样的:每个层都通过提供一个明确的数据模型来隐藏更低层次中的复杂性。这些抽象允许不
同的人群有效地协作(例如数据库厂商的工程师和使用数据库的应用程序开发人员)。
数据模型种类繁多,每个数据模型都带有如何使用的设想。有些用法很容易,有些则不支持
如此;有些操作运行很快,有些则表现很差;有些数据转换非常自然,有些则很麻烦。
掌握一个数据模型需要花费很多精力(想想关系数据建模有多少本书)。即便只使用一个数
据模型,不用操心其内部工作机制,构建软件也是非常困难的。然而,因为数据模型对上层
软件的功能(能做什么,不能做什么)有着至深的影响,所以选择一个适合的数据模型是非
常重要的。
在本章中,我们将研究一系列用于数据存储和查询的通用数据模型(前面列表中的第2点)。
特别地,我们将比较关系模型,文档模型和少量基于图形的数据模型。我们还将查看各种查
询语言并比较它们的用例。在第3章中,我们将讨论存储引擎是如何工作的。也就是说,这些
数据模型实际上是如何实现的(列表中的第3点)。
关系模型与文档模型
现在最著名的数据模型可能是SQL。它基于Edgar Codd在1970年提出的关系模型【1】:数
据被组织成关系(SQL中称作表),其中每个关系是元组(SQL中称作行)的无序集合。
关系模型曾是一个理论性的提议,当时很多人都怀疑是否能够有效实现它。然而到了20世纪
80年代中期,关系数据库管理系统(RDBMSes)和SQL已成为大多数人们存储和查询某些常
规结构的数据的首选工具。关系数据库已经持续称霸了大约25~30年——这对计算机史来说是
极其漫长的时间。
关系数据库起源于商业数据处理,在20世纪60年代和70年代用大型计算机来执行。从今天的
角度来看,那些用例显得很平常:典型的事务处理(将销售或银行交易,航空公司预订,库
存管理信息记录在库)和批处理(客户发票,工资单,报告)。
当时的其他数据库迫使应用程序开发人员必须考虑数据库内部的数据表示形式。关系模型致
力于将上述实现细节隐藏在更简洁的接口之后。
多年来,在数据存储和查询方面存在着许多相互竞争的方法。在20世纪70年代和80年代初,
网络模型和分层模型曾是主要的选择,但关系模型随后占据了主导地位。对象数据库在20世
纪80年代末和90年代初来了又去。XML数据库在二十一世纪初出现,但只有小众采用过。关
系模型的每个竞争者都在其时代产生了大量的炒作,但从来没有持续【2】。
第二章:数据模型与查询语言
33


随着电脑越来越强大和互联,它们开始用于日益多样化的目的。关系数据库非常成功地被推
广到业务数据处理的原始范围之外更为广泛的用例上。你今天在网上看到的大部分内容依旧
是由关系数据库来提供支持,无论是在线发布,讨论,社交网络,电子商务,游戏,软件即
服务生产力应用程序等等内容。
NoSQL的诞生
现在 - 2010年代,NoSQL开始了最新一轮尝试,试图推翻关系模型的统治地位。“NoSQL”这
个名字让人遗憾,因为实际上它并没有涉及到任何特定的技术。最初它只是作为一个醒目的
Twitter标签,用在2009年一个关于分布式,非关系数据库上的开源聚会上。无论如何,这个
术语触动了某些神经,并迅速在网络创业社区内外传播开来。好些有趣的数据库系统现在都
与#NoSQL#标签相关联,并且NoSQL被追溯性地重新解释为不仅是SQL(Not Only SQL)
【4】。
采用NoSQL数据库的背后有几个驱动因素,其中包括:
需要比关系数据库更好的可扩展性,包括非常大的数据集或非常高的写入吞吐量
相比商业数据库产品,免费和开源软件更受偏爱。
关系模型不能很好地支持一些特殊的查询操作
受挫于关系模型的限制性,渴望一种更具多动态性与表现力的数据模型【5】
不同的应用程序有不同的需求,一个用例的最佳技术选择可能不同于另一个用例的最佳技术
选择。因此,在可预见的未来,关系数据库似乎可能会继续与各种非关系数据库一起使用 - 这
种想法有时也被称为混合持久化(polyglot persistence)
对象关系不匹配
目前大多数应用程序开发都使用面向对象的编程语言来开发,这导致了对SQL数据模型的普
遍批评:如果数据存储在关系表中,那么需要一个笨拙的转换层,处于应用程序代码中的对
象和表,行,列的数据库模型之间。模型之间的不连贯有时被称为阻抗不匹配(impedance
mismatch) 。
. 一个从电子学借用的术语。每个电路的输入和输出都有一定的阻抗(交流电阻)。当你
将一个电路的输出连接到另一个电路的输入时,如果两个电路的输出和输入阻抗匹配,
则连接上的功率传输将被最大化。阻抗不匹配会导致信号反射及其他问题。 ↩
像ActiveRecord和Hibernate这样的对象关系映射(object-relational mapping, ORM)框架
可以减少这个转换层所需的样板代码的数量,但是它们不能完全隐藏这两个模型之间的差
异。
i
i
第二章:数据模型与查询语言
34


图2-1 使用关系型模式来表示领英简介
例如,图2-1展示了如何在关系模式中表示简历(一个LinkedIn简介)。整个简介可以通过一
个唯一的标识符 user_id 来标识。像 first_name 和 last_name 这样的字段每个用户只出现一
次,所以可以在User表上将其建模为列。但是,大多数人在职业生涯中拥有多于一份的工
作,人们可能有不同样的教育阶段和任意数量的联系信息。从用户到这些项目之间存在一对
多的关系,可以用多种方式来表示:
传统SQL模型(SQL:1999之前)中,最常见的规范化表示形式是将职位,教育和联系
信息放在单独的表中,对User表提供外键引用,如图2-1所示。
后续的SQL标准增加了对结构化数据类型和XML数据的支持;这允许将多值数据存储在单
行内,并支持在这些文档内查询和索引。这些功能在Oracle,IBM DB2,MS SQL Server
和PostgreSQL中都有不同程度的支持【6,7】。JSON数据类型也得到多个数据库的支
持,包括IBM DB2,MySQL和PostgreSQL 【8】。
第三种选择是将职业,教育和联系信息编码为JSON或XML文档,将其存储在数据库的文
本列中,并让应用程序解析其结构和内容。这种配置下,通常不能使用数据库来查询该
编码列中的值。
第二章:数据模型与查询语言
35


对于一个像简历这样自包含文档的数据结构而言,JSON表示是非常合适的:参见例2-1。
JSON比XML更简单。面向文档的数据库(如MongoDB 【9】,RethinkDB 【10】,
CouchDB 【11】和Espresso【12】)支持这种数据模型。 例2-1. 用JSON文档表示一个
LinkedIn简介
{
"user_id": 251,
"first_name": "Bill",
"last_name": "Gates",
"summary": "Co-chair of the Bill & Melinda Gates... Active blogger.",
"region_id": "us:91",
"industry_id": 131,
"photo_url": "/p/7/000/253/05b/308dd6e.jpg",
"positions": [
{
"job_title": "Co-chair",
"organization": "Bill & Melinda Gates Foundation"
},
{
"job_title": "Co-founder, Chairman",
"organization": "Microsoft"
}
],
"education": [
{
"school_name": "Harvard University",
"start": 1973,
"end": 1975
},
{
"school_name": "Lakeside School, Seattle",
"start": null,
"end": null
}
],
"contact_info": {
"blog": "http://thegatesnotes.com",
"twitter": "http://twitter.com/BillGates"
}
}
有一些开发人员认为JSON模型减少了应用程序代码和存储层之间的阻抗不匹配。不过,正如
我们将在第4章中看到的那样,JSON作为数据编码格式也存在问题。缺乏一个模式往往被认
为是一个优势;我们将在“文档模型中的模式灵活性”中讨论这个问题。
JSON表示比图2-1中的多表模式具有更好的局部性(locality)。如果在前面的关系型示例中
获取简介,那需要执行多个查询(通过 user_id 查询每个表),或者在User表与其下属表之
间混乱地执行多路连接。而在JSON表示中,所有相关信息都在同一个地方,一个查询就足够
了。
第二章:数据模型与查询语言
36


从用户简介文件到用户职位,教育历史和联系信息,这种一对多关系隐含了数据中的一个树
状结构,而JSON表示使得这个树状结构变得明确(见图2-2)。
图2-2 一对多关系构建了一个树结构
多对一和多对多的关系
在上一节的例2-1中, region_id 和 industry_id 是以ID,而不是纯字符串“Greater Seattle
Area”和“Philanthropy”的形式给出的。为什么?
如果用户界面用一个自由文本字段来输入区域和行业,那么将他们存储为纯文本字符串是合
理的。另一方式是给出地理区域和行业的标准化的列表,并让用户从下拉列表或自动填充器
中进行选择,其优势如下:
各个简介之间样式和拼写统一
避免歧义(例如,如果有几个同名的城市)
易于更新——名称只存储在一个地方,如果需要更改(例如,由于政治事件而改变城市
名称),很容易进行全面更新。
本地化支持——当网站翻译成其他语言时,标准化的列表可以被本地化,使得地区和行
业可以使用用户的语言来显示
更好的搜索——例如,搜索华盛顿州的慈善家就会匹配这份简介,因为地区列表可以编
码记录西雅图在华盛顿这一事实(从“Greater Seattle Area”这个字符串中看不出来)
存储ID还是文本字符串,这是个副本(duplication)问题。当使用ID时,对人类有意义的信
息(比如单词:Philanthropy)只存储在一处,所有引用它的地方使用ID(ID只在数据库中有
意义)。当直接存储文本时,对人类有意义的信息会复制在每处使用记录中。
使用ID的好处是,ID对人类没有任何意义,因而永远不需要改变:ID可以保持不变,即使它
标识的信息发生变化。任何对人类有意义的东西都可能需要在将来某个时候改变——如果这
些信息被复制,所有的冗余副本都需要更新。这会导致写入开销,也存在不一致的风险(一
第二章:数据模型与查询语言
37


些副本被更新了,还有些副本没有被更新)。去除此类重复是数据库规范化
(normalization)的关键思想。
. 关于关系模型的文献区分了几种不同的规范形式,但这些区别几乎没有实际意义。一
个经验法则是,如果重复存储了可以存储在一个地方的值,则模式就不是规范化
(normalized)的。 ↩
数据库管理员和开发人员喜欢争论规范化和非规范化,让我们暂时保留判断吧。在本书
的第三部分,我们将回到这个话题,探讨系统的方法用以处理缓存,非规范化和派生数
据。
不幸的是,对这些数据进行规范化需要多对一的关系(许多人生活在一个特定的地区,许多
人在一个特定的行业工作),这与文档模型不太吻合。在关系数据库中,通过ID来引用其他
表中的行是正常的,因为连接很容易。在文档数据库中,一对多树结构没有必要用连接,对
连接的支持通常很弱 。
. 在撰写本文时,RethinkDB支持连接,MongoDB不支持连接,而CouchDB只支持预先
声明的视图。 ↩
如果数据库本身不支持连接,则必须在应用程序代码中通过对数据库进行多个查询来模拟连
接。(在这种情况中,地区和行业的列表可能很小,改动很少,应用程序可以简单地将其保
存在内存中。不过,执行连接的工作从数据库被转移到应用程序代码上。
此外,即便应用程序的最初版本适合无连接的文档模型,随着功能添加到应用程序中,数据
会变得更加互联。例如,考虑一下对简历例子进行的一些修改:
组织和学校作为实体
在前面的描述中, organization (用户工作的公司)和 school_name (他们学习的地方)只
是字符串。也许他们应该是对实体的引用呢?然后,每个组织,学校或大学都可以拥有自己
的网页(标识,新闻提要等)。每个简历可以链接到它所提到的组织和学校,并且包括他们
的图标和其他信息(参见图2-3,来自LinkedIn的一个例子)。
推荐
假设你想添加一个新的功能:一个用户可以为另一个用户写一个推荐。在用户的简历上显示
推荐,并附上推荐用户的姓名和照片。如果推荐人更新他们的照片,那他们写的任何建议都
需要显示新的照片。因此,推荐应该拥有作者个人简介的引用。
ii
ii
iii
iii
第二章:数据模型与查询语言
38


图2-3 公司名不仅是字符串,还是一个指向公司实体的链接(LinkedIn截图)
图2-4阐明了这些新功能需要如何使用多对多关系。每个虚线矩形内的数据可以分组成一个文
档,但是对单位,学校和其他用户的引用需要表示成引用,并且在查询时需要连接。
图2-4 使用多对多关系扩展简历
文档数据库是否在重蹈覆辙?
第二章:数据模型与查询语言
39


在多对多的关系和连接已常规用在关系数据库时,文档数据库和NoSQL重启了辩论:如何最
好地在数据库中表示多对多关系。那场辩论可比NoSQL古老得多,事实上,最早可以追溯到
计算机化数据库系统。
20世纪70年代最受欢迎的业务数据处理数据库是IBM的信息管理系统(IMS),最初是为了阿
波罗太空计划的库存管理而开发的,并于1968年有了首次商业发布【13】。目前它仍在使用
和维护,运行在IBM大型机的OS/390上【14】。
IMS的设计中使用了一个相当简单的数据模型,称为层次模型(hierarchical model),它与
文档数据库使用的JSON模型有一些惊人的相似之处【2】。它将所有数据表示为嵌套在记录
中的记录树,这很像图2-2的JSON结构。
同文档数据库一样,IMS能良好处理一对多的关系,但是很难应对多对多的关系,并且不支持
连接。开发人员必须决定是否复制(非规范化)数据或手动解决从一个记录到另一个记录的
引用。这些二十世纪六七十年代的问题与现在开发人员遇到的文档数据库问题非常相似
【15】。
那时人们提出了各种不同的解决方案来解决层次模型的局限性。其中最突出的两个是关系模
型(relational model)(它变成了SQL,统治了世界)和网络模型(network model)(最
初很受关注,但最终变得冷门)。这两个阵营之间的“大辩论”在70年代持续了很久时间
【2】。
那两个模式解决的问题与当前的问题相关,因此值得简要回顾一下那场辩论。
网络模型
网络模型由一个称为数据系统语言会议(CODASYL)的委员会进行了标准化,并被数个不同
的数据库商实现;它也被称为CODASYL模型【16】。
CODASYL模型是层次模型的推广。在层次模型的树结构中,每条记录只有一个父节点;在网
络模式中,每条记录可能有多个父节点。例如,“Greater Seattle Area”地区可能是一条记录,
每个居住在该地区的用户都可以与之相关联。这允许对多对一和多对多的关系进行建模。
网络模型中记录之间的链接不是外键,而更像编程语言中的指针(同时仍然存储在磁盘
上)。访问记录的唯一方法是跟随从根记录起沿这些链路所形成的路径。这被称为访问路径
(access path)。
最简单的情况下,访问路径类似遍历链表:从列表头开始,每次查看一条记录,直到找到所
需的记录。但在多对多关系的情况中,数条不同的路径可以到达相同的记录,网络模型的程
序员必须跟踪这些不同的访问路径。
CODASYL中的查询是通过利用遍历记录列和跟随访问路径表在数据库中移动游标来执行的。
如果记录有多个父结点(即多个来自其他记录的传入指针),则应用程序代码必须跟踪所有
的各种关系。甚至CODASYL委员会成员也承认,这就像在n维数据空间中进行导航【17】。
第二章:数据模型与查询语言
40


尽管手动选择访问路径够能最有效地利用20世纪70年代非常有限的硬件功能(如磁带驱动
器,其搜索速度非常慢),但这使得查询和更新数据库的代码变得复杂不灵活。无论是分层
还是网络模型,如果你没有所需数据的路径,就会陷入困境。你可以改变访问路径,但是必
须浏览大量手写数据库查询代码,并重写来处理新的访问路径。更改应用程序的数据模型是
很难的。
关系模型
相比之下,关系模型做的就是将所有的数据放在光天化日之下:一个关系(表)只是一个元
组(行)的集合,仅此而已。如果你想读取数据,它没有迷宫似的嵌套结构,也没有复杂的
访问路径。你可以选中符合任意条件的行,读取表中的任何或所有行。你可以通过指定某些
列作为匹配关键字来读取特定行。你可以在任何表中插入一个新的行,而不必担心与其他表
的外键关系 。
. 外键约束允许对修改约束,但对于关系模型这并不是必选项。即使有约束,外键连接
在查询时执行,而在CODASYL中,连接在插入时高效完成。 ↩
在关系数据库中,查询优化器自动决定查询的哪些部分以哪个顺序执行,以及使用哪些索
引。这些选择实际上是“访问路径”,但最大的区别在于它们是由查询优化器自动生成的,而不
是由程序员生成,所以我们很少需要考虑它们。
如果想按新的方式查询数据,你可以声明一个新的索引,查询会自动使用最合适的那些索
引。无需更改查询来利用新的索引。(请参阅“用于数据的查询语言”。)关系模型因此使添加
应用程序新功能变得更加容易。
关系数据库的查询优化器是复杂的,已耗费了多年的研究和开发精力【18】。关系模型的一
个关键洞察是:只需构建一次查询优化器,随后使用该数据库的所有应用程序都可以从中受
益。如果你没有查询优化器的话,那么为特定查询手动编写访问路径比编写通用优化器更容
易——不过从长期看通用解决方案更好。
与文档数据库相比
在一个方面,文档数据库还原为层次模型:在其父记录中存储嵌套记录(图2-1中的一对多关
系,如 positions , education 和 contact_info ),而不是在单独的表中。
但是,在表示多对一和多对多的关系时,关系数据库和文档数据库并没有根本的不同:在这
两种情况下,相关项目都被一个唯一的标识符引用,这个标识符在关系模型中被称为外键,
在文档模型中称为文档引用【9】。该标识符在读取时通过连接或后续查询来解析。迄今为
止,文档数据库没有走CODASYL的老路。
关系型数据库与文档数据库在今日的对比
iv
iv
第二章:数据模型与查询语言
41


将关系数据库与文档数据库进行比较时,可以考虑许多方面的差异,包括它们的容错属性
(参阅第5章)和处理并发性(参阅第7章)。本章将只关注数据模型中的差异。
支持文档数据模型的主要论据是架构灵活性,因局部性而拥有更好的性能,以及对于某些应
用程序而言更接近于应用程序使用的数据结构。关系模型通过为连接提供更好的支持以及支
持多对一和多对多的关系来反击。
哪个数据模型更方便写代码?
如果应用程序中的数据具有类似文档的结构(即,一对多关系树,通常一次性加载整个
树),那么使用文档模型可能是一个好主意。将类似文档的结构分解成多个表(如图2-1中
的 positions , education 和 contact_info )的关系技术可能导致繁琐的模式和不必要的复
杂的应用程序代码。
文档模型有一定的局限性:例如,不能直接引用文档中的嵌套的项目,而是需要说“用户251
的位置列表中的第二项”(很像分层模型中的访问路径)。但是,只要文件嵌套不太深,这通
常不是问题。
文档数据库对连接的糟糕支持也许或也许不是一个问题,这取决于应用程序。例如,分析应
用程可能永远不需要多对多的关系,如果它使用文档数据库来记录何事发生于何时【19】。
但是,如果你的应用程序确实使用多对多关系,那么文档模型就没有那么吸引人了。通过反
规范化可以减少对连接的需求,但是应用程序代码需要做额外的工作来保持数据的一致性。
通过向数据库发出多个请求,可以在应用程序代码中模拟连接,但是这也将复杂性转移到应
用程序中,并且通常比由数据库内的专用代码执行的连接慢。在这种情况下,使用文档模型
会导致更复杂的应用程序代码和更差的性能【15】。
很难说在一般情况下哪个数据模型让应用程序代码更简单;它取决于数据项之间存在的关系
种类。对于高度相联的数据,选用文档模型是糟糕的,选用关系模型是可接受的,而选用图
形模型(参见“图数据模型”)是最自然的。
文档模型中的架构灵活性
大多数文档数据库以及关系数据库中的JSON支持都不会强制文档中的数据采用何种模式。关
系数据库的XML支持通常带有可选的模式验证。没有模式意味着可以将任意的键和值添加到
文档中,并且当读取时,客户端对无法保证文档可能包含的字段。
文档数据库有时称为无模式(schemaless),但这具有误导性,因为读取数据的代码通常假
定某种结构——即存在隐式模式,但不由数据库强制执行【20】。一个更精确的术语是读时
模式(schema-on-read)(数据的结构是隐含的,只有在数据被读取时才被解释),相应的
是写时模式(schema-on-write)(传统的关系数据库方法中,模式明确,且数据库确保所
有的数据都符合其模式)【21】。
第二章:数据模型与查询语言
42


读时模式类似于编程语言中的动态(运行时)类型检查,而写时模式类似于静态(编译时)
类型检查。就像静态和动态类型检查的相对优点具有很大的争议性一样【22】,数据库中模
式的强制性是一个具有争议的话题,一般来说没有正确或错误的答案。
在应用程序想要改变其数据格式的情况下,这些方法之间的区别尤其明显。例如,假设你把
每个用户的全名存储在一个字段中,而现在想分别存储名字和姓氏【23】。在文档数据库
中,只需开始写入具有新字段的新文档,并在应用程序中使用代码来处理读取旧文档的情
况。例如:
if (user && user.name && !user.first_name) {
// Documents written before Dec 8, 2013 don't have first_name
user.first_name = user.name.split(" ")[0];
}
另一方面,在“静态类型”数据库模式中,通常会执行以下迁移(migration)操作:
ALTER TABLE users ADD COLUMN first_name text;
UPDATE users SET first_name = split_part(name, ' ', 1); -- PostgreSQL
UPDATE users SET first_name = substring_index(name, ' ', 1); -- MySQL
模式变更的速度很慢,而且要求停运。它的这种坏名誉并不是完全应得的:大多数关系数据
库系统可在几毫秒内执行 ALTER TABLE 语句。MySQL是一个值得注意的例外,它执行 ALTER
TABLE 时会复制整个表,这可能意味着在更改一个大型表时会花费几分钟甚至几个小时的停机
时间,尽管存在各种工具来解决这个限制【24,25,26】。
大型表上运行 UPDATE 语句在任何数据库上都可能会很慢,因为每一行都需要重写。要是不可
接受的话,应用程序可以将 first_name 设置为默认值 NULL ,并在读取时再填充,就像使用
文档数据库一样。
读时模式更具优势,当由于某种原因(例如,数据是异构的)集合中的项目并不都具有相同
的结构时。例如,因为:
存在许多不同类型的对象,将每种类型的对象放在自己的表中是不现实的。
数据的结构由外部系统决定。你无法控制外部系统且它随时可能变化。
在这样的情况下,模式的坏处远大于它的帮助,无模式文档可能是一个更加自然的数据模
型。但是,要是所有记录都具有相同的结构,那么模式是记录并强制这种结构的有效机制。
第四章将更详细地讨论模式和模式演化。
查询的数据局部性
文档通常以单个连续字符串形式进行存储,编码为JSON,XML或其二进制变体(如
MongoDB的BSON)。如果应用程序经常需要访问整个文档(例如,将其渲染至网页),那
么存储局部性会带来性能优势。如果将数据分割到多个表中(如图2-1所示),则需要进行多
第二章:数据模型与查询语言
43


次索引查找才能将其全部检索出来,这可能需要更多的磁盘查找并花费更多的时间。
局部性仅仅适用于同时需要文档绝大部分内容的情况。数据库通常需要加载整个文档,即使
只访问其中的一小部分,这对于大型文档来说是很浪费的。更新文档时,通常需要整个重
写。只有不改变文档大小的修改才可以容易地原地执行。因此,通常建议保持相对小的文
档,并避免增加文档大小的写入【9】。这些性能限制大大减少了文档数据库的实用场景。
值得指出的是,为了局部性而分组集合相关数据的想法并不局限于文档模型。例如,Google
的Spanner数据库在关系数据模型中提供了同样的局部性属性,允许模式声明一个表的行应该
交错(嵌套)在父表内【27】。Oracle类似地允许使用一个称为多表索引集群表(multi
table index cluster tables)的类似特性【28】。Bigtable数据模型(用于Cassandra和
HBase)中的列族(column-family)概念与管理局部性的目的类似【29】。
在第3章将还会看到更多关于局部性的内容。
文档和关系数据库的融合
自2000年代中期以来,大多数关系数据库系统(MySQL除外)都已支持XML。这包括对XML
文档进行本地修改的功能,以及在XML文档中进行索引和查询的功能。这允许应用程序使用
那种与文档数据库应当使用的非常类似的数据模型。
从9.3版本开始的PostgreSQL 【8】,从5.7版本开始的MySQL以及从版本10.5开始的IBM
DB2 [30]也对JSON文档提供了类似的支持级别。鉴于用在Web APIs的JSON流行趋势,其他
关系数据库很可能会跟随他们的脚步并添加JSON支持。
在文档数据库中,RethinkDB在其查询语言中支持类似关系的连接,一些MongoDB驱动程序
可以自动解析数据库引用(有效地执行客户端连接,尽管这可能比在数据库中执行的连接
慢,需要额外的网络往返,并且优化更少)。
随着时间的推移,关系数据库和文档数据库似乎变得越来越相似,这是一件好事:数据模型
相互补充 ,如果一个数据库能够处理类似文档的数据,并能够对其执行关系查询,那么应用
程序就可以使用最符合其需求的功能组合。
关系模型和文档模型的混合是未来数据库一条很好的路线。
. Codd对关系模型【1】的原始描述实际上允许在关系模式中与JSON文档非常相似。他
称之为非简单域(nonsimple domains)。这个想法是,一行中的值不一定是一个像数
字或字符串一样的原始数据类型,也可以是一个嵌套的关系(表),因此可以把一个任
意嵌套的树结构作为一个值,这很像30年后添加到SQL中的JSON或XML支持。 ↩
数据查询语言
v
v
第二章:数据模型与查询语言
44


当引入关系模型时,关系模型包含了一种查询数据的新方法:SQL是一种声明式查询语言,
而IMS和CODASYL使用命令式代码来查询数据库。那是什么意思?
许多常用的编程语言是命令式的。例如,给定一个动物物种的列表,返回列表中的鲨鱼可以
这样写:
function getSharks() {
var sharks = [];
for (var i = 0; i < animals.length; i++) {
if (animals[i].family === "Sharks") {
sharks.push(animals[i]);
}
}
return sharks;
}
在关系代数中:
$$ sharks = σ_{family = "sharks"}(animals)
$$ σ(希腊字母西格玛)是选择操作符,只返回符合条件的动物, family="shark" 。
定义SQL时,它紧密地遵循关系代数的结构:
SELECT * FROM animals WHERE family ='Sharks';
命令式语言告诉计算机以特定顺序执行某些操作。可以想象一下,逐行地遍历代码,评估条
件,更新变量,并决定是否再循环一遍。
在声明式查询语言(如SQL或关系代数)中,你只需指定所需数据的模式 - 结果必须符合哪些
条件,以及如何将数据转换(例如,排序,分组和集合) - 但不是如何实现这一目标。数据库
系统的查询优化器决定使用哪些索引和哪些连接方法,以及以何种顺序执行查询的各个部
分。
声明式查询语言是迷人的,因为它通常比命令式API更加简洁和容易。但更重要的是,它还隐
藏了数据库引擎的实现细节,这使得数据库系统可以在无需对查询做任何更改的情况下进行
性能提升。
例如,在本节开头所示的命令代码中,动物列表以特定顺序出现。如果数据库想要在后台回
收未使用的磁盘空间,则可能需要移动记录,这会改变动物出现的顺序。数据库能否安全地
执行,而不会中断查询?
SQL示例不确保任何特定的顺序,因此不在意顺序是否改变。但是如果查询用命令式的代码
来写的话,那么数据库就永远不可能确定代码是否依赖于排序。SQL相当有限的功能性为数
据库提供了更多自动优化的空间。
第二章:数据模型与查询语言
45


最后,声明式语言往往适合并行执行。现在,CPU的速度通过内核的增加变得更快,而不是
以比以前更高的时钟速度运行【31】。命令代码很难在多个内核和多个机器之间并行化,因
为它指定了指令必须以特定顺序执行。声明式语言更具有并行执行的潜力,因为它们仅指定
结果的模式,而不指定用于确定结果的算法。在适当情况下,数据库可以自由使用查询语言
的并行实现【32】。
Web上的声明式查询
声明式查询语言的优势不仅限于数据库。为了说明这一点,让我们在一个完全不同的环境中
比较声明式和命令式方法:一个Web浏览器。
假设你有一个关于海洋动物的网站。用户当前正在查看鲨鱼页面,因此你将当前所选的导航
项目“鲨鱼”标记为当前选中项目。
<ul>
<li class="selected">
<p>Sharks</p>
<ul>
<li>Great White Shark</li>
<li>Tiger Shark</li>
<li>Hammerhead Shark</li>
</ul>
</li>
<li><p>Whales</p>
<ul>
<li>Blue Whale</li>
<li>Humpback Whale</li>
<li>Fin Whale</li>
</ul>
</li>
</ul>
现在想让当前所选页面的标题具有一个蓝色的背景,以便在视觉上突出显示。使用CSS实现
起来非常简单:
li.selected > p {
background-color: blue;
}
这里的CSS选择器 li.selected> p 声明了我们想要应用蓝色样式的元素的模式:即其直接父
元素是具有 selected CSS类的 <li> 元素的所有 <p> 元素。示例中的元素 <p> Sharks
</p> 匹配此模式,但 <p> Whales </p> 不匹配,因为其 <li> 父元素缺少 class
=“selected” 。
如果使用XSL而不是CSS,你可以做类似的事情:
第二章:数据模型与查询语言
46


<xsl:template match="li[@class='selected']/p">
<fo:block background-color="blue">
<xsl:apply-templates/>
</fo:block>
</xsl:template>
这里的XPath表达式 li[@class='selected']/p 相当于上例中的CSS选择器 li.selected> p 。
CSS和XSL的共同之处在于,它们都是用于指定文档样式的声明式语言。
想象一下,必须使用命令式方法的情况会是如何。在Javascript中,使用文档对象模型
(DOM)API,其结果可能如下所示:
var liElements = document.getElementsByTagName("li");
for (var i = 0; i < liElements.length; i++) {
if (liElements[i].className === "selected") {
var children = liElements[i].childNodes;
for (var j = 0; j < children.length; j++) {
var child = children[j];
if (child.nodeType === Node.ELEMENT_NODE && child.tagName === "P") {
child.setAttribute("style", "background-color: blue");
}
}
}
}
这段JavaScript代码命令式地将元素设置为蓝色背景,但是代码看起来很糟糕。不仅比CSS和
XSL等价物更长,更难理解,而且还有一些严重的问题:
如果选定的类被移除(例如,因为用户点击了不同的页面),即使代码重新运行,蓝色
背景也不会被移除 - 因此该项目将保持突出显示,直到整个页面被重新加载。使用
CSS,浏览器会自动检测 li.selected> p 规则何时不再适用,并在选定的类被移除后立
即移除蓝色背景。
如果你想要利用新的API(例如 document.getElementsBy ClassName(“selected” )甚
至 document.evaluate() )来提高性能,则必须重写代码。另一方面,浏览器供应商可以
在不破坏兼容性的情况下提高CSS和XPath的性能。
在Web浏览器中,使用声明式CSS样式比使用JavaScript命令式地操作样式要好得多。类似
地,在数据库中,使用像SQL这样的声明式查询语言比使用命令式查询API要好得多 。
. vi IMS和CODASYL都使用命令式API。应用程序通常使用COBOL代码遍历数据库中
的记录,一次一条记录【2,16】。 ↩
MapReduce查询
vi
vi
第二章:数据模型与查询语言
47


MapReduce是一个由Google推广的编程模型,用于在多台机器上批量处理大规模的数据
【33】。一些NoSQL数据存储(包括MongoDB和CouchDB)支持有限形式的MapReduce,
作为在多个文档中执行只读查询的机制。
MapReduce将第10章中有更详细的描述。现在我们将简要讨论一下MongoDB使用的模型。
MapReduce既不是一个声明式的查询语言,也不是一个完全命令式的查询API,而是处于两
者之间:查询的逻辑用代码片断来表示,这些代码片段会被处理框架重复性调用。它基
于 map (也称为 collect )和 reduce (也称为 fold 或 inject )函数,两个函数存在于许
多函数式编程语言中。
最好举例来解释MapReduce模型。假设你是一名海洋生物学家,每当你看到海洋中的动物
时,你都会在数据库中添加一条观察记录。现在你想生成一个报告,说明你每月看到多少鲨
鱼。
在PostgreSQL中,你可以像这样表述这个查询:
SELECT
date_trunc('month', observation_timestamp) AS observation_month,
sum(num_animals) AS total_animals
FROM observations
WHERE family = 'Sharks'
GROUP BY observation_month;
date_trunc('month',timestamp) 函数用于确定包含 timestamp 的日历月份,并返回代表该月
份开始的另一个时间戳。换句话说,它将时间戳舍入成最近的月份。
这个查询首先过滤观察记录,以只显示鲨鱼家族的物种,然后根据它们发生的日历月份对观
察记录果进行分组,最后将在该月的所有观察记录中看到的动物数目加起来。
同样的查询用MongoDB的MapReduce功能可以按如下来表述:
db.observations.mapReduce(function map() {
var year = this.observationTimestamp.getFullYear();
var month = this.observationTimestamp.getMonth() + 1;
emit(year + "-" + month, this.numAnimals);
},
function reduce(key, values) {
return Array.sum(values);
},
{
query: {
family: "Sharks"
},
out: "monthlySharkReport"
});
第二章:数据模型与查询语言
48


可以声明式地指定只考虑鲨鱼种类的过滤器(这是一个针对MapReduce的特定于
MongoDB的扩展)。
每个匹配查询的文档都会调用一次JavaScript函数 map ,将 this 设置为文档对象。
map 函数发出一个键(包括年份和月份的字符串,如 "2013-12" 或 "2014-1" )和一个值
(该观察记录中的动物数量)。
map 发出的键值对按键来分组。对于具有相同键(即,相同的月份和年份)的所有键值
对,调用一次 reduce 函数。
reduce 函数将特定月份内所有观测记录中的动物数量相加。
将最终的输出写入到 monthlySharkReport 集合中。
例如,假设 observations 集合包含这两个文档:
{
observationTimestamp: Date.parse( "Mon, 25 Dec 1995 12:34:56 GMT"),
family: "Sharks",
species: "Carcharodon carcharias",
numAnimals: 3
{
}
observationTimestamp: Date.parse("Tue, 12 Dec 1995 16:17:18 GMT"),
family: "Sharks",
species: "Carcharias taurus",
numAnimals: 4
}
对每个文档都会调用一次 map 函数,结果将是 emit("1995-12",3) 和 emit("1995-12",4) 。随
后,以 reduce("1995-12",[3,4]) 调用 reduce 函数,将返回 7 。
map和reduce函数在功能上有所限制:它们必须是纯函数,这意味着它们只使用传递给它们
的数据作为输入,它们不能执行额外的数据库查询,也不能有任何副作用。这些限制允许数
据库以任何顺序运行任何功能,并在失败时重新运行它们。然而,map和reduce函数仍然是
强大的:它们可以解析字符串,调用库函数,执行计算等等。
MapReduce是一个相当底层的编程模型,用于计算机集群上的分布式执行。像SQL这样的更
高级的查询语言可以用一系列的MapReduce操作来实现(见第10章),但是也有很多不使用
MapReduce的分布式SQL实现。请注意,SQL中没有任何内容限制它在单个机器上运行,而
MapReduce在分布式查询执行上没有垄断权。
能够在查询中使用JavaScript代码是高级查询的一个重要特性,但这不限于MapReduce,一
些SQL数据库也可以用JavaScript函数进行扩展【34】。
MapReduce的一个可用性问题是,必须编写两个密切合作的JavaScript函数,这通常比编写
单个查询更困难。此外,声明式查询语言为查询优化器提供了更多机会来提高查询的性能。
基于这些原因,MongoDB 2.2添加了一种叫做聚合管道的声明式查询语言的支持【9】。用这
种语言表述鲨鱼计数查询如下所示:
第二章:数据模型与查询语言
49


db.observations.aggregate([
{ $match: { family: "Sharks" } },
{ $group: {
_id: {
year: { $year: "$observationTimestamp" },
month: { $month: "$observationTimestamp" }
},
totalAnimals: { $sum: "$numAnimals" } }}
]);
聚合管道语言与SQL的子集具有类似表现力,但是它使用基于JSON的语法而不是SQL的英语
句子式语法; 这种差异也许是口味问题。这个故事的寓意是NoSQL系统可能会发现自己意外地
重新发明了SQL,尽管带着伪装。
图数据模型
如我们之前所见,多对多关系是不同数据模型之间具有区别性的重要特征。如果你的应用程
序大多数的关系是一对多关系(树状结构化数据),或者大多数记录之间不存在关系,那么
使用文档模型是合适的。
但是,要是多对多关系在你的数据中很常见呢?关系模型可以处理多对多关系的简单情况,
但是随着数据之间的连接变得更加复杂,将数据建模为图形显得更加自然。
一个图由两种对象组成:顶点(vertices)(也称为节点(nodes) 或实体(entities)),
和边(edges)( 也称为关系(relationships)或弧 (arcs) )。多种数据可以被建模为
一个图形。典型的例子包括:
社交图谱
顶点是人,边指示哪些人彼此认识。
网络图谱
顶点是网页,边缘表示指向其他页面的HTML链接。
公路或铁路网络
顶点是交叉路口,边线代表它们之间的道路或铁路线。
可以将那些众所周知的算法运用到这些图上:例如,汽车导航系统搜索道路网络中两点之间
的最短路径,PageRank可以用在网络图上来确定网页的流行程度,从而确定该网页在搜索结
果中的排名。
在刚刚给出的例子中,图中的所有顶点代表了相同类型的事物(人,网页或交叉路口)。不
过,图并不局限于这样的同类数据:同样强大地是,图提供了一种一致的方式,用来在单个
数据存储中存储完全不同类型的对象。例如,Facebook维护一个包含许多不同类型的顶点和
第二章:数据模型与查询语言
50


边的单个图:顶点表示人,地点,事件,签到和用户的评论;边缘表示哪些人是彼此的朋友,
哪个签到发生在何处,谁评论了哪条消息,谁参与了哪个事件,等等【35】。
在本节中,我们将使用图2-5所示的示例。它可以从社交网络或系谱数据库中获得:它显示了
两个人,来自爱达荷州的Lucy和来自法国Beaune的Alain。他们已婚,住在伦敦。
图2-5 图数据结构示例(框代表顶点,箭头代表边)
有几种不同但相关的方法用来构建和查询图表中的数据。在本节中,我们将讨论属性图模型
(由Neo4j,Titan和InfiniteGraph实现)和三元组存储(triple-store)模型(由Datomic,
AllegroGraph等实现)。我们将查看图的三种声明式查询语言:Cypher,SPARQL和
Datalog。除此之外,还有像Gremlin 【36】这样的图形查询语言和像Pregel这样的图形处理
框架(见第10章)。
属性图
在属性图模型中,每个顶点(vertex)包括:
唯一的标识符
一组出边(outgoing edges)
一组入边(ingoing edges)
一组属性(键值对)
每条边(edge)包括:
唯一标识符
边的起点/尾部顶点(tail vertex)
第二章:数据模型与查询语言
51


边的终点/头部顶点(head vertex)
描述两个顶点之间关系类型的标签
一组属性(键值对)
可以将图存储看作由两个关系表组成:一个存储顶点,另一个存储边,如例2-2所示(该模式
使用PostgreSQL json数据类型来存储每个顶点或每条边的属性)。头部和尾部顶点用来存储
每条边;如果你想要一组顶点的输入或输出边,你可以分别通
过 head_vertex 或 tail_vertex 来查询 edges 表。
例2-2 使用关系模式来表示属性图
CREATE TABLE vertices (
vertex_id INTEGER PRIMARY KEY,
properties JSON
);
CREATE TABLE edges (
edge_id INTEGER PRIMARY KEY,
tail_vertex INTEGER REFERENCES vertices (vertex_id),
head_vertex INTEGER REFERENCES vertices (vertex_id),
label TEXT,
properties JSON
);
CREATE INDEX edges_tails ON edges (tail_vertex);
CREATE INDEX edges_heads ON edges (head_vertex);
关于这个模型的一些重要方面是:
1. 任何顶点都可以有一条边连接到任何其他顶点。没有模式限制哪种事物可不可以关联。
2. 给定任何顶点,可以高效地找到它的入边和出边,从而遍历图,即沿着一系列顶点的路
径前后移动。(这就是为什么例2-2在 tail_vertex 和 head_vertex 列上都有索引的原
因。)
3. 通过对不同类型的关系使用不同的标签,可以在一个图中存储几种不同的信息,同时仍
然保持一个清晰的数据模型。
这些特性为数据建模提供了很大的灵活性,如图2-5所示。图中显示了一些传统关系模式难以
表达的事情,例如不同国家的不同地区结构(法国有省和州,美国有不同的州和州),国中
国的怪事(先忽略主权国家和国家错综复杂的烂摊子),不同的数据粒度(Lucy现在的住所
被指定为一个城市,而她的出生地点只是在一个州的级别)。
你可以想象延伸图还能包括许多关于Lucy和Alain,或其他人的其他更多的事实。例如,你可
以用它来表示食物过敏(为每个过敏源增加一个顶点,并增加人与过敏源之间的一条边来指
示一种过敏情况),并链接到过敏源,每个过敏源具有一组顶点用来显示哪些食物含有哪些
物质。然后,你可以写一个查询,找出每个人吃什么是安全的。图表在可演化性是富有优势
的:当向应用程序添加功能时,可以轻松扩展图以适应应用程序数据结构的变化。
第二章:数据模型与查询语言
52


Cypher查询语言
Cypher是属性图的声明式查询语言,为Neo4j图形数据库而发明【37】。(它是以电影“黑客
帝国”中的一个角色开命名的,而与密码术中的密码无关【38】。)
例2-3显示了将图2-5的左边部分插入图形数据库的Cypher查询。可以类似地添加图的其余部
分,为了便于阅读而省略。每个顶点都有一个像 USA 或 Idaho 这样的符号名称,查询的其他
部分可以使用这些名称在顶点之间创建边,使用箭头符号: (Idaho) - [:WITHIN] 
>(USA) 创建一条标记为 WITHIN 的边, Idaho 为尾节点, USA 为头节点。
例2-3 将图2-5中的数据子集表示为Cypher查询
CREATE
(NAmerica:Location {name:'North America', type:'continent'}),
(USA:Location {name:'United States', type:'country' }),
(Idaho:Location {name:'Idaho', type:'state' }),
(Lucy:Person {name:'Lucy' }),
(Idaho) -[:WITHIN]-> (USA) -[:WITHIN]-> (NAmerica),
(Lucy) -[:BORN_IN]-> (Idaho)
当图2-5的所有顶点和边被添加到数据库后,让我们提些有趣的问题:例如,找到所有从美国
移民到欧洲的人的名字。更确切地说,这里我们想要找到符合下面条件的所有顶点,并且返
回这些顶点的 name 属性:该顶点拥有一条连到美国任一位置的 BORN_IN 边,和一条连到欧洲
的任一位置的 LIVING_IN 边。
例2-4展示了如何在Cypher中表达这个查询。在MATCH子句中使用相同的箭头符号来查找图
中的模式: (person) -[:BORN_IN]-> () 可以匹配 BORN_IN 边的任意两个顶点。该边的尾节点
被绑定了变量 person ,头节点则未被绑定。
例2-4 查找所有从美国移民到欧洲的人的Cypher查询:
MATCH
(person) -[:BORN_IN]-> () -[:WITHIN*0..]-> (us:Location {name:'United States'}),
(person) -[:LIVES_IN]-> () -[:WITHIN*0..]-> (eu:Location {name:'Europe'})
RETURN person.name
查询按如下来解读:
第二章:数据模型与查询语言
53


找到满足以下两个条件的所有顶点(称之为person顶点):
1. person 顶点拥有一条到某个顶点的 BORN_IN 出边。从那个顶点开始,沿着一系
列 WITHIN 出边最终到达一个类型为 Location , name 属性为 United States 的顶
点。
2. person 顶点还拥有一条 LIVES_IN 出边。沿着这条边,可以通过一系列 WITHIN 出边
最终到达一个类型为 Location , name 属性为 Europe 的顶点。
对于这样的 Person 顶点,返回其 name 属性。
执行这条查询可能会有几种可行的查询路径。这里给出的描述建议首先扫描数据库中的所有
人,检查每个人的出生地和居住地,然后只返回符合条件的那些人。
等价地,也可以从两个 Location 顶点开始反向地查找。假如 name 属性上有索引,则可以高
效地找到代表美国和欧洲的两个顶点。然后,沿着所有 WITHIN 入边,可以继续查找出所有在
美国和欧洲的位置(州,地区,城市等)。最后,查找出那些可以由 BORN_IN 或 LIVES_IN 入
边到那些位置顶点的人。
通常对于声明式查询语言来说,在编写查询语句时,不需要指定执行细节:查询优化程序会
自动选择预测效率最高的策略,因此你可以继续编写应用程序的其他部分。
SQL中的图查询
例2-2建议在关系数据库中表示图数据。但是,如果把图数据放入关系结构中,我们是否也可
以使用SQL查询它?
答案是肯定的,但有些困难。在关系数据库中,你通常会事先知道在查询中需要哪些连接。
在图查询中,你可能需要在找到待查找的顶点之前,遍历可变数量的边。也就是说,连接的
数量事先并不确定。
在我们的例子中,这发生在Cypher查询中的 () -[:WITHIN*0..]-> () 规则中。一个人
的 LIVES_IN 边可以指向任何类型的位置:街道,城市,地区,地区,国家等。城市可以在一
个地区,在一个州内的一个地区,在一个国家内的一个州等等。 LIVES_IN 边可以直接指向正
在查找的位置,或者一个在位置层次结构中隔了数层的位置。
在Cypher中,用 WITHIN * 0 非常简洁地表述了上述事实:“沿着 WITHIN 边,零次或多次”。它
很像正则表达式中的 * 运算符。
自SQL:1999,查询可变长度遍历路径的思想可以使用称为递归公用表表达式( WITH
RECURSIVE 语法)的东西来表示。例2-5显示了同样的查询 - 查找从美国移民到欧洲的人的姓名
- 在SQL使用这种技术(PostgreSQL,IBM DB2,Oracle和SQL Server均支持)来表述。但
是,与Cypher相比,其语法非常笨拙。
例2-5 与示例2-4同样的查询,在SQL中使用递归公用表表达式表示
第二章:数据模型与查询语言
54


WITH RECURSIVE
-- in_usa 包含所有的美国境内的位置ID
in_usa(vertex_id) AS (
SELECT vertex_id FROM vertices WHERE properties ->> 'name' = 'United States'
UNION
SELECT edges.tail_vertex FROM edges
JOIN in_usa ON edges.head_vertex = in_usa.vertex_id
WHERE edges.label = 'within'
),
-- in_europe 包含所有的欧洲境内的位置ID
in_europe(vertex_id) AS (
SELECT vertex_id FROM vertices WHERE properties ->> 'name' = 'Europe'
UNION
SELECT edges.tail_vertex FROM edges
JOIN in_europe ON edges.head_vertex = in_europe.vertex_id
WHERE edges.label = 'within' ),
-- born_in_usa 包含了所有类型为Person,且出生在美国的顶点
born_in_usa(vertex_id) AS (
SELECT edges.tail_vertex FROM edges
JOIN in_usa ON edges.head_vertex = in_usa.vertex_id
WHERE edges.label = 'born_in' ),
-- lives_in_europe 包含了所有类型为Person,且居住在欧洲的顶点。
lives_in_europe(vertex_id) AS (
SELECT edges.tail_vertex FROM edges
JOIN in_europe ON edges.head_vertex = in_europe.vertex_id
WHERE edges.label = 'lives_in')
SELECT vertices.properties ->> 'name'
FROM vertices
JOIN born_in_usa ON vertices.vertex_id = born_in_usa.vertex_id
JOIN lives_in_europe ON vertices.vertex_id = lives_in_europe.vertex_id;
首先,查找 name 属性为 United States 的顶点,将其作为 in_use 顶点的集合的第一个
元素。
从 in_use 集合的顶点出发,沿着所有的 with_in 入边,将其尾顶点加入同一集合,不断
递归直到所有 with_in 入边都被访问完毕。
同理,从 name 属性为 Europe 的顶点出发,建立 in_europe 顶点的集合。
对于 in_usa 集合中的每个顶点,根据 born_in 入边来查找出生在美国某个地方的人。
同样,对于 in_europe 集合中的每个顶点,根据 lives_in 入边来查找居住在欧洲的人。
最后,把在美国出生的人的集合与在欧洲居住的人的集合相交。
同一个查询,用某一个查询语言可以写成4行,而用另一个查询语言需要29行,这恰恰说明了
不同的数据模型是为不同的应用场景而设计的。选择适合应用程序的数据模型非常重要。
三元组存储和SPARQL
第二章:数据模型与查询语言
55


三元组存储模式大体上与属性图模型相同,用不同的词来描述相同的想法。不过仍然值得讨
论,因为三元组存储有很多现成的工具和语言,这些工具和语言对于构建应用程序的工具箱
可能是宝贵的补充。
在三元组存储中,所有信息都以非常简单的三部分表示形式存储(主语,谓语,宾语)。例
如,三元组(吉姆, 喜欢 ,香蕉)中,吉姆是主语,喜欢是谓语(动词),香蕉是对象。
三元组的主语相当于图中的一个顶点。而宾语是下面两者之一:
1. 原始数据类型中的值,例如字符串或数字。在这种情况下,三元组的谓语和宾语相当于
主语顶点上的属性的键和值。例如, (lucy, age, 33) 就像属性 {“age”:33} 的顶点
lucy。
2. 图中的另一个顶点。在这种情况下,谓语是图中的一条边,主语是其尾部顶点,而宾语
是其头部顶点。例如,在 (lucy, marriedTo, alain) 中主语和宾语 lucy 和 alain 都是顶
点,并且谓语 marriedTo 是连接他们的边的标签。
例2-6显示了与例2-3相同的数据,以称为Turtle的格式(Notation3(N3)【39】)的一个子
集形式写成三元组。
例2-6 图2-5中的数据子集,表示为Turtle三元组
@prefix : <urn:example:>.
_:lucy a :Person.
_:lucy :name "Lucy".
_:lucy :bornIn _:idaho.
_:idaho a :Location.
_:idaho :name "Idaho".
_:idaho :type "state".
_:idaho :within _:usa.
_:usa a :Location
_:usa :name "United States"
_:usa :type "country".
_:usa :within _:namerica.
_:namerica a :Location
_:namerica :name "North America"
_:namerica :type :"continent"
在这个例子中,图的顶点被写为: _:someName 。这个名字并不意味着这个文件以外的任何东
西。它的存在只是帮助我们明确哪些三元组引用了同一顶点。当谓语表示边时,该宾语是一
个顶点,如 _:idaho :within _:usa. 。当谓语是一个属性时,该宾语是一个字符串,如 _:usa
:name "United States"
一遍又一遍地重复相同的主语看起来相当重复,但幸运的是,可以使用分号来说明关于同一
主语的多个事情。这使得Turtle格式相当不错,可读性强:参见例2-7。
例2-7 一种相对例2-6写入数据的更为简洁的方法。
第二章:数据模型与查询语言
56


@prefix : <urn:example:>.
_:lucy a :Person; :name "Lucy"; :bornIn _:idaho.
_:idaho a :Location; :name "Idaho"; :type "state"; :within _:usa
_:usa a :Loaction; :name "United States"; :type "country"; :within _:namerica.
_:namerica a :Location; :name "North America"; :type "continent".
语义网络
如果你阅读更多关于三元组存储的信息,你可能会被卷入关于语义网络的文章漩涡中。三元
组存储数据模型完全独立于语义网络,例如,Datomic【40】是三元组存储 ,并没有声称与
它有任何关系。但是,由于在很多人眼中这两者紧密相连,我们应该简要地讨论一下。
. 从技术上讲,Datomic使用的是五元组而不是三元组,两个额外的字段是用于版本控
制的元数据 ↩
从本质上讲语义网是一个简单且合理的想法:网站已经将信息发布为文字和图片供人类阅
读,为什么不将信息作为机器可读的数据也发布给计算机呢?资源描述框架(RDF)【41】
的目的是作为不同网站以一致的格式发布数据的一种机制,允许来自不同网站的数据自动合
并成一个数据网络 - 一种互联网范围内的“关于一切的数据库“。
不幸的是,这个语义网在二十一世纪初被过度使用,但到目前为止没有任何迹象表明已在实
践中实现,这使得许多人呲之以鼻。它还遭受了过多的令人眼花缭乱的缩略词,过于复杂的
标准提议和狂妄自大的苦果。
然而,如果仔细观察这些失败,语义Web项目还是拥有很多优秀的工作成果。即使你没有兴
趣在语义网上发布RDF数据,三元组也可以成为应用程序的良好内部数据模型。
RDF数据模型
例2-7中使用的Turtle语言是一种用于RDF数据的人可读格式。有时候,RDF也可以以XML格
式编写,不过完成同样的事情会相对啰嗦,参见例2-8。Turtle/N3是更可取的,因为它更容易
阅读,像Apache Jena 【42】这样的工具可以根据需要在不同的RDF格式之间进行自动转
换。
例2-8 用RDF/XML语法表示例2-7的数据
vii
vii
第二章:数据模型与查询语言
57


<rdf:RDF xmlns="urn:example:"
xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
<Location rdf:nodeID="idaho">
<name>Idaho</name>
<type>state</type>
<within>
<Location rdf:nodeID="usa">
<name>United States</name>
<type>country</type>
<within>
<Location rdf:nodeID="namerica">
<name>North America</name>
<type>continent</type>
</Location>
</within>
</Location>
</within>
</Location>
<Person rdf:nodeID="lucy">
<name>Lucy</name>
<bornIn rdf:nodeID="idaho"/>
</Person>
</rdf:RDF>
RDF有一些奇怪之处,因为它是为了在互联网上交换数据而设计的。三元组的主语,谓语和
宾语通常是URI。例如,谓语可能是一个URI,如 <http://my
company.com/namespace#within> 或 <http://my-company.com/namespace#lives_in> ,而不仅仅
是 WITHIN 或 LIVES_IN 。这个设计背后的原因为了让你能够把你的数据和其他人的数据结合
起来,如果他们赋予单词 within 或者 lives_in 不同的含义,两者也不会冲突,因为它们的
谓语实际上是 <http://other.org/foo#within> 和 <http://other.org/foo#lives_in> 。
从RDF的角度来看,URL <http://my-company.com/namespace> 不一定需要能解析成什么东
西,它只是一个命名空间。为避免与 http://URL 混淆,本节中的示例使用不可解析的URI,
如 urn:example:within 。幸运的是,你只需在文件顶部指定一个前缀,然后就不用再管了。
SPARQL查询语言
SPARQL是一种用于三元组存储的面向RDF数据模型的查询语言,【43】。(它是SPARQL
协议和RDF查询语言的缩写,发音为“sparkle”。)SPARQL早于Cypher,并且由于Cypher的
模式匹配借鉴于SPARQL,这使得它们看起来非常相似【37】。
与之前相同的查询 - 查找从美国转移到欧洲的人 - 使用SPARQL比使用Cypher甚至更为简洁
(参见例2-9)。
例2-9 与示例2-4相同的查询,用SPARQL表示
第二章:数据模型与查询语言
58


PREFIX : <urn:example:>
SELECT ?personName WHERE {
?person :name ?personName.
?person :bornIn / :within* / :name "United States".
?person :livesIn / :within* / :name "Europe".
}
结构非常相似。以下两个表达式是等价的(SPARQL中的变量以问号开头):
(person) -[:BORN_IN]-> () -[:WITHIN*0..]-> (location) # Cypher
?person :bornIn / :within* ?location. # SPARQL
因为RDF不区分属性和边,而只是将它们作为谓语,所以可以使用相同的语法来匹配属性。
在下面的表达式中,变量 usa 被绑定到任意具有值为字符串 "United States" 的 name 属性的
顶点:
(usa {name:'United States'}) # Cypher
?usa :name "United States". # SPARQL
SPARQL是一种很好的查询语言——哪怕语义网从未实现,它仍然可以成为一种应用程序内
部使用的强大工具。
第二章:数据模型与查询语言
59


图形数据库与网络模型相比较
在“文档数据库是否在重蹈覆辙?”中,我们讨论了CODASYL和关系模型如何竞相解决
IMS中的多对多关系问题。乍一看,CODASYL的网络模型看起来与图模型相似。
CODASYL是否是图形数据库的第二个变种?
不,他们在几个重要方面有所不同:
在CODASYL中,数据库有一个模式,用于指定哪种记录类型可以嵌套在其他记录类
型中。在图形数据库中,不存在这样的限制:任何顶点都可以具有到其他任何顶点
的边。这为应用程序适应不断变化的需求提供了更大的灵活性。
在CODASYL中,达到特定记录的唯一方法是遍历其中的一个访问路径。在图形数据
库中,可以通过其唯一ID直接引用任何顶点,也可以使用索引来查找具有特定值的
顶点。
在CODASYL,记录的后续是一个有序集合,所以数据库的人不得不维持排序(这会
影响存储布局),并且插入新记录到数据库的应用程序不得不担心的新记录在这些
集合中的位置。在图形数据库中,顶点和边不是有序的(只能在查询时对结果进行
排序)。
在CODASYL中,所有查询都是命令式的,难以编写,并且很容易因架构中的变化而
受到破坏。在图形数据库中,如果需要,可以在命令式代码中编写遍历,但大多数
图形数据库也支持高级声明式查询语言,如Cypher或SPARQL。
基础:Datalog
Datalog是比SPARQL或Cypher更古老的语言,在20世纪80年代被学者广泛研究
【44,45,46】。它在软件工程师中不太知名,但是它是重要的,因为它为以后的查询语言提供
了基础。
在实践中,Datalog被用于少数的数据系统中:例如,它是Datomic 【40】的查询语言,
Cascalog 【47】是一种用于查询Hadoop大数据集的Datalog实现 。
. Datomic和Cascalog使用Datalog的Clojure S表达式语法。在下面的例子中使用了一
个更容易阅读的Prolog语法,但两者没有任何功能差异。 ↩
Datalog的数据模型类似于三元组模式,但进行了一点泛化。把三元组写成谓语(主语,宾
语),而不是写三元语(主语,宾语,宾语)。例2-10显示了如何用Datalog写入我们的例子
中的数据。
例2-10 用Datalog来表示图2-5中的数据子集
viii
viii
第二章:数据模型与查询语言
60


name(namerica, 'North America').
type(namerica, continent).
name(usa, 'United States').
type(usa, country).
within(usa, namerica).
name(idaho, 'Idaho').
type(idaho, state).
within(idaho, usa).
name(lucy, 'Lucy').
born_in(lucy, idaho).
既然已经定义了数据,我们可以像之前一样编写相同的查询,如例2-11所示。它看起来有点不
同于Cypher或SPARQL的等价物,但是请不要放弃它。Datalog是Prolog的一个子集,如果你
学过计算机科学,你可能已经见过。
例2-11 与示例2-4相同的查询,用Datalog表示
within_recursive(Location, Name) :- name(Location, Name). /* Rule 1 */
within_recursive(Location, Name) :- within(Location, Via), /* Rule 2 */
within_recursive(Via, Name).
migrated(Name, BornIn, LivingIn) :- name(Person, Name), /* Rule 3 */
born_in(Person, BornLoc),
within_recursive(BornLoc, BornIn),
lives_in(Person, LivingLoc),
within_recursive(LivingLoc, LivingIn).
?- migrated(Who, 'United States', 'Europe'). /* Who = 'Lucy'. */
Cypher和SPARQL使用SELECT立即跳转,但是Datalog一次只进行一小步。我们定义规则,
以将新谓语告诉数据库:在这里,我们定义了两个新的谓语, _recursive 和 migrated 。这些
谓语不是存储在数据库中的三元组中,而是它们是从数据或其他规则派生而来的。规则可以
引用其他规则,就像函数可以调用其他函数或者递归地调用自己一样。像这样,复杂的查询
可以一次构建其中的一小块。
在规则中,以大写字母开头的单词是变量,谓语则用Cypher和SPARQL的方式一样来匹配。
例如, name(Location, Name) 通过变量绑定 Location = namerica 和 Name ='North America' 可
以匹配三元组 name(namerica, 'North America') 。
要是系统可以在 :- 操作符的右侧找到与所有谓语的一个匹配,就运用该规则。当规则运用
时,就好像通过 :- 的左侧将其添加到数据库(将变量替换成它们匹配的值)。
因此,一种可能的应用规则的方式是:
第二章:数据模型与查询语言
61


1. 数据库存在 name(namerica, 'North America') ,故运用规则1。它生
成 within_recursive(namerica, 'North America') 。
2. 数据库存在 within(usa, namerica) ,在上一步骤中生成 within_recursive(namerica,
'North America') ,故运用规则2。它会产生 within_recursive(usa, 'North America') 。
3. 数据库存在 within(idaho, usa) ,在上一步生成 within_recursive(usa, 'North
America') ,故运用规则2。它产生 within_recursive(idaho, 'North America') 。
通过重复应用规则1和2, within_recursive 谓语可以告诉我们在数据库中包含北美(或任何
其他位置名称)的所有位置。这个过程如图2-6所示。
图2-6 使用示例2-11中的Datalog规则来确定爱达荷州在北美。
现在规则3可以找到出生在某个地方 BornIn 的人,并住在某个地方 LivingIn 。通过查
询 BornIn ='United States' 和 LivingIn ='Europe' ,并将此人作为变量 Who ,让Datalog系统
找出变量 Who 会出现哪些值。因此,最后得到了与早先的Cypher和SPARQL查询相同的答
案。
相对于本章讨论的其他查询语言,我们需要采取不同的思维方式来思考Datalog方法,但这是
一种非常强大的方法,因为规则可以在不同的查询中进行组合和重用。虽然对于简单的一次
性查询,显得不太方便,但是它可以更好地处理数据很复杂的情况。
本章小结
数据模型是一个巨大的课题,在本章中,我们快速浏览了各种不同的模型。我们没有足够的
空间来详细介绍每个模型的细节,但是希望这个概述足以激起你的兴趣,以更多地了解最适
合你的应用需求的模型。
在历史上,数据最开始被表示为一棵大树(层次数据模型),但是这不利于表示多对多的关
系,所以发明了关系模型来解决这个问题。最近,开发人员发现一些应用程序也不适合采用
关系模型。新的非关系型“NoSQL”数据存储在两个主要方向上存在分歧:
1. 文档数据库的应用场景是:数据通常是自我包含的,而且文档之间的关系非常稀少。
2. 图形数据库用于相反的场景:任意事物都可能与任何事物相关联。
第二章:数据模型与查询语言
62


这三种模型(文档,关系和图形)在今天都被广泛使用,并且在各自的领域都发挥很好。一
个模型可以用另一个模型来模拟 — 例如,图数据可以在关系数据库中表示 — 但结果往往是
糟糕的。这就是为什么我们有着针对不同目的的不同系统,而不是一个单一的万能解决方
案。
文档数据库和图数据库有一个共同点,那就是它们通常不会为存储的数据强制一个模式,这
可以使应用程序更容易适应不断变化的需求。但是应用程序很可能仍会假定数据具有一定的
结构;这只是模式是明确的(写入时强制)还是隐含的(读取时处理)的问题。
每个数据模型都具有各自的查询语言或框架,我们讨论了几个例子:SQL,MapReduce,
MongoDB的聚合管道,Cypher,SPARQL和Datalog。我们也谈到了CSS和XSL/XPath,它
们不是数据库查询语言,而包含有趣的相似之处。
虽然我们已经覆盖了很多层面,但仍然有许多数据模型没有提到。举几个简单的例子:
使用基因组数据的研究人员通常需要执行序列相似性搜索,这意味着需要一个很长的字
符串(代表一个DNA分子),并在一个拥有类似但不完全相同的字符串的大型数据库中
寻找匹配。这里所描述的数据库都不能处理这种用法,这就是为什么研究人员编写了像
GenBank这样的专门的基因组数据库软件的原因【48】。
粒子物理学家数十年来一直在进行大数据类型的大规模数据分析,像大型强子对撞机
(LHC)这样的项目现在可以工作在数百亿兆字节的范围内!在这样的规模下,需要定
制解决方案来阻住硬件成本的失控【49】。
全文搜索可以说是一种经常与数据库一起使用的数据模型。信息检索是一个很大的专业
课题,我们不会在本书中详细介绍,但是我们将在第三章和第三章中介绍搜索索引。
让我们暂时将其放在一边。在下一章中,我们将讨论在实现本章描述的数据模型时会遇到的
一些权衡。
参考文献
1. Edgar F. Codd: “A Relational Model of Data for Large Shared Data Banks,”
Communications of the ACM, volume 13, number 6, pages 377–387, June 1970.
doi:10.1145/362384.362685
2. Michael Stonebraker and Joseph M. Hellerstein: “What Goes Around Comes Around,”
in Readings in Database Systems, 4th edition, MIT Press, pages 2–41, 2005. ISBN:
978-0-262-69314-1
3. Pramod J. Sadalage and Martin Fowler: NoSQL Distilled. Addison-Wesley, August
2012. ISBN: 978-0-321-82662-6
4. Eric Evans: “NoSQL: What's in a Name?,” blog.sym-link.com, October 30, 2009.
第二章:数据模型与查询语言
63


5. James Phillips: “Surprises in Our NoSQL Adoption Survey,” blog.couchbase.com,
February 8, 2012.
6. Michael Wagner: SQL/XML:2006 – Evaluierung der Standardkonformität ausgewählter
Datenbanksysteme. Diplomica Verlag, Hamburg, 2010. ISBN: 978-3-836-64609-3
7. “XML Data in SQL Server,” SQL Server 2012 documentation, technet.microsoft.com,
2013.
8. “PostgreSQL 9.3.1 Documentation,” The PostgreSQL Global Development Group,
2013.
9. “The MongoDB 2.4 Manual,” MongoDB, Inc., 2013.
10. “RethinkDB 1.11 Documentation,” rethinkdb.com, 2013.
11. “Apache CouchDB 1.6 Documentation,” docs.couchdb.org, 2014.
12. Lin Qiao, Kapil Surlaker, Shirshanka Das, et al.: “On Brewing Fresh Espresso:
LinkedIn’s Distributed Data Serving Platform,” at ACM International Conference on
Management of Data (SIGMOD), June 2013.
13. Rick Long, Mark Harrington, Robert Hain, and Geoff Nicholls: IMS Primer. IBM Redbook
SG24-5352-00, IBM International Technical Support Organization, January 2000.
14. Stephen D. Bartlett: “IBM’s IMS—Myths, Realities, and Opportunities,” The Clipper
Group Navigator, TCG2013015LI, July 2013.
15. Sarah Mei: “Why You Should Never Use MongoDB,” sarahmei.com, November 11,
2013.
16. J. S. Knowles and D. M. R. Bell: “The CODASYL Model,” in Databases—Role and
Structure: An Advanced Course, edited by P. M. Stocker, P. M. D. Gray, and M. P.
Atkinson, pages 19–56, Cambridge University Press, 1984. ISBN: 978-0-521-25430-4
17. Charles W. Bachman: “The Programmer as Navigator,” Communications of the ACM,
volume 16, number 11, pages 653–658, November 1973. doi:10.1145/355611.362534
18. Joseph M. Hellerstein, Michael Stonebraker, and James Hamilton: “Architecture of a
Database System,” Foundations and Trends in Databases, volume 1, number 2, pages
141–259, November 2007. doi:10.1561/1900000002
19. Sandeep Parikh and Kelly Stirman: “Schema Design for Time Series Data in
MongoDB,” blog.mongodb.org, October 30, 2013.
20. Martin Fowler: “Schemaless Data Structures,” martinfowler.com, January 7, 2013.
第二章:数据模型与查询语言
64


21. Amr Awadallah: “Schema-on-Read vs. Schema-on-Write,” at Berkeley EECS RAD Lab
Retreat, Santa Cruz, CA, May 2009.
22. Martin Odersky: “The Trouble with Types,” at Strange Loop, September 2013.
23. Conrad Irwin: “MongoDB—Confessions of a PostgreSQL Lover,” at HTML5DevConf,
October 2013.
24. “Percona Toolkit Documentation: pt-online-schema-change,” Percona Ireland Ltd., 2013.
25. Rany Keddo, Tobias Bielohlawek, and Tobias Schmidt: “Large Hadron Migrator,”
SoundCloud, 2013. Shlomi Noach:
“gh-ost: GitHub's Online Schema Migration Tool for MySQL,” githubengineering.com,
August 1, 2016.
26. James C. Corbett, Jeffrey Dean, Michael Epstein, et al.: “Spanner: Google’s Globally
Distributed Database,” at 10th USENIX Symposium on Operating System Design and
Implementation (OSDI), October 2012.
27. Donald K. Burleson: “Reduce I/O with Oracle Cluster Tables,” dba-oracle.com.
28. Fay Chang, Jeffrey Dean, Sanjay Ghemawat, et al.: “Bigtable: A Distributed Storage
System for Structured Data,” at 7th USENIX Symposium on Operating System Design
and Implementation (OSDI), November 2006.
29. Bobbie J. Cochrane and Kathy A. McKnight: “DB2 JSON Capabilities, Part 1:
Introduction to DB2 JSON,” IBM developerWorks, June 20, 2013.
30. Herb Sutter: “The Free Lunch Is Over: A Fundamental Turn Toward Concurrency in
Software,” Dr. Dobb's Journal, volume 30, number 3, pages 202-210, March 2005.
31. Joseph M. Hellerstein: “The Declarative Imperative: Experiences and Conjectures in
Distributed Logic,” Electrical Engineering and Computer Sciences, University of
California at Berkeley, Tech report UCB/EECS-2010-90, June 2010.
32. Jeffrey Dean and Sanjay Ghemawat: “MapReduce: Simplified Data Processing on
Large Clusters,” at 6th USENIX Symposium on Operating System Design and
Implementation (OSDI), December 2004.
33. Craig Kerstiens: “JavaScript in Your Postgres,” blog.heroku.com, June 5, 2013.
34. Nathan Bronson, Zach Amsden, George Cabrera, et al.: “TAO: Facebook’s Distributed
Data Store for the Social Graph,” at USENIX Annual Technical Conference (USENIX
ATC), June 2013.
35. “Apache TinkerPop3.2.3 Documentation,” tinkerpop.apache.org, October 2016.
第二章:数据模型与查询语言
65


36. “The Neo4j Manual v2.0.0,” Neo Technology, 2013. Emil Eifrem: Twitter
correspondence, January 3, 2014.
37. David Beckett and Tim Berners-Lee: “Turtle – Terse RDF Triple Language,” W3C Team
Submission, March 28, 2011.
38. “Datomic Development Resources,” Metadata Partners, LLC, 2013. W3C RDF Working
Group: “Resource Description Framework (RDF),” w3.org, 10 February 2004.
39. “Apache Jena,” Apache Software Foundation.
40. Steve Harris, Andy Seaborne, and Eric Prud'hommeaux: “SPARQL 1.1 Query
Language,” W3C Recommendation, March 2013.
41. Todd J. Green, Shan Shan Huang, Boon Thau Loo, and Wenchao Zhou: “Datalog and
Recursive Query Processing,” Foundations and Trends in Databases, volume 5,
number 2, pages 105–195, November 2013. doi:10.1561/1900000017
42. Stefano Ceri, Georg Gottlob, and Letizia Tanca: “What You Always Wanted to Know
About Datalog (And Never Dared to Ask),” IEEE Transactions on Knowledge and Data
Engineering, volume 1, number 1, pages 146–166, March 1989. doi:10.1109/69.43410
43. Serge Abiteboul, Richard Hull, and Victor Vianu: Foundations of Databases. Addison
Wesley, 1995. ISBN: 978-0-201-53771-0, available online at webdam.inria.fr/Alice
44. Nathan Marz: “Cascalog," cascalog.org. Dennis A. Benson, Ilene Karsch-Mizrachi,
David J. Lipman, et al.:
“GenBank,” Nucleic Acids Research, volume 36, Database issue, pages D25–D30,
December 2007. doi:10.1093/nar/gkm929
45. Fons Rademakers: “ROOT for Big Data Analysis,” at Workshop on the Future of Big
Data Management, London, UK, June 2013.
上一章 目录 下一章
第一章:可靠、可扩展、可维护 设计数据密集型应用 第三章:存储与检索
第二章:数据模型与查询语言
66


3. 存储与检索
建立秩序,省却搜索
——德国谚语
[TOC]
一个数据库在最基础的层次上需要完成两件事情:当你把数据交给数据库时,它应当把数据
存储起来;而后当你向数据库要数据时,它应当把数据返回给你。
在第2章中,我们讨论了数据模型和查询语言,即程序员将数据录入数据库的格式,以及再次
要回数据的机制。在本章中我们会从数据库的视角来讨论同样的问题:数据库如何存储我们
提供的数据,以及如何在我们需要时重新找到数据。
作为程序员,为什么要关心数据库内部存储与检索的机理?你可能不会去从头开始实现自己
的存储引擎,但是你确实需要从许多可用的存储引擎中选择一个合适的。而且为了调谐存储
引擎以适配应用工作负载,你也需要大致了解存储引擎在底层究竟做什么。
第三章:存储与检索
67


特别需要注意,针对事务性负载和分析性负载优化的存储引擎之间存在巨大差异。稍后我们
将在 “事务处理还是分析?” 一节中探讨这一区别,并在 “列存储”中讨论一系列针对分析优化
存储引擎。
但是,我们将从您最可能熟悉的两大类数据库:传统关系型数据库与很多所谓的“NoSQL”数
据库开始,通过介绍它们的存储引擎来开始本章的内容。我们会研究两大类存储引擎:日志
结构(log-structured)的存储引擎,以及面向页面(page-oriented)的存储引擎(例如B
树)。
驱动数据库的数据结构
世界上最简单的数据库可以用两个Bash函数实现:
#!/bin/bash
db_set () {
echo "$1,$2" >> database
}
db_get () {
grep "^$1," database | sed -e "s/^$1,//" | tail -n 1
}
这两个函数实现了键值存储的功能。执行 db_set key value ,会将 键(key)和值
(value) 存储在数据库中。键和值(几乎)可以是你喜欢的任何东西,例如,值可以是
JSON文档。然后调用 db_get key ,查找与该键关联的最新值并将其返回。
麻雀虽小,五脏俱全:
$ db_set 123456 '{"name":"London","attractions":["Big Ben","London Eye"]}' $
$ db_set 42 '{"name":"San Francisco","attractions":["Golden Gate Bridge"]}'
$ db_get 42
{"name":"San Francisco","attractions":["Golden Gate Bridge"]}
底层的存储格式非常简单:一个文本文件,每行包含一条逗号分隔的键值对(忽略转义问题
的话,大致与CSV文件类似)。每次对 db_set 的调用都会向文件末尾追加记录,所以更新
键的时候旧版本的值不会被覆盖 —— 因而查找最新值的时候,需要找到文件中键最后一次出
现的位置(因此 db_get 中使用了 tail -n 1 。)
第三章:存储与检索
68


$ db_set 42 '{"name":"San Francisco","attractions":["Exploratorium"]}'
$ db_get 42
{"name":"San Francisco","attractions":["Exploratorium"]}
$ cat database
123456,{"name":"London","attractions":["Big Ben","London Eye"]}
42,{"name":"San Francisco","attractions":["Golden Gate Bridge"]}
42,{"name":"San Francisco","attractions":["Exploratorium"]}
db_set 函数对于极其简单的场景其实有非常好的性能,因为在文件尾部追加写入通常是非常
高效的。与 db_set 做的事情类似,许多数据库在内部使用了日志(log),也就是一个仅追
加(append-only)的数据文件。真正的数据库有更多的问题需要处理(如并发控制,回收
磁盘空间以避免日志无限增长,处理错误与部分写入的记录),但基本原理是一样的。日志
极其有用,我们还将在本书的其它部分重复见到它好几次。
日志(log)这个词通常指应用日志:即应用程序输出的描述发生事情的文本。本书在更
普遍的意义下使用日志这一词:一个仅追加的记录序列。它可能压根就不是给人类看
的,使用二进制格式,并仅能由其他程序读取。
另一方面,如果这个数据库中有着大量记录,则这个 db_get 函数的性能会非常糟糕。每次你
想查找一个键时, db_get 必须从头到尾扫描整个数据库文件来查找键的出现。用算法的语言
来说,查找的开销是 O(n) :如果数据库记录数量 n 翻了一倍,查找时间也要翻一倍。这就
不好了。
为了高效查找数据库中特定键的值,我们需要一个数据结构:索引(index)。本章将介绍一
系列的索引结构,并它们进行对比。索引背后的大致思想是,保存一些额外的元数据作为路
标,帮助你找到想要的数据。如果您想在同一份数据中以几种不同的方式进行搜索,那么你
也许需要不同的索引,建在数据的不同部分上。
索引是从主数据衍生的附加(additional)结构。许多数据库允许添加与删除索引,这不会影
响数据的内容,它只影响查询的性能。维护额外的结构会产生开销,特别是在写入时。写入
性能很难超过简单地追加写入文件,因为追加写入是最简单的写入操作。任何类型的索引通
常都会减慢写入速度,因为每次写入数据时都需要更新索引。
这是存储系统中一个重要的权衡:精心选择的索引加快了读查询的速度,但是每个索引都会
拖慢写入速度。因为这个原因,数据库默认并不会索引所有的内容,而需要你(程序员或
DBA)通过对应用查询模式的了解来手动选择索引。你可以选择能为应用带来最大收益,同
时又不会引入超出必要开销的索引。
哈希索引
让我们从键值数据(key-value Data)的索引开始。这不是您可以索引的唯一数据类型,但
键值数据是很常见的。对于更复杂的索引来说,这是一个有用的构建模块。
第三章:存储与检索
69


键值存储与在大多数编程语言中可以找到的字典(dictionary)类型非常相似,通常字典都是
用散列映射(hash map)(或哈希表(hash table))实现的。哈希映射在许多算法教科书
中都有描述【1,2】,所以这里我们不会讨论它的工作细节。既然我们已经有内存中数据结构
—— 哈希映射,为什么不使用它来索引在磁盘上的数据呢?
假设我们的数据存储只是一个追加写入的文件,就像前面的例子一样。那么最简单的索引策
略就是:保留一个内存中的哈希映射,其中每个键都映射到一个数据文件中的字节偏移量,
指明了可以找到对应值的位置,如图3-1所示。当你将新的键值对追加写入文件中时,还要更
新散列映射,以反映刚刚写入的数据的偏移量(这同时适用于插入新键与更新现有键)。当
你想查找一个值时,使用哈希映射来查找数据文件中的偏移量,寻找(seek)该位置并读取
该值。
图3-1 以类CSV格式存储键值对的日志,并使用内存哈希映射进行索引。
听上去简单,但这是一个可行的方法。现实中,Bitcask实际上就是这么做的(Riak中默认的
存储引擎)【3】。 Bitcask提供高性能的读取和写入操作,但所有键必须能放入可用内存
中,因为哈希映射完全保留在内存中。这些值可以使用比可用内存更多的空间,因为可以从
磁盘上通过一次 seek 加载所需部分,如果数据文件的那部分已经在文件系统缓存中,则读取
根本不需要任何磁盘I/O。
像Bitcask这样的存储引擎非常适合每个键的值经常更新的情况。例如,键可能是视频的
URL,值可能是它播放的次数(每次有人点击播放按钮时递增)。在这种类型的工作负载
中,有很多写操作,但是没有太多不同的键——每个键有很多的写操作,但是将所有键保存
在内存中是可行的。
直到现在,我们只是追加写入一个文件 —— 所以如何避免最终用完磁盘空间?一种好的解决
方案是,将日志分为特定大小的段,当日志增长到特定尺寸时关闭当前段文件,并开始写入
一个新的段文件。然后,我们就可以对这些段进行压缩(compaction),如图3-2所示。压
缩意味着在日志中丢弃重复的键,只保留每个键的最近更新。
第三章:存储与检索
70


图3-2 压缩键值更新日志(统计猫视频的播放次数),只保留每个键的最近值
而且,由于压缩经常会使得段变得很小(假设在一个段内键被平均重写了好几次),我们也
可以在执行压缩的同时将多个段合并在一起,如图3-3所示。段被写入后永远不会被修改,所
以合并的段被写入一个新的文件。冻结段的合并和压缩可以在后台线程中完成,在进行时,
我们仍然可以继续使用旧的段文件来正常提供读写请求。合并过程完成后,我们将读取请求
转换为使用新的合并段而不是旧段 —— 然后可以简单地删除旧的段文件。
图3-3 同时执行压缩和分段合并
每个段现在都有自己的内存散列表,将键映射到文件偏移量。为了找到一个键的值,我们首
先检查最近段的哈希映射;如果键不存在,我们检查第二个最近的段,依此类推。合并过程保
持细分的数量,所以查找不需要检查许多哈希映射。 大量的细节进入实践这个简单的想法工
作。简而言之,一些真正实施中重要的问题是:
文件格式
第三章:存储与检索
71


CSV不是日志的最佳格式。使用二进制格式更快,更简单,首先以字节为单位对字符串的长
度进行编码,然后使用原始字符串(不需要转义)。
删除记录
如果要删除一个键及其关联的值,则必须在数据文件(有时称为逻辑删除)中附加一个特殊
的删除记录。当日志段被合并时,逻辑删除告诉合并过程放弃删除键的任何以前的值。
崩溃恢复
如果数据库重新启动,则内存散列映射将丢失。原则上,您可以通过从头到尾读取整个段文
件并在每次按键时注意每个键的最近值的偏移量来恢复每个段的哈希映射。但是,如果段文
件很大,这可能需要很长时间,这将使服务器重新启动痛苦。 Bitcask通过存储加速恢复磁盘
上每个段的哈希映射的快照,可以更快地加载到内存中。
部分写入记录
数据库可能随时崩溃,包括将记录附加到日志中途。 Bitcask文件包含校验和,允许检测和忽
略日志的这些损坏部分。
并发控制
由于写操作是以严格顺序的顺序附加到日志中的,所以常见的实现选择是只有一个写入器线
程。数据文件段是附加的,否则是不可变的,所以它们可以被多个线程同时读取。
乍一看,只有追加日志看起来很浪费:为什么不更新文件,用新值覆盖旧值?但是只能追加
设计的原因有几个:
追加和分段合并是顺序写入操作,通常比随机写入快得多,尤其是在磁盘旋转硬盘上。
在某种程度上,顺序写入在基于闪存的固态硬盘(SSD)上也是优选的【4】。我们将在
第83页的“比较B-树和LSM-树”中进一步讨论这个问题。
如果段文件是附加的或不可变的,并发和崩溃恢复就简单多了。例如,您不必担心在覆
盖值时发生崩溃的情况,而将包含旧值和新值的一部分的文件保留在一起。
合并旧段可以避免数据文件随着时间的推移而分散的问题。
但是,哈希表索引也有局限性:
散列表必须能放进内存
如果你有非常多的键,那真是倒霉。原则上可以在磁盘上保留一个哈希映射,不幸的是
磁盘哈希映射很难表现优秀。它需要大量的随机访问I/O,当它变满时增长是很昂贵的,
并且散列冲突需要很多的逻辑【5】。
范围查询效率不高。例如,您无法轻松扫描kitty00000和kitty99999之间的所有键——您
必须在散列映射中单独查找每个键。
在下一节中,我们将看看一个没有这些限制的索引结构。
第三章:存储与检索
72


SSTables和LSM树
在图3-3中,每个日志结构存储段都是一系列键值对。这些对按照它们写入的顺序出现,日志
中稍后的值优先于日志中较早的相同键的值。除此之外,文件中键值对的顺序并不重要。
现在我们可以对段文件的格式做一个简单的改变:我们要求键值对的序列按键排序。乍一
看,这个要求似乎打破了我们使用顺序写入的能力,但是我们马上就会明白这一点。
我们把这个格式称为排序字符串表(Sorted String Table),简称SSTable。我们还要求每个
键只在每个合并的段文件中出现一次(压缩过程已经保证)。与使用散列索引的日志段相
比,SSTable有几个很大的优势:
1. 合并段是简单而高效的,即使文件大于可用内存。这种方法就像归并排序算法中使用的
方法一样,如图3-4所示:您开始并排读取输入文件,查看每个文件中的第一个键,复制
最低键(根据排序顺序)到输出文件,并重复。这产生一个新的合并段文件,也按键排
序。
图3-4 合并几个SSTable段,只保留每个键的最新值
如果在几个输入段中出现相同的键,该怎么办?请记住,每个段都包含在一段时间内写
入数据库的所有值。这意味着一个输入段中的所有值必须比另一个段中的所有值更新
(假设我们总是合并相邻的段)。当多个段包含相同的键时,我们可以保留最近段的
值,并丢弃旧段中的值。
第三章:存储与检索
73


2. 为了在文件中找到一个特定的键,你不再需要保存内存中所有键的索引。以图3-5为例:
假设你正在内存中寻找键 handiwork ,但是你不知道段文件中该关键字的确切偏移量。
然而,你知道 handbag 和 handsome 的偏移,而且由于排序特性,你知道 handiwork
必须出现在这两者之间。这意味着您可以跳到 handbag 的偏移位置并从那里扫描,直到
您找到 handiwork (或没找到,如果该文件中没有该键)。
图3-5 具有内存索引的SSTable
您仍然需要一个内存中索引来告诉您一些键的偏移量,但它可能很稀疏:每几千字节的
段文件就有一个键就足够了,因为几千字节可以很快被扫描 。
1. 由于读取请求无论如何都需要扫描所请求范围内的多个键值对,因此可以将这些记录分
组到块中,并在将其写入磁盘之前对其进行压缩(如图3-5中的阴影区域所示) 。稀疏内
存中索引的每个条目都指向压缩块的开始处。除了节省磁盘空间之外,压缩还可以减少
IO带宽的使用。
. 如果所有的键与值都是定长的,你可以使用段文件上的二分查找并完全避免使用内存索
引。然而实践中键值通常都是变长的,因此如果没有索引,就很难知道记录的分界点
(前一条记录结束,后一条记录开始的地方) ↩
构建和维护SSTables
到目前为止,但是如何让你的数据首先被按键排序呢?我们的传入写入可以以任何顺序发
生。
在磁盘上维护有序结构是可能的(参阅“B树”),但在内存保存则要容易得多。有许多可以使
用的众所周知的树形数据结构,例如红黑树或AVL树【2】。使用这些数据结构,您可以按任
何顺序插入键,并按排序顺序读取它们。
现在我们可以使我们的存储引擎工作如下:
i
i
第三章:存储与检索
74


写入时,将其添加到内存中的平衡树数据结构(例如,红黑树)。这个内存树有时被称
为内存表(memtable)。
当内存表大于某个阈值(通常为几兆字节)时,将其作为SSTable文件写入磁盘。这可以
高效地完成,因为树已经维护了按键排序的键值对。新的SSTable文件成为数据库的最新
部分。当SSTable被写入磁盘时,写入可以继续到一个新的内存表实例。
为了提供读取请求,首先尝试在内存表中找到关键字,然后在最近的磁盘段中,然后在
下一个较旧的段中找到该关键字。
有时会在后台运行合并和压缩过程以组合段文件并丢弃覆盖或删除的值。
这个方案效果很好。它只会遇到一个问题:如果数据库崩溃,则最近的写入(在内存表中,
但尚未写入磁盘)将丢失。为了避免这个问题,我们可以在磁盘上保存一个单独的日志,每
个写入都会立即被附加到磁盘上,就像在前一节中一样。该日志不是按排序顺序,但这并不
重要,因为它的唯一目的是在崩溃后恢复内存表。每当内存表写出到SSTable时,相应的日志
都可以被丢弃。
用SSTables制作LSM树
这里描述的算法本质上是LevelDB 【6】和RocksDB 【7】中使用的关键值存储引擎库,被设
计嵌入到其他应用程序中。除此之外,LevelDB可以在Riak中用作Bitcask的替代品。在
Cassandra和HBase中使用了类似的存储引擎【8】,这两种引擎都受到了Google的Bigtable
文档【9】(引入了SSTable和memtable)的启发。
最初这种索引结构是由Patrick O'Neil等人描述的。在日志结构合并树(或LSM树)【10】的
基础上,建立在以前的工作上日志结构的文件系统【11】。基于这种合并和压缩排序文件原
理的存储引擎通常被称为LSM存储引擎。
Lucene是Elasticsearch和Solr使用的一种全文搜索的索引引擎,它使用类似的方法来存储它
的词典【12,13】。全文索引比键值索引复杂得多,但是基于类似的想法:在搜索查询中给出
一个单词,找到提及单词的所有文档(网页,产品描述等)。这是通过键值结构实现的,其
中键是单词(关键词(term)),值是包含单词(文章列表)的所有文档的ID的列表。在
Lucene中,从术语到发布列表的这种映射保存在SSTable类的有序文件中,根据需要在后台
合并【14】。
性能优化
与往常一样,大量的细节使得存储引擎在实践中表现良好。例如,当查找数据库中不存在的
键时,LSM树算法可能会很慢:您必须检查内存表,然后将这些段一直回到最老的(可能必
须从磁盘读取每一个),然后才能确定键不存在。为了优化这种访问,存储引擎通常使用额
外的Bloom过滤器【15】。 (布隆过滤器是用于近似集合内容的内存高效数据结构,它可以
告诉您数据库中是否出现键,从而为不存在的键节省许多不必要的磁盘读取操作。
第三章:存储与检索
75


还有不同的策略来确定SSTables如何被压缩和合并的顺序和时间。最常见的选择是大小分层
压实。 LevelDB和RocksDB使用平坦压缩(LevelDB因此得名),HBase使用大小分层,
Cassandra同时支持【16】。在规模级别的调整中,更新和更小的SSTables先后被合并到更
老的和更大的SSTable中。在水平压实中,关键范围被拆分成更小的SSTables,而较旧的数
据被移动到单独的“水平”,这使得压缩能够更加递增地进行,并且使用更少的磁盘空间。
即使有许多微妙的东西,LSM树的基本思想 —— 保存一系列在后台合并的SSTables —— 简
单而有效。即使数据集比可用内存大得多,它仍能继续正常工作。由于数据按排序顺序存
储,因此可以高效地执行范围查询(扫描所有高于某些最小值和最高值的所有键),并且因
为磁盘写入是连续的,所以LSM树可以支持非常高的写入吞吐量。
B树
刚才讨论的日志结构索引正处在逐渐被接受的阶段,但它们并不是最常见的索引类型。使用
最广泛的索引结构在1970年被引入【17】,不到10年后变得“无处不在”【18】,B树经受了时
间的考验。在几乎所有的关系数据库中,它们仍然是标准的索引实现,许多非关系数据库也
使用它们。
像SSTables一样,B树保持按键排序的键值对,这允许高效的键值查找和范围查询。但这就是
相似之处的结尾:B树有着非常不同的设计理念。
我们前面看到的日志结构索引将数据库分解为可变大小的段,通常是几兆字节或更大的大
小,并且总是按顺序编写段。相比之下,B树将数据库分解成固定大小的块或页面,传统上大
小为4KB(有时会更大),并且一次只能读取或写入一个页面。这种设计更接近于底层硬件,
因为磁盘也被安排在固定大小的块中。
每个页面都可以使用地址或位置来标识,这允许一个页面引用另一个页面 —— 类似于指针,
但在磁盘而不是在内存中。我们可以使用这些页面引用来构建一个页面树,如图3-6所示。
第三章:存储与检索
76


图3-6 使用B树索引查找一个键
一个页面会被指定为B树的根;在索引中查找一个键时,就从这里开始。该页面包含几个键和
对子页面的引用。每个子页面负责一段连续范围的键,引用之间的键,指明了引用子页面的
键范围。
在图3-6的例子中,我们正在寻找关键字 251 ,所以我们知道我们需要遵循边界 200 和 300
之间的页面引用。这将我们带到一个类似的页面,进一步打破了200 - 300到子范围。
最后,我们可以看到包含单个键(叶页)的页面,该页面包含每个键的内联值,或者包含对
可以找到值的页面的引用。
在B树的一个页面中对子页面的引用的数量称为分支因子。例如,在图3-6中,分支因子是 6
。在实践中,分支因子取决于存储页面参考和范围边界所需的空间量,但通常是几百个。
如果要更新B树中现有键的值,则搜索包含该键的叶页,更改该页中的值,并将该页写回到磁
盘(对该页的任何引用保持有效) 。如果你想添加一个新的键,你需要找到其范围包含新键
的页面,并将其添加到该页面。如果页面中没有足够的可用空间容纳新键,则将其分成两个
半满页面,并更新父页面以解释键范围的新分区,如图3-7所示 。
. 向B树中插入一个新的键是相当符合直觉的,但删除一个键(同时保持树平衡)就会牵
扯很多其他东西了。 ↩
ii
ii
第三章:存储与检索
77


图3-7 通过分割页面来生长B树
该算法确保树保持平衡:具有 n 个键的B树总是具有 $O(log n)$ 的深度。大多数数据库可以
放入一个三到四层的B树,所以你不需要遵追踪多页面引用来找到你正在查找的页面。 (分
支因子为 500 的 4KB 页面的四级树可以存储多达 256TB 。)
让B树更可靠
B树的基本底层写操作是用新数据覆盖磁盘上的页面。假定覆盖不改变页面的位置;即,当页
面被覆盖时,对该页面的所有引用保持完整。这与日志结构索引(如LSM树)形成鲜明对
比,后者只附加到文件(并最终删除过时的文件),但从不修改文件。
您可以考虑将硬盘上的页面覆盖为实际的硬件操作。在磁性硬盘驱动器上,这意味着将磁头
移动到正确的位置,等待旋转盘上的正确位置出现,然后用新的数据覆盖适当的扇区。在固
态硬盘上,由于SSD必须一次擦除和重写相当大的存储芯片块,所以会发生更复杂的事情
【19】。
而且,一些操作需要覆盖几个不同的页面。例如,如果因为插入导致页面过度而拆分页面,
则需要编写已拆分的两个页面,并覆盖其父页面以更新对两个子页面的引用。这是一个危险
的操作,因为如果数据库在仅有一些页面被写入后崩溃,那么最终将导致一个损坏的索引
(例如,可能有一个孤儿页面不是任何父项的子项) 。
为了使数据库对崩溃具有韧性,B树实现通常会带有一个额外的磁盘数据结构:预写式日志
(WAL, write-ahead-log)(也称为重做日志(redo log))。这是一个仅追加的文件,每
个B树修改都可以应用到树本身的页面上。当数据库在崩溃后恢复时,这个日志被用来使B树
恢复到一致的状态【5,20】。
第三章:存储与检索
78


更新页面的一个额外的复杂情况是,如果多个线程要同时访问B树,则需要仔细的并发控制
—— 否则线程可能会看到树处于不一致的状态。这通常通过使用锁存器(latches)(轻量级
锁)保护树的数据结构来完成。日志结构化的方法在这方面更简单,因为它们在后台进行所
有的合并,而不会干扰传入的查询,并且不时地将旧的分段原子交换为新的分段。
B树优化
由于B树已经存在了这么久,许多优化已经发展了多年,这并不奇怪。仅举几例:
一些数据库(如LMDB)使用写时复制方案【21】,而不是覆盖页面并维护WAL进行崩
溃恢复。修改的页面被写入到不同的位置,并且树中的父页面的新版本被创建,指向新
的位置。这种方法对于并发控制也很有用,我们将在“快照隔离和可重复读”中看到。
我们可以通过不存储整个键来节省页面空间,但可以缩小它的大小。特别是在树内部的
页面上,键只需要提供足够的信息来充当键范围之间的边界。在页面中包含更多的键允
许树具有更高的分支因子,因此更少的层次
通常,页面可以放置在磁盘上的任何位置;没有什么要求附近的键范围页面附近的磁盘
上。如果查询需要按照排序顺序扫描大部分关键字范围,那么每个页面的布局可能会非
常不方便,因为每个读取的页面都可能需要磁盘查找。因此,许多B树实现尝试布局树,
使得叶子页面按顺序出现在磁盘上。但是,随着树的增长,维持这个顺序是很困难的。
相比之下,由于LSM树在合并过程中一次又一次地重写存储的大部分,所以它们更容易
使顺序键在磁盘上彼此靠近。
额外的指针已添加到树中。例如,每个叶子页面可以在左边和右边具有对其兄弟页面的
引用,这允许不跳回父页面就能顺序扫描。
B树的变体如分形树【22】借用一些日志结构的思想来减少磁盘寻道(而且它们与分形无
关)。
比较B树和LSM树
尽管B树实现通常比LSM树实现更成熟,但LSM树由于其性能特点也非常有趣。根据经验,通
常LSM树的写入速度更快,而B树的读取速度更快【23】。 LSM树上的读取通常比较慢,因
为它们必须在压缩的不同阶段检查几个不同的数据结构和SSTables。
然而,基准通常对工作量的细节不确定和敏感。 您需要测试具有特定工作负载的系统,以便
进行有效的比较。 在本节中,我们将简要讨论一些在衡量存储引擎性能时值得考虑的事情。
LSM树的优点
B树索引必须至少两次写入每一段数据:一次写入预先写入日志,一次写入树页面本身(也许
再次分页)。即使在该页面中只有几个字节发生了变化,也需要一次编写整个页面的开销。
有些存储引擎甚至会覆盖同一个页面两次,以免在电源故障的情况下导致页面部分更新
【24,25】。
第三章:存储与检索
79


由于反复压缩和合并SSTables,日志结构索引也会重写数据。这种影响 —— 在数据库的生命
周期中写入数据库导致对磁盘的多次写入 —— 被称为写放大(write amplification)。需要
特别关注的是固态硬盘,固态硬盘在磨损之前只能覆写一段时间。
在写入繁重的应用程序中,性能瓶颈可能是数据库可以写入磁盘的速度。在这种情况下,写
放大会导致直接的性能代价:存储引擎写入磁盘的次数越多,可用磁盘带宽内的每秒写入次
数越少。
而且,LSM树通常能够比B树支持更高的写入吞吐量,部分原因是它们有时具有较低的写放大
(尽管这取决于存储引擎配置和工作负载),部分是因为它们顺序地写入紧凑的SSTable文件
而不是必须覆盖树中的几个页面【26】。这种差异在磁性硬盘驱动器上尤其重要,顺序写入
比随机写入快得多。
LSM树可以被压缩得更好,因此经常比B树在磁盘上产生更小的文件。 B树存储引擎会由于分
割而留下一些未使用的磁盘空间:当页面被拆分或某行不能放入现有页面时,页面中的某些
空间仍未被使用。由于LSM树不是面向页面的,并且定期重写SSTables以去除碎片,所以它
们具有较低的存储开销,特别是当使用平坦压缩时【27】。
在许多固态硬盘上,固件内部使用日志结构化算法,将随机写入转变为顺序写入底层存储芯
片,因此存储引擎写入模式的影响不太明显【19】。但是,较低的写入放大率和减少的碎片
对SSD仍然有利:更紧凑地表示数据可在可用的I/O带宽内提供更多的读取和写入请求。
LSM树的缺点
日志结构存储的缺点是压缩过程有时会干扰正在进行的读写操作。尽管存储引擎尝试逐步执
行压缩而不影响并发访问,但是磁盘资源有限,所以很容易发生请求需要等待而磁盘完成昂
贵的压缩操作。对吞吐量和平均响应时间的影响通常很小,但是在更高百分比的情况下(参
阅“描述性能”),对日志结构化存储引擎的查询响应时间有时会相当长,而B树的行为则相对
更具可预测性【28】。
压缩的另一个问题出现在高写入吞吐量:磁盘的有限写入带宽需要在初始写入(记录和刷新
内存表到磁盘)和在后台运行的压缩线程之间共享。写入空数据库时,可以使用全磁盘带宽
进行初始写入,但数据库越大,压缩所需的磁盘带宽就越多。
如果写入吞吐量很高,并且压缩没有仔细配置,压缩跟不上写入速率。在这种情况下,磁盘
上未合并段的数量不断增加,直到磁盘空间用完,读取速度也会减慢,因为它们需要检查更
多段文件。通常情况下,即使压缩无法跟上,基于SSTable的存储引擎也不会限制传入写入的
速率,所以您需要进行明确的监控来检测这种情况【29,30】。
B树的一个优点是每个键只存在于索引中的一个位置,而日志结构化的存储引擎可能在不同的
段中有相同键的多个副本。这个方面使得B树在想要提供强大的事务语义的数据库中很有吸引
力:在许多关系数据库中,事务隔离是通过在键范围上使用锁来实现的,在B树索引中,这些
锁可以直接连接到树【5】。在第7章中,我们将更详细地讨论这一点。
第三章:存储与检索
80


B树在数据库体系结构中是非常根深蒂固的,为许多工作负载提供始终如一的良好性能,所以
它们不可能很快就会消失。在新的数据存储中,日志结构化索引变得越来越流行。没有快速
和容易的规则来确定哪种类型的存储引擎对你的场景更好,所以值得进行一些经验上的测试
其他索引结构
到目前为止,我们只讨论了关键值索引,它们就像关系模型中的主键(primary key)索引。
主键唯一标识关系表中的一行,或文档数据库中的一个文档或图形数据库中的一个顶点。数
据库中的其他记录可以通过其主键(或ID)引用该行/文档/顶点,并且索引用于解析这样的引
用。
有二级索引也很常见。在关系数据库中,您可以使用 CREATE INDEX 命令在同一个表上创建多
个二级索引,而且这些索引通常对于有效地执行联接而言至关重要。例如,在第2章中的图2
1中,很可能在 user_id 列上有一个二级索引,以便您可以在每个表中找到属于同一用户的
所有行。
一个二级索引可以很容易地从一个键值索引构建。主要的不同是键不是唯一的。即可能有许
多行(文档,顶点)具有相同的键。这可以通过两种方式来解决:或者通过使索引中的每个
值,成为匹配行标识符的列表(如全文索引中的发布列表),或者通过向每个索引添加行标
识符来使每个关键字唯一。无论哪种方式,B树和日志结构索引都可以用作辅助索引。
将值存储在索引中
索引中的关键字是查询搜索的内容,但是该值可以是以下两种情况之一:它可以是所讨论的
实际行(文档,顶点),也可以是对存储在别处的行的引用。在后一种情况下,行被存储的
地方被称为堆文件(heap file),并且存储的数据没有特定的顺序(它可以是仅附加的,或
者可以跟踪被删除的行以便用新数据覆盖它们后来)。堆文件方法很常见,因为它避免了在
存在多个二级索引时复制数据:每个索引只引用堆文件中的一个位置,实际的数据保存在一
个地方。 在不更改键的情况下更新值时,堆文件方法可以非常高效:只要新值不大于旧值,
就可以覆盖该记录。如果新值更大,情况会更复杂,因为它可能需要移到堆中有足够空间的
新位置。在这种情况下,要么所有的索引都需要更新,以指向记录的新堆位置,或者在旧堆
位置留下一个转发指针【5】。
在某些情况下,从索引到堆文件的额外跳跃对读取来说性能损失太大,因此可能希望将索引
行直接存储在索引中。这被称为聚集索引。例如,在MySQL的InnoDB存储引擎中,表的主键
总是一个聚簇索引,二级索引用主键(而不是堆文件中的位置)【31】。在SQL Server中,
可以为每个表指定一个聚簇索引【32】。
在聚集索引(clustered index)(在索引中存储所有行数据)和非聚集索引(nonclustered
index)(仅在索引中存储对数据的引用)之间的折衷被称为包含列的索引(index with
included columns)或覆盖索引(covering index),其存储表的一部分在索引内【33】。
第三章:存储与检索
81


这允许通过单独使用索引来回答一些查询(这种情况叫做:索引覆盖(cover)了查询)
【32】。
与任何类型的数据重复一样,聚簇和覆盖索引可以加快读取速度,但是它们需要额外的存储
空间,并且会增加写入开销。数据库还需要额外的努力来执行事务保证,因为应用程序不应
该因为重复而导致不一致。
多列索引
至今讨论的索引只是将一个键映射到一个值。如果我们需要同时查询一个表中的多个列(或
文档中的多个字段),这显然是不够的。
最常见的多列索引被称为连接索引(concatenated index),它通过将一列的值追加到另一
列后面,简单地将多个字段组合成一个键(索引定义中指定了字段的连接顺序)。这就像一
个老式的纸质电话簿,它提供了一个从(姓,名)到电话号码的索引。由于排序顺序,索引
可以用来查找所有具有特定姓氏的人,或所有具有特定姓-名组合的人。然而,如果你想找到
所有具有特定名字的人,这个索引是没有用的。
多维索引(multi-dimensional index)是一种查询多个列的更一般的方法,这对于地理空间
数据尤为重要。例如,餐厅搜索网站可能有一个数据库,其中包含每个餐厅的经度和纬度。
当用户在地图上查看餐馆时,网站需要搜索用户正在查看的矩形地图区域内的所有餐馆。这
需要一个二维范围查询,如下所示:
SELECT * FROM restaurants WHERE latitude > 51.4946 AND latitude < 51.5079
AND longitude > -0.1162 AND longitude < -0.1004;
一个标准的B树或者LSM树索引不能够高效地响应这种查询:它可以返回一个纬度范围内的所
有餐馆(但经度可能是任意值),或者返回在同一个经度范围内的所有餐馆(但纬度可能是
北极和南极之间的任意地方),但不能同时满足。
一种选择是使用空间填充曲线将二维位置转换为单个数字,然后使用常规B树索引【34】。更
普遍的是,使用特殊化的空间索引,例如R树。例如,PostGIS使用PostgreSQL的通用Gist工
具【35】将地理空间索引实现为R树。这里我们没有足够的地方来描述R树,但是有大量的文
献可供参考。
一个有趣的主意是,多维索引不仅可以用于地理位置。例如,在电子商务网站上可以使用维
度(红色,绿色,蓝色)上的三维索引来搜索特定颜色范围内的产品,也可以在天气观测数
据库中搜索二维(日期,温度)的指数,以便有效地搜索2013年的温度在25至30°C之间的所
有观测资料。使用一维索引,你将不得不扫描2013年的所有记录(不管温度如何),然后通
过温度进行过滤,反之亦然。 二维索引可以同时通过时间戳和温度来收窄数据集。这个技术
被HyperDex使用【36】。
全文搜索和模糊索引
第三章:存储与检索
82


到目前为止所讨论的所有索引都假定您有确切的数据,并允许您查询键的确切值或具有排序
顺序的键的值范围。他们不允许你做的是搜索类似的键,如拼写错误的单词。这种模糊的查
询需要不同的技术。
例如,全文搜索引擎通常允许搜索一个单词以扩展为包括该单词的同义词,忽略单词的语法
变体,并且搜索在相同文档中彼此靠近的单词的出现,并且支持各种其他功能取决于文本的
语言分析。为了处理文档或查询中的拼写错误,Lucene能够在一定的编辑距离内搜索文本
(编辑距离1意味着添加,删除或替换了一个字母)【37】。
正如“在SSTables中创建LSM树”中所提到的,Lucene为其词典使用了一个类似于SSTable的
结构。这个结构需要一个小的内存索引,告诉查询在排序文件中哪个偏移量需要查找关键
字。在LevelDB中,这个内存中的索引是一些键的稀疏集合,但在Lucene中,内存中的索引
是键中字符的有限状态自动机,类似于trie 【38】。这个自动机可以转换成Levenshtein自动
机,它支持在给定的编辑距离内有效地搜索单词【39】。
其他的模糊搜索技术正朝着文档分类和机器学习的方向发展。有关更多详细信息,请参阅信
息检索教科书,例如【40】。
在内存中存储一切
本章到目前为止讨论的数据结构都是对磁盘限制的回答。与主内存相比,磁盘处理起来很尴
尬。对于磁盘和SSD,如果要在读取和写入时获得良好性能,则需要仔细地布置磁盘上的数
据。但是,我们容忍这种尴尬,因为磁盘有两个显着的优点:它们是耐用的(它们的内容在
电源关闭时不会丢失),并且每GB的成本比RAM低。
随着RAM变得更便宜,每GB的成本价格被侵蚀了。许多数据集不是那么大,所以将它们全部
保存在内存中是非常可行的,可能分布在多个机器上。这导致了内存数据库的发展。
某些内存中的键值存储(如Memcached)仅用于缓存,在重新启动计算机时丢失的数据是可
以接受的。但其他内存数据库的目标是持久性,可以通过特殊的硬件(例如电池供电的
RAM),将更改日志写入磁盘,将定时快照写入磁盘或通过复制内存来实现,记忆状态到其
他机器。
内存数据库重新启动时,需要从磁盘或通过网络从副本重新加载其状态(除非使用特殊的硬
件)。尽管写入磁盘,它仍然是一个内存数据库,因为磁盘仅用作耐久性附加日志,读取完
全由内存提供。写入磁盘也具有操作优势:磁盘上的文件可以很容易地由外部实用程序进行
备份,检查和分析。
诸如VoltDB,MemSQL和Oracle TimesTen等产品是具有关系模型的内存数据库,供应商声
称,通过消除与管理磁盘上的数据结构相关的所有开销,他们可以提供巨大的性能改进
【41,42】。 RAM Cloud是一个开源的内存键值存储器,具有持久性(对存储器中的数据以及
磁盘上的数据使用日志结构化方法)【43】。 Redis和Couchbase通过异步写入磁盘提供了
较弱的持久性。
第三章:存储与检索
83


反直觉的是,内存数据库的性能优势并不是因为它们不需要从磁盘读取的事实。即使是基于
磁盘的存储引擎也可能永远不需要从磁盘读取,因为操作系统缓存最近在内存中使用了磁盘
块。相反,它们更快的原因在于省去了将内存数据结构编码为磁盘数据结构的开销。
【44】。
除了性能,内存数据库的另一个有趣的领域是提供难以用基于磁盘的索引实现的数据模型。
例如,Redis为各种数据结构(如优先级队列和集合)提供了类似数据库的接口。因为它将所
有数据保存在内存中,所以它的实现相对简单。
最近的研究表明,内存数据库体系结构可以扩展到支持比可用内存更大的数据集,而不必重
新采用以磁盘为中心的体系结构【45】。所谓的反缓存(anti-caching)方法通过在内存不
足的情况下将最近最少使用的数据从内存转移到磁盘,并在将来再次访问时将其重新加载到
内存中。这与操作系统对虚拟内存和交换文件的操作类似,但数据库可以比操作系统更有效
地管理内存,因为它可以按单个记录的粒度工作,而不是整个内存页面。尽管如此,这种方
法仍然需要索引能完全放入内存中(就像本章开头的Bitcask例子)。
如果非易失性存储器(NVM)技术得到更广泛的应用,可能还需要进一步改变存储引擎设计
【46】。目前这是一个新的研究领域,值得关注。
事务处理还是分析?
在业务数据处理的早期,对数据库的写入通常对应于正在进行的商业交易:进行销售,向供
应商下订单,支付员工工资等等。随着数据库扩展到那些没有不涉及钱易手,术语交易仍然
卡住,指的是形成一个逻辑单元的一组读写。 事务不一定具有ACID(原子性,一致性,隔离
性和持久性)属性。事务处理只是意味着允许客户端进行低延迟读取和写入 —— 而不是批量
处理作业,而这些作业只能定期运行(例如每天一次)。我们在第7章中讨论ACID属性,在
第10章中讨论批处理。
即使数据库开始被用于许多不同类型的博客文章,游戏中的动作,地址簿中的联系人等等,
基本访问模式仍然类似于处理业务事务。应用程序通常使用索引通过某个键查找少量记录。
根据用户的输入插入或更新记录。由于这些应用程序是交互式的,因此访问模式被称为在线
事务处理(OLTP, OnLine Transaction Processing)。
但是,数据库也开始越来越多地用于数据分析,这些数据分析具有非常不同的访问模式。通
常,分析查询需要扫描大量记录,每个记录只读取几列,并计算汇总统计信息(如计数,总
和或平均值),而不是将原始数据返回给用户。例如,如果您的数据是一个销售交易表,那
么分析查询可能是:
一月份我们每个商店的总收入是多少?
我们在最近的推广活动中销售多少香蕉?
哪种品牌的婴儿食品最常与X品牌的尿布一起购买?
第三章:存储与检索
84


这些查询通常由业务分析师编写,并提供给帮助公司管理层做出更好决策(商业智能)的报
告。为了区分这种使用数据库的事务处理模式,它被称为在线分析处理(OLAP, OnLine
Analytice Processing)。【47】。OLTP和OLAP之间的区别并不总是清晰的,但是一些典
型的特征在表3-1中列出。
表3-1 比较交易处理和分析系统的特点
属性 事务处理 OLTP 分析系统 OLAP
主要读取模式 查询少量记录,按键读取 在大批量记录上聚合
主要写入模式 随机访问,写入要求低延时 批量导入(ETL),事件流
主要用户 终端用户,通过Web应用 内部数据分析师,决策支持
处理的数据 数据的最新状态(当前时间点) 随时间推移的历史事件
数据集尺寸 GB ~ TB TB ~ PB
起初,相同的数据库用于事务处理和分析查询。 SQL在这方面证明是非常灵活的:对于OLTP
类型的查询以及OLAP类型的查询来说效果很好。尽管如此,在二十世纪八十年代末和九十年
代初期,公司有停止使用OLTP系统进行分析的趋势,而是在单独的数据库上运行分析。这个
单独的数据库被称为数据仓库(data warehouse)。
数据仓库
一个企业可能有几十个不同的交易处理系统:系统为面向客户的网站提供动力,控制实体商
店的销售点(checkout)系统,跟踪仓库中的库存,规划车辆路线,管理供应商,管理员工
等。这些系统中的每一个都是复杂的,需要一个人员去维护,所以系统最终都是自动运行
的。
这些OLTP系统通常具有高度的可用性,并以低延迟处理事务,因为这些系统往往对业务运作
至关重要。因此数据库管理员密切关注他们的OLTP数据库他们通常不愿意让业务分析人员在
OLTP数据库上运行临时分析查询,因为这些查询通常很昂贵,扫描大部分数据集,这会损害
同时执行的事务的性能。
相比之下,数据仓库是一个独立的数据库,分析人员可以查询他们心中的内容,而不影响
OLTP操作【48】。数据仓库包含公司所有各种OLTP系统中的只读数据副本。从OLTP数据库
中提取数据(使用定期的数据转储或连续的更新流),转换成适合分析的模式,清理并加载
到数据仓库中。将数据存入仓库的过程称为“抽取-转换-加载(ETL)”,如图3-8所示。
第三章:存储与检索
85


图3-8 ETL至数据仓库的简化提纲
几乎所有的大型企业都有数据仓库,但在小型企业中几乎闻所未闻。这可能是因为大多数小
公司没有这么多不同的OLTP系统,大多数小公司只有少量的数据 —— 可以在传统的SQL数
据库中查询,甚至可以在电子表格中分析。在一家大公司里,要做一些在一家小公司很简单
的事情,需要很多繁重的工作。
使用单独的数据仓库,而不是直接查询OLTP系统进行分析的一大优势是数据仓库可针对分析
访问模式进行优化。事实证明,本章前半部分讨论的索引算法对于OLTP来说工作得很好,但
对于回答分析查询并不是很好。在本章的其余部分中,我们将看看为分析而优化的存储引
擎。
OLTP数据库和数据仓库之间的分歧
数据仓库的数据模型通常是关系型的,因为SQL通常很适合分析查询。有许多图形数据分析
工具可以生成SQL查询,可视化结果,并允许分析人员探索数据(通过下钻,切片和切块等
操作)。
表面上,一个数据仓库和一个关系OLTP数据库看起来很相似,因为它们都有一个SQL查询接
口。然而,系统的内部看起来可能完全不同,因为它们针对非常不同的查询模式进行了优
化。现在许多数据库供应商都将重点放在支持事务处理或分析工作负载上,而不是两者都支
持。
第三章:存储与检索
86


一些数据库(例如Microsoft SQL Server和SAP HANA)支持在同一产品中进行事务处理和数
据仓库。但是,它们正在日益成为两个独立的存储和查询引擎,这些引擎正好可以通过一个
通用的SQL接口访问【49,50,51】。
Teradata,Vertica,SAP HANA和ParAccel等数据仓库供应商通常使用昂贵的商业许可证销
售他们的系统。 Amazon RedShift是ParAccel的托管版本。最近,大量的开源SQL-on
Hadoop项目已经出现,它们还很年轻,但是正在与商业数据仓库系统竞争。这些包括Apache
Hive,Spark SQL,Cloudera Impala,Facebook Presto,Apache Tajo和Apache Drill
【52,53】。其中一些是基于谷歌的Dremel [54]的想法。
星型和雪花型:分析的模式
正如第2章所探讨的,根据应用程序的需要,在事务处理领域中使用了大量不同的数据模型。
另一方面,在分析中,数据模型的多样性则少得多。许多数据仓库都以相当公式化的方式使
用,被称为星型模式(也称为维度建模【55】)。
图3-9中的示例模式显示了可能在食品零售商处找到的数据仓库。在模式的中心是一个所谓的
事实表(在这个例子中,它被称为 fact_sales )。事实表的每一行代表在特定时间发生的事
件(这里,每一行代表客户购买的产品)。如果我们分析的是网站流量而不是零售量,则每
行可能代表一个用户的页面浏览量或点击量。
第三章:存储与检索
87


图3-9 用于数据仓库的星型模式的示例
通常情况下,事实被视为单独的事件,因为这样可以在以后分析中获得最大的灵活性。但
是,这意味着事实表可以变得非常大。像苹果,沃尔玛或eBay这样的大企业在其数据仓库中
可能有几十PB的交易历史,其中大部分实际上是表【56】。
事实表中的一些列是属性,例如产品销售的价格和从供应商那里购买的成本(允许计算利润
余额)。事实表中的其他列是对其他表(称为维表)的外键引用。由于事实表中的每一行都
表示一个事件,因此这些维度代表事件的发生地点,时间,方式和原因。
例如,在图3-9中,其中一个维度是已售出的产品。 dim_product 表中的每一行代表一种待售
产品,包括库存单位(SKU),说明,品牌名称,类别,脂肪含量,包装尺寸
等。 fact_sales 表中的每一行都使用外部表明在特定交易中销售了哪些产品。 (为了简单
起见,如果客户一次购买几种不同的产品,则它们在事实表中被表示为单独的行)。
第三章:存储与检索
88


即使日期和时间通常使用维度表来表示,因为这允许对日期(诸如公共假期)的附加信息进
行编码,从而允许查询区分假期和非假期的销售。
“星型模式”这个名字来源于这样一个事实,即当表关系可视化时,事实表在中间,由维表包
围;与这些表的连接就像星星的光芒。
这个模板的变体被称为雪花模式,其中尺寸被进一步分解为子尺寸。例如,品牌和产品类别
可能有单独的表格,并且 dim_product 表格中的每一行都可以将品牌和类别作为外键引用,
而不是将它们作为字符串存储在 dim_product 表格中。雪花模式比星形模式更规范化,但是
星形模式通常是首选,因为分析师使用它更简单【55】。
在典型的数据仓库中,表格通常非常宽泛:事实表格通常有100列以上,有时甚至有数百列
【51】。维度表也可以是非常宽的,因为它们包括可能与分析相关的所有元数据——例
如, dim_store 表可以包括在每个商店提供哪些服务的细节,它是否具有店内面包房,方形
镜头,商店第一次开幕的日期,最后一次改造的时间,离最近的高速公路的距离等等。
列存储
如果事实表中有万亿行和数PB的数据,那么高效地存储和查询它们就成为一个具有挑战性的
问题。维度表通常要小得多(数百万行),所以在本节中我们将主要关注事实的存储。
尽管事实表通常超过100列,但典型的数据仓库查询一次只能访问4个或5个查询( “ SELECT
* ” 查询很少用于分析)【51】。以例3-1中的查询为例:它访问了大量的行(在2013日历年
中每次都有人购买水果或糖果),但只需访问 fact_sales 表的三列: date_key, product_sk,
quantity 。查询忽略所有其他列。
例3-1 分析人们是否更倾向于购买新鲜水果或糖果,这取决于一周中的哪一天
SELECT
dim_date.weekday,
dim_product.category,
SUM(fact_sales.quantity) AS quantity_sold
FROM fact_sales
JOIN dim_date ON fact_sales.date_key = dim_date.date_key
JOIN dim_product ON fact_sales.product_sk = dim_product.product_sk
WHERE
dim_date.year = 2013 AND
dim_product.category IN ('Fresh fruit', 'Candy')
GROUP BY
dim_date.weekday, dim_product.category;
我们如何有效地执行这个查询?
第三章:存储与检索
89


在大多数OLTP数据库中,存储都是以面向行的方式进行布局的:表格的一行中的所有值都相
邻存储。文档数据库是相似的:整个文档通常存储为一个连续的字节序列。你可以在图3-1的
CSV例子中看到这个。
为了处理像例3-1这样的查询,您可能在 fact_sales.date_key , fact_sales.product_sk 上有
索引,它们告诉存储引擎在哪里查找特定日期或特定产品的所有销售情况。但是,面向行的
存储引擎仍然需要将所有这些行(每个包含超过100个属性)从磁盘加载到内存中,解析它
们,并过滤掉那些不符合要求的条件。这可能需要很长时间。
面向列的存储背后的想法很简单:不要将所有来自一行的值存储在一起,而是将来自每一列
的所有值存储在一起。如果每个列存储在一个单独的文件中,查询只需要读取和解析查询中
使用的那些列,这可以节省大量的工作。这个原理如图3-10所示。
图3-10 使用列存储关系型数据,而不是行
列存储在关系数据模型中是最容易理解的,但它同样适用于非关系数据。例如,Parquet
【57】是一种列式存储格式,支持基于Google的Dremel 【54】的文档数据模型。
面向列的存储布局依赖于包含相同顺序行的每个列文件。 因此,如果您需要重新组装整行,
您可以从每个单独的列文件中获取第23项,并将它们放在一起形成表的第23行。
列压缩
第三章:存储与检索
90


除了仅从磁盘加载查询所需的列以外,我们还可以通过压缩数据来进一步降低对磁盘吞吐量
的需求。幸运的是,面向列的存储通常很适合压缩。
看看图3-10中每一列的值序列:它们通常看起来是相当重复的,这是压缩的好兆头。根据列
中的数据,可以使用不同的压缩技术。在数据仓库中特别有效的一种技术是位图编码,如图3
11所示。
图3-11 压缩位图索引存储布局
通常情况下,一列中不同值的数量与行数相比较小(例如,零售商可能有数十亿的销售交
易,但只有100,000个不同的产品)。现在我们可以得到一个有 n 个不同值的列,并把它转换
成 n 个独立的位图:每个不同值的一个位图,每行一位。如果该行具有该值,则该位为 1 ,
否则为 0 。
如果 n 非常小(例如,国家/地区列可能有大约200个不同的值),则这些位图可以每行存储
一位。但是,如果n更大,大部分位图中将会有很多的零(我们说它们是稀疏的)。在这种情
况下,位图可以另外进行游程编码,如图3-11底部所示。这可以使列的编码非常紧凑。
这些位图索引非常适合数据仓库中常见的各种查询。例如:
WHERE product_sk IN(30,68,69)
第三章:存储与检索
91


加载 product_sk = 30 , product_sk = 68 , product_sk = 69 的三个位图,并计算三个位图
的按位或,这可以非常有效地完成。
WHERE product_sk = 31 AND store_sk = 3
加载 product_sk = 31 和 store_sk = 3 的位图,并逐位计算AND。 这是因为列按照相同的
顺序包含行,因此一列的位图中的第 k 位对应于与另一列的位图中的第 k 位相同的行。
对于不同种类的数据,也有各种不同的压缩方案,但我们不会详细讨论它们,参见【58】的
概述。
面向列的存储和列族
Cassandra和HBase有一个列族的概念,他们从Bigtable继承【9】。然而,把它们称为
面向列是非常具有误导性的:在每个列族中,它们将一行中的所有列与行键一起存储,
并且不使用列压缩。因此,Bigtable模型仍然主要是面向行的。
内存带宽和向量处理
对于需要扫描数百万行的数据仓库查询来说,一个巨大的瓶颈是从磁盘获取数据到内存的带
宽。但是,这不是唯一的瓶颈。分析数据库的开发人员也担心有效利用主存储器带宽到CPU
缓存中的带宽,避免CPU指令处理流水线中的分支错误预测和泡沫,以及在现代中使用单指
令多数据(SIMD)指令CPU 【59,60】。
除了减少需要从磁盘加载的数据量以外,面向列的存储布局也可以有效利用CPU周期。例
如,查询引擎可以将大量压缩的列数据放在CPU的L1缓存中,然后在紧密的循环中循环(即
没有函数调用)。一个CPU可以执行这样一个循环比代码要快得多,这个代码需要处理每个
记录的大量函数调用和条件。列压缩允许列中的更多行适合相同数量的L1缓存。前面描述的
按位“与”和“或”运算符可以被设计为直接在这样的压缩列数据块上操作。这种技术被称为矢量
化处理【58,49】。
列存储中的排序顺序
在列存储中,存储行的顺序并不一定很重要。按插入顺序存储它们是最简单的,因为插入一
个新行就意味着附加到每个列文件。但是,我们可以选择强制执行一个命令,就像我们之前
对SSTables所做的那样,并将其用作索引机制。
注意,每列独自排序是没有意义的,因为那样我们就不会知道列中的哪些项属于同一行。我
们只能重建一行,因为我们知道一列中的第k项与另一列中的第k项属于同一行。
第三章:存储与检索
92


相反,即使按列存储数据,也需要一次对整行进行排序。数据库的管理员可以使用他们对常
见查询的知识来选择表格应该被排序的列。例如,如果查询通常以日期范围为目标,例如上
个月,则可以将 date_key 作为第一个排序键。然后,查询优化器只能扫描上个月的行,这
比扫描所有行要快得多。
第二列可以确定第一列中具有相同值的任何行的排序顺序。例如,如果 date_key 是图3-10
中的第一个排序关键字,那么 product_sk 可能是第二个排序关键字,因此同一天的同一产
品的所有销售都将在存储中组合在一起。这将有助于需要在特定日期范围内按产品对销售进
行分组或过滤的查询。
排序顺序的另一个好处是它可以帮助压缩列。如果主要排序列没有多个不同的值,那么在排
序之后,它将具有很长的序列,其中相同的值连续重复多次。一个简单的运行长度编码(就
像我们用于图3-11中的位图一样)可以将该列压缩到几千字节 —— 即使表中有数十亿行。
第一个排序键的压缩效果最强。第二和第三个排序键会更混乱,因此不会有这么长时间的重
复值。排序优先级下面的列以基本上随机的顺序出现,所以它们可能不会被压缩。但前几列
排序仍然是一个整体。
几个不同的排序顺序
这个想法的巧妙扩展在C-Store中引入,并在商业数据仓库Vertica【61,62】中被采用。不同
的查询受益于不同的排序顺序,为什么不以相同的方式存储相同的数据呢?无论如何,数据
需要复制到多台机器,这样,如果一台机器发生故障,您不会丢失数据。您可能还需要存储
以不同方式排序的冗余数据,以便在处理查询时,可以使用最适合查询模式的版本。
在一个面向列的存储中有多个排序顺序有点类似于在一个面向行的存储中有多个二级索引。
但最大的区别在于面向行的存储将每一行保存在一个地方(在堆文件或聚簇索引中),二级
索引只包含指向匹配行的指针。在列存储中,通常在其他地方没有任何指向数据的指针,只
有包含值的列。
写入列存储
这些优化在数据仓库中是有意义的,因为大多数负载由分析人员运行的大型只读查询组成。
面向列的存储,压缩和排序都有助于更快地读取这些查询。然而,他们有写更加困难的缺
点。
使用B树的更新就地方法对于压缩的列是不可能的。如果你想在排序表的中间插入一行,你很
可能不得不重写所有的列文件。由于行由列中的位置标识,因此插入必须始终更新所有列。
幸运的是,本章前面已经看到了一个很好的解决方案:LSM树。所有的写操作首先进入一个
内存中的存储,在这里它们被添加到一个已排序的结构中,并准备写入磁盘。内存中的存储
是面向行还是列的,这并不重要。当已经积累了足够的写入数据时,它们将与磁盘上的列文
件合并,并批量写入新文件。这基本上是Vertica所做的【62】。
第三章:存储与检索
93


查询需要检查磁盘上的列数据和最近在内存中的写入,并将两者结合起来。但是,查询优化
器隐藏了用户的这个区别。从分析师的角度来看,通过插入,更新或删除操作进行修改的数
据会立即反映在后续查询中。
聚合:数据立方体和物化视图
并不是每个数据仓库都必定是一个列存储:传统的面向行的数据库和其他一些架构也被使
用。然而,对于专门的分析查询,列式存储可以显着加快,所以它正在迅速普及【51,63】。
数据仓库的另一个值得一提的是物化汇总。如前所述,数据仓库查询通常涉及一个聚合函
数,如SQL中的COUNT,SUM,AVG,MIN或MAX。如果相同的聚合被许多不同的查询使
用,那么每次都可以通过原始数据来处理。为什么不缓存一些查询使用最频繁的计数或总
和?
创建这种缓存的一种方式是物化视图。在关系数据模型中,它通常被定义为一个标准(虚
拟)视图:一个类似于表的对象,其内容是一些查询的结果。不同的是,物化视图是查询结
果的实际副本,写入磁盘,而虚拟视图只是写入查询的捷径。从虚拟视图读取时,SQL引擎
会将其展开到视图的底层查询中,然后处理展开的查询。
当底层数据发生变化时,物化视图需要更新,因为它是数据的非规范化副本。数据库可以自
动完成,但是这样的更新使得写入成本更高,这就是在OLTP数据库中不经常使用物化视图的
原因。在读取繁重的数据仓库中,它们可能更有意义(不管它们是否实际上改善了读取性能
取决于个别情况)。
物化视图的常见特例称为数据立方体或OLAP立方【64】。它是按不同维度分组的聚合网格。
图3-12显示了一个例子。
图3-12 数据立方的两个维度,通过求和聚合
第三章:存储与检索
94


想象一下,现在每个事实都只有两个维度表的外键——在图3-12中,这些是日期和产品。您
现在可以绘制一个二维表格,一个轴线上的日期和另一个轴上的产品。每个单元包含具有该
日期 - 产品组合的所有事实的属性(例如, net_price )的聚集(例如, SUM )。然后,您
可以沿着每行或每列应用相同的汇总,并获得一个维度减少的汇总(按产品的销售额,无论
日期,还是按日期销售,无论产品如何)。
一般来说,事实往往有两个以上的维度。在图3-9中有五个维度:日期,产品,商店,促销和
客户。要想象一个五维超立方体是什么样子是很困难的,但是原理是一样的:每个单元格都
包含特定日期(产品-商店-促销-客户)组合的销售。这些值可以在每个维度上重复概括。
物化数据立方体的优点是某些查询变得非常快,因为它们已经被有效地预先计算了。例如,
如果您想知道每个商店的总销售额,则只需查看合适维度的总计,无需扫描数百万行。
缺点是数据立方体不具有查询原始数据的灵活性。例如,没有办法计算哪个销售比例来自成
本超过100美元的项目,因为价格不是其中的一个维度。因此,大多数数据仓库试图保留尽可
能多的原始数据,并将聚合数据(如数据立方体)仅用作某些查询的性能提升。
本章小结
在本章中,我们试图深入了解数据库如何处理存储和检索。将数据存储在数据库中会发生什
么,以及稍后再次查询数据时数据库会做什么?
在高层次上,我们看到存储引擎分为两大类:优化事务处理(OLTP)和优化分析(OLAP)
的类别。这些用例的访问模式之间有很大的区别:
OLTP系统通常面向用户,这意味着他们可能会看到大量的请求。为了处理负载,应用程
序通常只触及每个查询中的少量记录。应用程序使用某种键来请求记录,存储引擎使用
索引来查找所请求的键的数据。磁盘寻道时间往往是这里的瓶颈。
数据仓库和类似的分析系统不太知名,因为它们主要由业务分析人员使用,而不是由最
终用户使用。它们处理比OLTP系统少得多的查询量,但是每个查询通常要求很高,需要
在短时间内扫描数百万条记录。磁盘带宽(不是查找时间)往往是瓶颈,列式存储是这
种工作负载越来越流行的解决方案。
在OLTP方面,我们看到了来自两大主流学派的存储引擎:
日志结构学派
只允许附加到文件和删除过时的文件,但不会更新已经写入的文件。 Bitcask,SSTables,
LSM树,LevelDB,Cassandra,HBase,Lucene等都属于这个组。
就地更新学派
将磁盘视为一组可以覆盖的固定大小的页面。 B树是这种哲学的最大的例子,被用在所有主
要的关系数据库中,还有许多非关系数据库。
第三章:存储与检索
95


日志结构的存储引擎是相对较新的发展。他们的主要想法是,他们系统地将随机访问写入顺
序写入磁盘,由于硬盘驱动器和固态硬盘的性能特点,可以实现更高的写入吞吐量。在完成
OLTP方面,我们通过一些更复杂的索引结构和为保留所有数据而优化的数据库做了一个简短
的介绍。
然后,我们从存储引擎的内部绕开,看看典型数据仓库的高级架构。这一背景说明了为什么
分析工作负载与OLTP差别很大:当您的查询需要在大量行中顺序扫描时,索引的相关性就会
降低很多。相反,非常紧凑地编码数据变得非常重要,以最大限度地减少查询需要从磁盘读
取的数据量。我们讨论了列式存储如何帮助实现这一目标。
作为一名应用程序开发人员,如果您掌握了有关存储引擎内部的知识,那么您就能更好地了
解哪种工具最适合您的特定应用程序。如果您需要调整数据库的调整参数,这种理解可以让
您设想一个更高或更低的值可能会产生什么效果。
尽管本章不能让你成为一个特定存储引擎的调参专家,但它至少有大概率使你有了足够的概
念与词汇储备去读懂数据库的文档,从而选择合适的数据库。
参考文献
1. Alfred V. Aho, John E. Hopcroft, and Jeffrey D. Ullman: Data Structures and Algorithms.
Addison-Wesley, 1983. ISBN: 978-0-201-00023-8
2. Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein:
Introduction to Algorithms, 3rd edition. MIT Press, 2009. ISBN: 978-0-262-53305-8
3. Justin Sheehy and David Smith: “Bitcask: A Log-Structured Hash Table for Fast
Key/Value Data,” Basho Technologies, April 2010.
4. Yinan Li, Bingsheng He, Robin Jun Yang, et al.: “Tree Indexing on Solid State Drives,”
Proceedings of the VLDB Endowment, volume 3, number 1, pages 1195–1206,
September 2010.
5. Goetz Graefe: “Modern B-Tree Techniques,” Foundations and Trends in Databases,
volume 3, number 4, pages 203–402, August 2011. doi:10.1561/1900000028
6. Jeffrey Dean and Sanjay Ghemawat: “LevelDB Implementation Notes,”
leveldb.googlecode.com.
7. Dhruba Borthakur: “The History of RocksDB,” rocksdb.blogspot.com, November 24,
2013.
8. Matteo Bertozzi: “Apache HBase I/O – HFile,” blog.cloudera.com, June, 29 2012.
第三章:存储与检索
96


9. Fay Chang, Jeffrey Dean, Sanjay Ghemawat, et al.: “Bigtable: A Distributed Storage
System for Structured Data,” at 7th USENIX Symposium on Operating System Design
and Implementation (OSDI), November 2006.
10. Patrick O'Neil, Edward Cheng, Dieter Gawlick, and Elizabeth O'Neil: “The Log
Structured Merge-Tree (LSM-Tree),” Acta Informatica, volume 33, number 4, pages
351–385, June 1996. doi:10.1007/s002360050048
11. Mendel Rosenblum and John K. Ousterhout: “The Design and Implementation of a Log
Structured File System,” ACM Transactions on Computer Systems, volume 10, number
1, pages 26–52, February 1992. doi:10.1145/146941.146943
12. Adrien Grand: “What Is in a Lucene Index?,” at Lucene/Solr Revolution, November 14,
2013.
13. Deepak Kandepet: “Hacking Lucene—The Index Format,” hackerlabs.org, October 1,
2011.
14. Michael McCandless: “Visualizing Lucene's Segment Merges,”
blog.mikemccandless.com, February 11, 2011.
15. Burton H. Bloom: “Space/Time Trade-offs in Hash Coding with Allowable Errors,”
Communications of the ACM, volume 13, number 7, pages 422–426, July 1970.
doi:10.1145/362686.362692
16. “Operating Cassandra: Compaction,” Apache Cassandra Documentation v4.0, 2016.
17. Rudolf Bayer and Edward M. McCreight: “Organization and Maintenance of Large
Ordered Indices,” Boeing Scientific Research Laboratories, Mathematical and
Information Sciences Laboratory, report no. 20, July 1970.
18. Douglas Comer: “The Ubiquitous B-Tree,” ACM Computing Surveys, volume 11,
number 2, pages 121–137, June 1979. doi:10.1145/356770.356776
19. Emmanuel Goossaert: “Coding for SSDs,” codecapsule.com, February 12, 2014.
20. C. Mohan and Frank Levine: “ARIES/IM: An Efficient and High Concurrency Index
Management Method Using Write-Ahead Logging,” at ACM International Conference on
Management of Data (SIGMOD), June 1992. doi:10.1145/130283.130338
21. Howard Chu: “LDAP at Lightning Speed,” at Build Stuff '14, November 2014.
22. Bradley C. Kuszmaul: “A Comparison of Fractal Trees to Log-Structured Merge (LSM)
Trees,” tokutek.com, April 22, 2014.
第三章:存储与检索
97


23. Manos Athanassoulis, Michael S. Kester, Lukas M. Maas, et al.: “Designing Access
Methods: The RUM Conjecture,” at 19th International Conference on Extending
Database Technology (EDBT), March 2016. doi:10.5441/002/edbt.2016.42
24. Peter Zaitsev: “Innodb Double Write,” percona.com, August 4, 2006.
25. Tomas Vondra: “On the Impact of Full-Page Writes,” blog.2ndquadrant.com, November
23, 2016.
26. Mark Callaghan: “The Advantages of an LSM vs a B-Tree,” smalldatum.blogspot.co.uk,
January 19, 2016.
27. Mark Callaghan: “Choosing Between Efficiency and Performance with RocksDB,” at
Code Mesh, November 4, 2016.
28. Michi Mutsuzaki: “MySQL vs. LevelDB,” github.com, August 2011.
29. Benjamin Coverston, Jonathan Ellis, et al.: “CASSANDRA-1608: Redesigned
Compaction, issues.apache.org, July 2011.
30. Igor Canadi, Siying Dong, and Mark Callaghan: “RocksDB Tuning Guide,” github.com,
2016.
31. MySQL 5.7 Reference Manual. Oracle, 2014.
32. Books Online for SQL Server 2012. Microsoft, 2012.
33. Joe Webb: “Using Covering Indexes to Improve Query Performance,” simple-talk.com,
29 September 2008.
34. Frank Ramsak, Volker Markl, Robert Fenk, et al.: “Integrating the UB-Tree into a
Database System Kernel,” at 26th International Conference on Very Large Data Bases
(VLDB), September 2000.
35. The PostGIS Development Group: “PostGIS 2.1.2dev Manual,” postgis.net, 2014.
36. Robert Escriva, Bernard Wong, and Emin Gün Sirer: “HyperDex: A Distributed,
Searchable Key-Value Store,” at ACM SIGCOMM Conference, August 2012.
doi:10.1145/2377677.2377681
37. Michael McCandless: “Lucene's FuzzyQuery Is 100 Times Faster in 4.0,”
blog.mikemccandless.com, March 24, 2011.
38. Steffen Heinz, Justin Zobel, and Hugh E. Williams: “Burst Tries: A Fast, Efficient Data
Structure for String Keys,” ACM Transactions on Information Systems, volume 20,
number 2, pages 192–223, April 2002. doi:10.1145/506309.506312
第三章:存储与检索
98


39. Klaus U. Schulz and Stoyan Mihov: “Fast String Correction with Levenshtein Automata,”
International Journal on Document Analysis and Recognition, volume 5, number 1,
pages 67–85, November 2002. doi:10.1007/s10032-002-0082-8
40. Christopher D. Manning, Prabhakar Raghavan, and Hinrich Schütze: Introduction to
Information Retrieval. Cambridge University Press, 2008. ISBN: 978-0-521-86571-5,
available online at nlp.stanford.edu/IR-book
41. Michael Stonebraker, Samuel Madden, Daniel J. Abadi, et al.: “The End of an
Architectural Era (It’s Time for a Complete Rewrite),” at 33rd International Conference
on Very Large Data Bases (VLDB), September 2007.
42. “VoltDB Technical Overview White Paper,” VoltDB, 2014.
43. Stephen M. Rumble, Ankita Kejriwal, and John K. Ousterhout: “Log-Structured Memory
for DRAM-Based Storage,” at 12th USENIX Conference on File and Storage
Technologies (FAST), February 2014.
44. Stavros Harizopoulos, Daniel J. Abadi, Samuel Madden, and Michael Stonebraker:
“OLTP Through the Looking Glass, and What We Found There,” at ACM International
Conference on Management of Data (SIGMOD), June 2008.
doi:10.1145/1376616.1376713
45. Justin DeBrabant, Andrew Pavlo, Stephen Tu, et al.: “Anti-Caching: A New Approach to
Database Management System Architecture,” Proceedings of the VLDB Endowment,
volume 6, number 14, pages 1942–1953, September 2013.
46. Joy Arulraj, Andrew Pavlo, and Subramanya R. Dulloor: “Let's Talk About Storage &
Recovery Methods for Non-Volatile Memory Database Systems,” at ACM International
Conference on Management of Data (SIGMOD), June 2015.
doi:10.1145/2723372.2749441
47. Edgar F. Codd, S. B. Codd, and C. T. Salley: “Providing OLAP to User-Analysts: An IT
Mandate,” E. F. Codd Associates, 1993.
48. Surajit Chaudhuri and Umeshwar Dayal: “An Overview of Data Warehousing and OLAP
Technology,” ACM SIGMOD Record, volume 26, number 1, pages 65–74, March 1997.
doi:10.1145/248603.248616
49. Per-Åke Larson, Cipri Clinciu, Campbell Fraser, et al.: “Enhancements to SQL Server
Column Stores,” at ACM International Conference on Management of Data (SIGMOD),
June 2013.
第三章:存储与检索
99


50. Franz Färber, Norman May, Wolfgang Lehner, et al.: “The SAP HANA Database – An
Architecture Overview,” IEEE Data Engineering Bulletin, volume 35, number 1, pages
28–33, March 2012.
51. Michael Stonebraker: “The Traditional RDBMS Wisdom Is (Almost Certainly) All Wrong,”
presentation at EPFL, May 2013.
52. Daniel J. Abadi: “Classifying the SQL-on-Hadoop Solutions,” hadapt.com, October 2,
2013.
53. Marcel Kornacker, Alexander Behm, Victor Bittorf, et al.: “Impala: A Modern, Open
Source SQL Engine for Hadoop,” at 7th Biennial Conference on Innovative Data
Systems Research (CIDR), January 2015.
54. Sergey Melnik, Andrey Gubarev, Jing Jing Long, et al.: “Dremel: Interactive Analysis of
Web-Scale Datasets,” at 36th International Conference on Very Large Data Bases
(VLDB), pages 330–339, September 2010.
55. Ralph Kimball and Margy Ross: The Data Warehouse Toolkit: The Definitive Guide to
Dimensional Modeling, 3rd edition. John Wiley & Sons, July 2013. ISBN: 978-1-118
53080-1
56. Derrick Harris: “Why Apple, eBay, and Walmart Have Some of the Biggest Data
Warehouses You’ve Ever Seen,” gigaom.com, March 27, 2013.
57. Julien Le Dem: “Dremel Made Simple with Parquet,” blog.twitter.com, September 11,
2013.
58. Daniel J. Abadi, Peter Boncz, Stavros Harizopoulos, et al.: “The Design and
Implementation of Modern Column-Oriented Database Systems,” Foundations and
Trends in Databases, volume 5, number 3, pages 197–280, December 2013.
doi:10.1561/1900000024
59. Peter Boncz, Marcin Zukowski, and Niels Nes: “MonetDB/X100: Hyper-Pipelining Query
Execution,” at 2nd Biennial Conference on Innovative Data Systems Research (CIDR),
January 2005.
60. Jingren Zhou and Kenneth A. Ross: “Implementing Database Operations Using SIMD
Instructions,” at ACM International Conference on Management of Data (SIGMOD),
pages 145–156, June 2002. doi:10.1145/564691.564709
61. Michael Stonebraker, Daniel J. Abadi, Adam Batkin, et al.: “C-Store: A Column-oriented
DBMS,” at 31st International Conference on Very Large Data Bases (VLDB), pages
553–564, September 2005.
第三章:存储与检索
100